{
  "projectName": "docsrs-mcp",
  "lastUpdated": "2025-08-23",
  "purpose": "Track errors, solutions, and lessons learned during development",
  "categories": {
    "errorSolutions": {
      "description": "Solutions to specific errors encountered during development",
      "entries": [
        {
          "error": "compareVersions Schema Reference Error - PointerToNowhere for '/components/schemas/ItemChange'",
          "rootCause": "MCP manifest uses $ref to ChangeCategory enum that doesn't exist in the schema structure. The schema references undefined components.",
          "solution": "Replace $ref with inline enum array definitions in the MCP manifest schema. Define enum values directly instead of referencing external components.",
          "context": "MCP manifest schema validation failing on tool parameter definitions",
          "lesson": "Always validate that $ref paths exist in the actual schema structure before using them in MCP manifests",
          "pattern": "Use inline enum definitions instead of $ref for simple value constraints",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["mcp_server.py", "src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Instead of:\n\"changeType\": {\"$ref\": \"#/components/schemas/ChangeCategory\"}\n# Use:\n\"changeType\": {\"type\": \"string\", \"enum\": [\"major\", \"minor\", \"patch\", \"prerelease\"]}",
          "debuggingTechnique": "Use MCP tools to trace schema generation and compare manifest schemas with actual Pydantic model definitions"
        },
        {
          "error": "K Parameter Validation Errors - searchItems and startPreIngestion reject integer parameters",
          "rootCause": "Despite anyOf patterns in schema, validation order issues persist. Field validators may not be properly coercing parameters to expected types.",
          "solution": "Ensure field validators exist with coerce_to_int_with_bounds function. Add defensive bounds checking and proper integer coercion in validation chain.",
          "context": "MCP tool parameter validation failing on numeric inputs that should be valid",
          "lesson": "anyOf patterns alone are insufficient - explicit field validators are required for type coercion in MCP tools",
          "pattern": "Implement coerce_to_int_with_bounds validators for all numeric parameters in MCP tools",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py", "src/docsrs_mcp/validators.py"],
          "codeExample": "@field_validator('k', mode='before')\n@classmethod\ndef coerce_k(cls, v):\n    return coerce_to_int_with_bounds(v, min_val=1, max_val=100)",
          "debuggingTechnique": "Test with curl to isolate MCP client vs server validation issues"
        },
        {
          "error": "Boolean parameter validation with string inputs requires specialized handling",
          "rootCause": "MCP clients send boolean parameters as strings ('true', 'false', '1', '0', 'yes', 'no', 'on', 'off') requiring flexible conversion beyond simple type checking",
          "solution": "Use coerce_to_bool_with_validation() function for all boolean parameters to handle string inputs. Function provides comprehensive string-to-boolean mapping with case-insensitive matching",
          "context": "MCP parameter validation for boolean values needs to handle multiple string representations while maintaining type safety",
          "lesson": "Boolean parameter validation in MCP requires more than simple type coercion - implement comprehensive string mapping for user-friendly input handling",
          "pattern": "Always use coerce_to_bool_with_validation() for MCP boolean parameters to handle diverse input formats",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/validators.py"],
          "codeExample": "@field_validator('enabled', mode='before')\n@classmethod\ndef validate_enabled(cls, v):\n    return coerce_to_bool_with_validation(v, field_name='enabled')\n\n# Helper function:\ndef coerce_to_bool_with_validation(value, field_name: str) -> bool:\n    if isinstance(value, bool):\n        return value\n    if isinstance(value, str):\n        return value.lower() in ('true', '1', 'yes', 'on')\n    raise ValueError(f'{field_name} must be boolean or string. Got: {type(value).__name__}')",
          "debuggingTechnique": "Test with various string representations: 'true', 'false', '1', '0', 'yes', 'no' to ensure comprehensive coverage"
        },
        {
          "error": "MCP parameter validation requires mode='before' for proper string conversion",
          "rootCause": "Pydantic field validators need mode='before' to intercept raw parameter values before standard type conversion. Without mode='before', validators run after failed type conversion",
          "solution": "Always use @field_validator with mode='before' for MCP parameter validation to ensure string inputs are processed before Pydantic's built-in type conversion attempts",
          "context": "MCP parameter validation failing because validators run after type conversion rather than before",
          "lesson": "MCP parameter validation architecture requires intercepting raw values with mode='before' to handle string inputs properly",
          "pattern": "All MCP parameter field validators must use mode='before' to process string inputs before standard validation",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "codeExample": "# Correct - processes string before type conversion\n@field_validator('parameter', mode='before')\n@classmethod\ndef validate_parameter(cls, v):\n    # Handle string conversion here\n    return processed_value\n\n# Incorrect - runs after failed conversion\n@field_validator('parameter')\n@classmethod\ndef validate_parameter(cls, v):\n    # Too late - string already rejected",
          "debuggingTechnique": "Check validator execution order and ensure string inputs reach custom validators before Pydantic type conversion"
        },
        {
          "error": "MCP schema override workaround needed for Claude Code compatibility",
          "rootCause": "Claude Code MCP client has specific schema validation requirements that conflict with standard FastMCP schema generation. anyOf patterns and complex schemas cause validation failures",
          "solution": "Keep MCP schema override workaround in mcp_server.py for Claude Code compatibility. Override auto-generated schemas with simplified string-only definitions while maintaining robust Pydantic validation",
          "context": "Claude Code MCP client requires simpler schemas than other MCP clients, necessitating client-specific compatibility layers",
          "lesson": "MCP client compatibility varies significantly - maintain schema override capabilities for problematic clients like Claude Code",
          "pattern": "Implement schema override system for MCP tools when client compatibility issues arise with auto-generated schemas",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["mcp_server.py", "src/docsrs_mcp/app.py"],
          "codeExample": "# Schema override for Claude Code compatibility\ntools_to_fix = {\n    'searchItems': {\n        'k': {'type': 'string', 'description': 'Number of results (1-100)'},\n        'enabled': {'type': 'string', 'description': 'Enable flag (true/false)'}\n    }\n}\n\n# Apply overrides to manifest\nfor tool_name, overrides in tools_to_fix.items():\n    if tool_name in manifest['tools']:\n        manifest['tools'][tool_name]['inputSchema']['properties'].update(overrides)",
          "debuggingTechnique": "Test schema compatibility across different MCP clients to identify client-specific validation requirements"
        },
        {
          "error": "Performance degradation from repeated string-to-boolean conversion in hot paths",
          "rootCause": "String-to-boolean conversion using case-insensitive string operations in tight loops causes unnecessary performance overhead during parameter validation",
          "solution": "Use lookup tables for boolean string mapping for 10x performance improvement. Pre-compute string-to-boolean mappings and use dictionary lookups instead of repeated string operations",
          "context": "High-frequency parameter validation creating performance bottlenecks with string comparison operations",
          "lesson": "Optimize parameter validation hot paths with lookup tables rather than repeated string operations for significant performance gains",
          "pattern": "Use pre-computed lookup tables for parameter validation in high-frequency operations",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/validators.py"],
          "codeExample": "# Optimized lookup table approach\nBOOL_STRING_MAP = {\n    'true': True, '1': True, 'yes': True, 'on': True,\n    'false': False, '0': False, 'no': False, 'off': False\n}\n\ndef coerce_to_bool_with_validation(value, field_name: str) -> bool:\n    if isinstance(value, bool):\n        return value\n    if isinstance(value, str):\n        lower_val = value.lower()\n        if lower_val in BOOL_STRING_MAP:\n            return BOOL_STRING_MAP[lower_val]\n        raise ValueError(f'{field_name} invalid boolean string: {value}')\n    raise ValueError(f'{field_name} must be boolean. Got: {type(value).__name__}')",
          "performanceImpact": "10x performance improvement over repeated string.lower() and 'in' operations",
          "debuggingTechnique": "Profile parameter validation functions under load to identify performance bottlenecks"
        },
        {
          "error": "AttributeError: 'NoneType' object has no attribute issues in parameter processing",
          "rootCause": "Parameter validation functions not handling None values before attempting method calls or attribute access, causing runtime AttributeError exceptions",
          "solution": "Defensive None checking prevents AttributeError: 'NoneType' object has no attribute issues. Always check for None values first in parameter validation chains",
          "context": "Runtime errors occurring when None values reach parameter processing functions without proper validation",
          "lesson": "Defensive programming requires explicit None handling in all parameter validation functions to prevent AttributeError exceptions",
          "pattern": "Always validate None values first before any method calls or attribute access in parameter validators",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/validators.py"],
          "codeExample": "def validate_parameter(value, field_name: str):\n    # Defensive None checking first\n    if value is None:\n        return None  # or default value\n    \n    # Safe to access methods/attributes\n    if isinstance(value, str):\n        return value.lower()  # No AttributeError risk\n    \n    return value",
          "prevention": "Implement None checks at the beginning of all parameter validation functions",
          "debuggingTechnique": "Add explicit None value tests to parameter validation test suites"
        },
        {
          "error": "CLI-callable HTTP testing insufficient for production validation",
          "rootCause": "Testing only with synthetic test suites misses real-world parameter validation edge cases and MCP client compatibility issues",
          "solution": "Test with production code using --mode rest flag for CLI-callable HTTP testing. This enables testing with real parameter combinations and client scenarios",
          "context": "Production deployment revealing parameter validation issues not caught by synthetic testing",
          "lesson": "Synthetic tests alone are insufficient - always validate with production scenarios and real client interactions",
          "pattern": "Complement synthetic tests with production-scenario testing using CLI HTTP mode",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "# Production testing with CLI HTTP mode\n# Start server: uv run docsrs-mcp --mode rest\n# Test with real parameters:\ncurl -X POST http://localhost:8000/mcp/tools/searchItems \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"k\": \"5\", \"query\": \"Vec::new\", \"enabled\": \"true\"}'\n\n# This tests actual MCP parameter validation with production data",
          "testingStrategy": "Use --mode rest for testing parameter validation with realistic client parameter formats",
          "debuggingTechnique": "Compare synthetic test results with production HTTP testing to identify validation gaps"
        },
        {
          "error": "File Path Validation Too Restrictive - Rejects case variations of Cargo.toml",
          "rootCause": "Exact case-sensitive matching against hardcoded filename patterns. File validation logic uses strict string equality instead of case-insensitive comparison.",
          "solution": "Use path.name.lower() for case-insensitive comparison when validating common configuration files like Cargo.toml.",
          "context": "File validation rejecting valid files due to case sensitivity in cross-platform environments",
          "lesson": "File validation should be case-insensitive for common configuration files to support different naming conventions across platforms",
          "pattern": "Always use .lower() comparison for configuration file validation",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["src/docsrs_mcp/validators.py", "src/docsrs_mcp/ingest.py"],
          "codeExample": "# Instead of:\nif path.name == 'Cargo.toml':\n# Use:\nif path.name.lower() == 'cargo.toml':",
          "debuggingTechnique": "Compare exact path strings and test with various case combinations to identify validation failures"
        },
        {
          "error": "No Partial Ingestion Status - Users can't determine ingestion progress",
          "rootCause": "Response models lack real-time progress fields. Existing crate_progress data is tracked internally but not exposed to users.",
          "solution": "Expose existing crate_progress data in health endpoints. Add progress fields to response models for long-running operations.",
          "context": "Users need visibility into ingestion progress for large crates or when operations are slow",
          "lesson": "Always expose progress information for long-running operations to improve user experience",
          "pattern": "Include progress fields in all long-running operation response models",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# Add to response model:\n@dataclass\nclass IngestionResponse:\n    status: str\n    progress: Optional[Dict[str, int]] = None  # {crate_name: items_processed}\n    total_crates: Optional[int] = None",
          "debuggingTechnique": "Monitor internal progress tracking variables and expose them through API endpoints"
        },
        {
          "error": "CLI/MCP parameter synchronization issue - MCP mode checking args.pre_ingest directly instead of environment variables",
          "rootCause": "Inconsistent parameter handling between REST and MCP modes. MCP mode was checking args.pre_ingest directly instead of using environment variables",
          "solution": "Unified both modes to use config.PRE_INGEST_ENABLED environment variable. Set environment variables before module imports to ensure configuration visibility across different server modes.",
          "context": "MCP mode requires different parameter handling than CLI mode",
          "lesson": "Always use environment variables for configuration consistency across different server modes",
          "pattern": "Set environment variables before module imports to ensure configuration visibility",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["mcp_server.py", "src/docsrs_mcp/app.py"],
          "codeExample": "os.environ['PRE_INGEST_ENABLED'] = str(args.pre_ingest).lower() # Set before imports"
        },
        {
          "error": "Cold start latency of 1.4s on first embedding generation",
          "rootCause": "First embedding request triggers ONNX model loading into memory, causing significant delay",
          "solution": "Implement comprehensive embedding warmup on server startup with representative text samples and dual-mode support",
          "context": "First query loads ONNX model into memory causing delay",
          "implementation": [
            "Use 3-5 representative text samples (short, medium, long) for thorough model warmup",
            "Fire-and-forget pattern with asyncio.create_task() to avoid blocking server startup",
            "Global status tracking for health endpoint integration",
            "Dual-mode support: REST mode uses startup_event with asyncio, MCP mode uses threading with separate event loop"
          ],
          "pattern": "Fire-and-forget background warmup to eliminate cold-start latency",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/mcp_server.py"],
          "codeExample": "# REST mode\nasync def startup_event():\n    asyncio.create_task(warmup_embeddings())\n\n# MCP mode\ndef start_warmup_thread():\n    def warmup_worker():\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        loop.run_until_complete(warmup_embeddings())\n    threading.Thread(target=warmup_worker, daemon=True).start()\n\n# Shared warmup function\nasync def warmup_embeddings():\n    samples = ['short', 'medium length text sample', 'longer text sample for comprehensive model warmup']\n    await embed_model.embed(samples)"
        },
        {
          "error": "Fuzzy path matching not finding obvious matches",
          "solution": "Extend RapidFuzz scoring algorithm. Use token_sort_ratio() for unordered matches. Set preprocessing=false in RapidFuzz 3.0.0+ for case sensitivity. Implement bulk operations with process.extract().",
          "context": "Current fuzzy matching too strict for item paths",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "from rapidfuzz import process, fuzz; process.extract(query, choices, scorer=fuzz.token_sort_ratio, preprocessing=False)"
        },
        {
          "error": "Search results showing too many similar items from the same module/type",
          "rootCause": "Pure relevance-based ranking can return homogeneous results that don't provide diverse information to the user",
          "solution": "Implement Maximum Marginal Relevance (MMR) diversification with configurable lambda parameter to balance relevance and diversity",
          "context": "Search quality improvement requiring balanced relevance and diversity in results",
          "implementation": [
            "Add MMR algorithm in database.py with _apply_mmr_diversification() function",
            "Configure RANKING_DIVERSITY_LAMBDA (0.6 default) for relevance vs diversity balance",
            "Set RANKING_DIVERSITY_WEIGHT (0.1 default) as global diversification toggle",
            "Implement dynamic fetch_k adjustment (1.5x multiplier when MMR enabled)",
            "Add diversity scoring based on item type penalties and path similarity"
          ],
          "pattern": "MMR = λ * relevance + (1-λ) * diversity where λ=0.6 provides optimal balance",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/config.py", "src/docsrs_mcp/cache.py"],
          "codeExample": "def _apply_mmr_diversification(ranked_results, k, lambda_param):\n    \"\"\"Apply MMR algorithm to balance relevance and diversity.\"\"\"\n    selected = []\n    remaining = ranked_results[:]\n    \n    # Always select highest scoring item first\n    selected.append(remaining.pop(0))\n    \n    while len(selected) < k and remaining:\n        mmr_scores = []\n        for item in remaining:\n            # Calculate diversity penalty based on selected items\n            diversity = calculate_diversity_score(item, selected)\n            # MMR formula: λ * relevance + (1-λ) * diversity\n            mmr_score = lambda_param * item[0] + (1 - lambda_param) * diversity\n            mmr_scores.append((mmr_score, item))\n        \n        # Select item with highest MMR score\n        best_item = max(mmr_scores, key=lambda x: x[0])[1]\n        selected.append(best_item)\n        remaining.remove(best_item)\n    \n    return [(score, path, header, content) for score, path, header, content, _ in selected]"
        },
        {
          "error": "British English queries not finding American English documentation (e.g., 'serialise' not matching 'serialize')",
          "rootCause": "Documentation typically uses American English spelling while users may search with British English variations",
          "solution": "Implement fuzzy query normalization to convert British spellings to American equivalents during query preprocessing",
          "context": "International user experience improvement for search consistency",
          "implementation": [
            "Add _apply_fuzzy_normalization() method in SearchItemsRequest Pydantic model",
            "Use regex-based word boundary matching to replace whole words only",
            "Preserve original case patterns (SERIALISE → SERIALIZE, Serialise → Serialize)",
            "Apply normalization during field validation with mode='before'",
            "Handle common patterns: -ise→-ize, -our→-or, -re→-er"
          ],
          "pattern": "Apply during Pydantic field validation for consistent query preprocessing",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "codeExample": "@field_validator('query', mode='before')\n@classmethod\ndef normalize_query(cls, value: str) -> str:\n    if not isinstance(value, str):\n        return value\n    \n    # Apply Unicode normalization first\n    normalized = unicodedata.normalize('NFKC', value)\n    \n    # Apply fuzzy normalization for British/American spellings\n    return cls._apply_fuzzy_normalization(normalized)\n\n@classmethod\ndef _apply_fuzzy_normalization(cls, query: str) -> str:\n    # British to American spelling patterns with word boundaries\n    patterns = [\n        (r'\\b(\\w*?)ise\\b', r'\\1ize'),  # serialise → serialize\n        (r'\\b(\\w*?)our\\b', r'\\1or'),   # colour → color\n        (r'\\b(\\w*?)re\\b', r'\\1er'),    # centre → center\n    ]\n    \n    result = query\n    for british, american in patterns:\n        result = re.sub(british, american, result, flags=re.IGNORECASE)\n    \n    return result"
        },
        {
          "error": "FastEmbed memory leak with large batches",
          "solution": "Use generator pattern with explicit cleanup: process in small batches (16 for CPU), call gc.collect() between batches, and use streaming instead of loading all at once",
          "context": "FastEmbed v0.7.1 has known memory issues when processing large numbers of embeddings",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["ingest.py"],
          "references": ["https://github.com/qdrant/fastembed/issues/memory-leak"]
        },
        {
          "error": "Search returns only crate-level docs",
          "solution": "Modified module_pattern filtering to include both the module itself AND items within it using OR clause: 'WHERE (module_name = ? OR module_name LIKE ?) AND ...' instead of just exact module matching",
          "context": "Vector search was filtering too strictly and only returning crate-level documentation, missing specific module content",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "WHERE (embeddings.module_name = ? OR embeddings.module_name LIKE ?) AND embeddings.item_type != 'crate' AND embeddings.rowid IN (SELECT rowid FROM vss_embeddings WHERE vss_search(embeddings_vec, ?) AND k = ?)"
        },
        {
          "error": "sqlite-vec k parameter errors",
          "solution": "Added explicit 'AND k = ?' to WHERE clause as required by sqlite-vec. The k parameter must be included in the query constraints, not just as a LIMIT clause",
          "context": "sqlite-vec extension requires the k parameter to be explicitly specified in the WHERE clause for vector similarity searches",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "WHERE vss_search(embeddings_vec, ?) AND k = ?"
        },
        {
          "error": "Unhelpful validation error messages",
          "solution": "Enhanced validators to include valid ranges and examples in error messages. For example: 'k must be between 1-20, got 25. Use k=5 for standard results' instead of just 'invalid k value'",
          "context": "Generic validation errors made it difficult for users to understand what values were acceptable",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "raise ValueError(f'k must be between 1-{MAX_K}, got {k}. Use k=5 for standard results')"
        },
        {
          "error": "searchExamples returns fragmented characters",
          "solution": "Added defensive type checking and proper string wrapping to prevent character iteration. Ensure examples are treated as complete strings rather than iterables of characters",
          "context": "When examples were strings, they were being treated as iterables and returned character by character instead of as complete example strings",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "if isinstance(examples, str): examples = [examples]  # Wrap single string in list"
        },
        {
          "error": "NOT NULL constraint failed: embeddings.item_path",
          "context": "Ingestion pipeline crashes during rustdoc JSON parsing when items have empty paths",
          "rootCause": "The parsing logic in parse_rustdoc_items_streaming() uses 'path or name' which results in empty string when both are empty, violating the NOT NULL constraint",
          "solution": [
            "Added validate_item_path_with_fallback() function in validation.py that generates fallback paths",
            "Validation at parse time (ingest.py:1199) generates fallback paths like 'kind::item_id' when paths are empty",
            "Defensive validation in _store_batch() skips any chunks that still have invalid paths",
            "Fallback path patterns: 'item_kind::item_id' for items with IDs, 'item_kind::unknown_hash' for items without IDs"
          ],
          "prevention": "Always validate database fields that have NOT NULL constraints before insertion",
          "dateEncountered": "2025-08-09",
          "affectedVersions": "All versions prior to fix",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/validation.py"],
          "codeExample": "def validate_item_path_with_fallback(path: str, name: str, item_kind: str, item_id: str) -> str:\n    if path:\n        return path\n    if name:\n        return name\n    # Generate fallback path\n    if item_id:\n        return f'{item_kind}::{item_id}'\n    return f'{item_kind}::unknown_{hash(str(item_kind))}'",
          "researchFindings": [
            "NOT NULL constraint failures are sqlite3.IntegrityError exceptions",
            "Use INSERT OR IGNORE to skip constraint violations gracefully", 
            "Validate data before database insertion to prevent constraint errors",
            "Fallback path generation ensures all items have valid identifiers"
          ]
        },
        {
          "error": "FastEmbed TextEmbedding global singleton memory leak",
          "solution": "Configure ONNX Runtime with sess_options.enable_cpu_mem_arena = False and implement explicit model lifecycle management. Use del session, gc.collect() for cleanup. Consider switching to lighter models like all-MiniLM-L6-v2.",
          "context": "Memory grows from 176MB to 1661MB after processing 3 crates due to ONNX Runtime sessions being retained indefinitely in global singleton",
          "rootCause": "FastEmbed v0.7.1 TextEmbedding global singleton retains ONNX Runtime sessions indefinitely without proper cleanup",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/ingest.py"],
          "codeExample": "# Configure ONNX Runtime environment variables:\nos.environ['ONNXRUNTIME_ENABLE_CPU_MEM_ARENA'] = '0'\nos.environ['ORT_DISABLE_ALL_OPTIMIZATION'] = '1'\n\n# Add cleanup function:\ndef cleanup_embedding_model():\n    global _embedding_model\n    if _embedding_model is not None:\n        del _embedding_model\n        _embedding_model = None\n        import gc\n        gc.collect()",
          "prevention": "Implement proper model lifecycle management and configure ONNX Runtime memory settings"
        },
        {
          "error": "MCP tool parameter validation failure - Input validation error: '50' is not valid under any of the given schemas",
          "solution": "Successfully fixed by adding anyOf patterns to both include_unchanged and max_results fields in compare_versions tool schema (app.py lines 685-705) and corresponding field validators with mode='before' in CompareVersionsRequest model (models.py lines 1347-1365). Use anyOf: [{'type': 'integer'}, {'type': 'string'}] for numeric parameters and anyOf: [{'type': 'boolean'}, {'type': 'string'}] for boolean parameters to handle string parameters from MCP clients.",
          "context": "MCP clients often send numeric and boolean parameters as strings, causing validation failures when schemas are too restrictive. All MCP tools need anyOf patterns for parameter flexibility.",
          "rootCause": "Missing anyOf schema patterns in MCP manifest prevents JSON Schema validation from passing when MCP clients send string parameters",
          "status": "RESOLVED",
          "dateEncountered": "2025-08-09",
          "dateResolved": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "implementation": "For any MCP tool parameters that need to accept both native types and strings, use: 'anyOf': [{'type': 'boolean'}, {'type': 'string'}] in schema and @field_validator with mode='before' in model. This pattern is now consistently applied across all 9 MCP tools.",
          "codeExample": "# In get_mcp_manifest() for all numeric/boolean parameters:\n'k': {\n    'type': 'integer',\n    'description': 'Number of results to return',\n    'anyOf': [{'type': 'integer'}, {'type': 'string'}]\n},\n'enabled': {\n    'type': 'boolean',\n    'description': 'Enable feature flag',\n    'anyOf': [{'type': 'boolean'}, {'type': 'string'}]\n}\n\n# In models.py with corresponding field validator:\n@field_validator('max_results', mode='before')\n@classmethod\ndef validate_max_results(cls, v):\n    if v is None:\n        return None\n    if isinstance(v, int):\n        return v\n    if isinstance(v, str):\n        try:\n            return int(v.strip())\n        except ValueError:\n            raise ValueError(f'max_results must be integer. Got: {repr(v)[:100]}')\n    raise ValueError(f'max_results must be integer. Got: {type(v).__name__}')",
          "prevention": "Ensure all MCP tools with numeric or boolean parameters have anyOf patterns in manifest schema to handle string conversion"
        },
        {
          "error": "Search result duplicates from re-ingestion - Multiple entries with same item_path in results",
          "solution": "Add UNIQUE constraint/index on item_path column in embeddings table and use INSERT OR REPLACE pattern to handle duplicates gracefully.",
          "context": "embeddings table lacks UNIQUE constraint on item_path, causing duplicate entries when crates are re-ingested",
          "rootCause": "Database schema allows duplicate item_path entries without constraints",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"],
          "codeExample": "# Add UNIQUE constraint:\nCREATE UNIQUE INDEX idx_embeddings_item_path ON embeddings(item_path);\n\n# Use INSERT OR REPLACE pattern:\nINSERT OR REPLACE INTO embeddings (item_path, content, embeddings_vec, ...)\nVALUES (?, ?, ?, ...);\n\n# Alternative UPSERT pattern:\nINSERT INTO embeddings (item_path, content, embeddings_vec, ...)\nVALUES (?, ?, ?, ...)\nON CONFLICT(item_path) DO UPDATE SET\n    content = excluded.content,\n    embeddings_vec = excluded.embeddings_vec;",
          "prevention": "Design database schema with appropriate UNIQUE constraints from the beginning and use INSERT OR REPLACE for idempotent operations"
        },
        {
          "error": "UNIQUE constraint failed: embeddings.item_path",
          "solution": "Added in-batch deduplication using a seen_paths set to skip duplicates during ingestion before database insertion",
          "context": "Duplicate item_paths in rustdoc JSON data (up to 50% duplicates) caused constraint violations during batch insertion",
          "rootCause": "rustdoc JSON contains duplicate items with identical paths, causing UNIQUE constraint failures when inserting into embeddings table",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"],
          "codeExample": "seen_paths = set()\nfor item in items:\n    if item['path'] in seen_paths:\n        continue  # Skip duplicate\n    seen_paths.add(item['path'])\n    # Process item",
          "prevention": "Always deduplicate data before database insertion when UNIQUE constraints exist",
          "performanceImpact": "Deduplication reduces ingestion from 2806 to 1231 unique items for serde (~50% reduction)"
        },
        {
          "error": "no such module: vec0",
          "solution": "Removed triggers, implemented manual synchronization in _store_batch function instead of relying on SQLite triggers",
          "context": "SQLite triggers execute in a context where sqlite-vec extension isn't loaded, causing 'no such module: vec0' errors",
          "rootCause": "SQLite triggers execute in a limited context where extensions like sqlite-vec aren't available, preventing vec0 module access",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"],
          "codeExample": "# Instead of triggers, use manual sync:\nasync def _store_batch(self, items):\n    # Insert into embeddings\n    await cursor.executemany('INSERT INTO embeddings ...', items)\n    # Manual sync to vec_embeddings\n    await cursor.execute('INSERT INTO vec_embeddings SELECT rowid, embeddings_vec FROM embeddings WHERE rowid NOT IN (SELECT rowid FROM vec_embeddings)')",
          "prevention": "Avoid using database triggers with extension-dependent operations; implement synchronization in application code instead",
          "lessonLearned": "Virtual table extensions require careful session management and aren't available in all SQLite execution contexts"
        },
        {
          "error": "UNIQUE constraint failed on vec_embeddings primary key",
          "solution": "Added AUTOINCREMENT to embeddings table PRIMARY KEY to prevent rowid reuse after DELETE operations",
          "context": "Rowid reuse after DELETE operations without AUTOINCREMENT caused primary key conflicts in vec_embeddings virtual table",
          "rootCause": "SQLite reuses rowid values after DELETE operations when AUTOINCREMENT is not specified, causing conflicts with vector embeddings that reference these rowids",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/database.py"],
          "codeExample": "CREATE TABLE embeddings (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,  -- Added AUTOINCREMENT\n    item_path TEXT NOT NULL UNIQUE,\n    -- other columns\n);",
          "prevention": "Use AUTOINCREMENT on PRIMARY KEY columns when foreign tables or virtual tables reference the rowid",
          "lessonLearned": "Virtual tables that reference rowids are sensitive to rowid reuse patterns"
        },
        {
          "error": "Pydantic RequestValidationError non-serializable fields in custom exception handlers",
          "solution": "When creating custom FastAPI exception handlers for RequestValidationError, convert error['input'] and error['ctx'] to strings before including in JSON responses. These fields may contain non-serializable objects like ValueError exceptions",
          "context": "Custom exception handlers for enhanced validation error messages",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["mcp_server.py", "src/docsrs_mcp/app.py"],
          "codeExample": "def format_error_detail(error: dict) -> str:\n    field = error.get('loc', [])[-1] if error.get('loc') else 'field'\n    value = str(error.get('input', 'unknown'))[:100]  # Convert to string\n    return f'{field} validation failed. Got: {value}'"
        },
        {
          "error": "Error message template inconsistency across validation handlers",
          "solution": "Use consistent template-based formatting with placeholders for field, value, constraints, and examples. Store templates in a dictionary for reusability and maintain consistent error message patterns across all validation functions",
          "context": "Standardizing validation error message formatting across the application",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/validation.py"],
          "codeExample": "ERROR_TEMPLATES = {\n    'invalid_type': '{field} must be {expected_type}. Got: {value}. Examples: {examples}',\n    'out_of_range': '{field} must be {constraint}. Got: {value}. Examples: {examples}'\n}",
          "prevention": "Define error message templates at module level for consistency and reusability"
        },
        {
          "error": "StartPreIngestionRequest force parameter validation fails when MCP clients send boolean as string",
          "rootCause": "Missing field_validator for force parameter - only concurrency and count had validators",
          "solution": "Added @field_validator('force', mode='before') following validate_include_unchanged pattern",
          "context": "MCP clients often send boolean values as strings ('true'/'false') which need conversion",
          "implementation": "Check isinstance(bool) first for fast path, then convert strings 'true', '1', 'yes', 'on' to True",
          "pattern": "All boolean fields in MCP request models require field_validator with mode='before'",
          "dateEncountered": "2025-01-11",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "codeExample": "@field_validator('force', mode='before')\n@classmethod\ndef validate_force(cls, v: Any) -> bool:\n    if isinstance(v, bool):\n        return v\n    if isinstance(v, str):\n        return v.lower() in ('true', '1', 'yes', 'on')\n    return False"
        },
        {
          "error": "MCP parameter string-to-type conversion compatibility issues",
          "solution": "All numeric and boolean parameters must support string-to-type conversion for MCP clients using coercion functions with mode='before' validators. Handle None values first, then check existing type, then attempt string conversion with try/catch",
          "context": "MCP protocol compatibility requires flexible parameter type handling",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "codeExample": "@field_validator('k', mode='before')\n@classmethod\ndef validate_k(cls, v):\n    if v is None:\n        return None\n    if isinstance(v, int):\n        return v\n    if isinstance(v, str):\n        try:\n            return int(v.strip())\n        except ValueError:\n            raise ValueError(f'k must be integer. Got: {repr(v)[:100]}. Examples: 5, \"10\"')\n    raise ValueError(f'k must be integer. Got: {type(v).__name__}')"
        },
        {
          "error": "Circular import issues with validation utilities in field validators",
          "solution": "When using validation utilities in Pydantic field validators, import them inside the validator method to avoid circular imports. This is especially important when validation utilities are defined in the same module hierarchy",
          "context": "Pydantic field validator implementation patterns",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/validation.py"],
          "codeExample": "@field_validator('query', mode='before')\n@classmethod\ndef validate_query(cls, v):\n    from .validation import validate_query_string  # Import inside method\n    return validate_query_string(v)"
        },
        {
          "error": "API endpoint testing with incorrect URL patterns",
          "solution": "Use `/mcp/tools/` prefix for API endpoint tests, not just the tool name. FastAPI mounts MCP tools under this path structure for proper routing",
          "context": "Testing MCP tool endpoints through FastAPI test client",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["tests/"],
          "codeExample": "response = client.post('/mcp/tools/search_items', json={...})  # Correct\n# NOT: response = client.post('/search_items', json={...})  # Incorrect"
        },
        {
          "error": "Performance degradation from repeated template compilation",
          "solution": "Precompile error message templates and regex patterns at module level for better performance. Store compiled patterns in module-level constants rather than compiling them on each validation call",
          "context": "Optimizing validation error message generation performance",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/validation.py"],
          "codeExample": "import re\n\n# Module level - compiled once\nMODULE_PATH_PATTERN = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]*(::[a-zA-Z_][a-zA-Z0-9_]*)*$')\nERROR_TEMPLATES = {\n    'invalid_path': 'Invalid module path format. Got: {value}. Examples: \"std::collections\", \"serde::de\"'\n}\n\ndef validate_module_path(value: str) -> str:\n    if not MODULE_PATH_PATTERN.match(value):\n        raise ValueError(ERROR_TEMPLATES['invalid_path'].format(value=repr(value)[:100]))\n    return value"
        },
        {
          "error": "AttributeError: 'NoneType' object has no attribute 'lower' in version_diff.py line 416",
          "context": "Processing item type mapping in _map_item_type method during version comparison operations",
          "rootCause": "_map_item_type method attempted to call .lower() on None values returned from data structure lookups, causing AttributeError when item_type is None",
          "solution": "Add defensive None check before string operations, return default ItemKind.FUNCTION for None values",
          "implementation": [
            "Add explicit None validation before calling .lower() method",
            "Return sensible default (ItemKind.FUNCTION) when item_type is None",
            "Ensure all string method calls are protected with None checks"
          ],
          "prevention": "Always validate potentially None values before calling methods, even when dict.get() has a default value - the default might still be None in some cases",
          "testingCommand": "curl -X POST http://localhost:8000/mcp/tools/compare_versions -H 'Content-Type: application/json' -d '{\"crate_name\": \"serde\", \"version_a\": \"1.0.0\", \"version_b\": \"1.1.0\"}'",
          "lessonLearned": "dict.get() with a default value doesn't guarantee non-None results - the stored value itself might be None, requiring additional validation",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/version_diff.py"],
          "affectedLines": ["version_diff.py:416"],
          "codeExample": "# Before (causes AttributeError):\ndef _map_item_type(self, item_type):\n    return ITEM_KIND_MAP.get(item_type, ItemKind.FUNCTION).lower()  # Fails if item_type is None\n\n# After (handles None values correctly):\ndef _map_item_type(self, item_type):\n    if item_type is None:\n        return ItemKind.FUNCTION\n    return ITEM_KIND_MAP.get(item_type, ItemKind.FUNCTION)",
          "pattern": "Defensive None validation before method calls on potentially None values"
        },
        {
          "error": "Stdlib documentation limited to 15-16 items fallback",
          "rootCause": "Rustdoc JSON not available on docs.rs for stdlib crates (by design). System architecture assumes docs.rs availability for all crates. Fallback mechanism was emergency measure, not designed solution",
          "context": "Users query stdlib items (std::vec::Vec, core::option::Option, etc.) and only get minimal fallback documentation instead of full docs",
          "symptoms": [
            "Queries for stdlib items return minimal documentation",
            "Only 15-16 predefined items available per stdlib crate",
            "No guidance provided on how to get complete stdlib documentation"
          ],
          "solution": "Expanded fallback to 62 items (std), 68 items (core), 43 items (alloc). Added comprehensive tutorial message with rust-docs-json setup instructions",
          "implementation": [
            "Modified ingest.py stdlib_items dictionary with comprehensive item coverage",
            "Enhanced warning message with detailed tutorial at ingest.py:2641",
            "Shows alternative documentation sources and setup instructions",
            "Provides rust-docs-json component installation guide for complete stdlib docs"
          ],
          "researchFindings": {
            "localJsonComponent": "rust-docs-json component available on nightly: 'rustup component add --toolchain nightly rust-docs-json'",
            "localLocation": "Component provides complete stdlib JSON documentation locally in ~/.rustup/toolchains/*/share/doc/rust/json/",
            "manualGeneration": "Manual generation possible via Rust repo: 'python x.py doc library -- --output-format=json'",
            "alternativeSource": "Complete stdlib documentation available through local JSON generation"
          },
          "futureSolution": {
            "architecture": "DocumentationSource abstraction to support multiple doc sources",
            "capability": "Local JSON ingestion capability",
            "routing": "Intelligent source routing with quality-based selection",
            "benefit": "Eliminates root cause of docs.rs dependency for stdlib"
          },
          "testing": "Verified expanded items accessible via API, tutorial displays correctly",
          "pattern": "Graceful degradation with enhanced user guidance when external sources are unavailable",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"],
          "affectedLines": ["ingest.py:2641"],
          "codeExample": "# Expanded stdlib_items dictionary with comprehensive coverage\nstdlib_items = {\n    'std': 62,  # Previously 15-16, now includes Vec, HashMap, Result, etc.\n    'core': 68,  # Expanded core types and traits\n    'alloc': 43  # Memory allocation types\n}\n\n# Enhanced warning with tutorial when stdlib fallback triggered\nif is_stdlib_crate(crate_name):\n    logger.warning(f\"Stdlib documentation limited to fallback items. For complete stdlib docs, install: 'rustup component add --toolchain nightly rust-docs-json'\")\n    # Show coverage limitation and alternatives\n    logger.info(f\"Current fallback provides {len(fallback_items)} items. Local JSON provides complete coverage.\")"
        },
        {
          "error": "MCP Schema anyOf Pattern Missing for Numeric Parameters",
          "rootCause": "MCP tools were rejecting integer values for numeric parameters due to missing anyOf patterns in the JSON schema. MCP clients may send numeric values as integers or strings.",
          "solution": "Add anyOf pattern with both integer and string types for numeric parameters in MCP manifest schema definitions to handle both integer and string inputs from different MCP clients.",
          "context": "MCP tool parameter validation failing on numeric inputs that should accept both integer and string representations",
          "implementation": [
            "Added anyOf pattern with integer and string types in MCP manifest",
            "Maintained minimum and maximum validation constraints",
            "Applied to concurrency parameter in ingest_cargo_file tool"
          ],
          "lesson": "MCP clients may serialize numeric parameters differently - always use anyOf patterns to accept both integer and string types for numeric parameters",
          "pattern": "Use anyOf pattern for numeric parameters: {'anyOf': [{'type': 'integer'}, {'type': 'string'}], 'minimum': min_val, 'maximum': max_val}",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["app.py"],
          "codeExample": "\"concurrency\": {\n    \"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"string\"}],\n    \"minimum\": 1,\n    \"maximum\": 10,\n    \"description\": \"Number of concurrent requests for dependency resolution\"\n}",
          "debuggingTechnique": "Test MCP tools with both integer and string values to verify schema accepts both formats"
        },
        {
          "error": "Case-Sensitive File Path Validation Rejection",
          "rootCause": "File path validation was rejecting lowercase 'cargo.toml' when expecting 'Cargo.toml' due to exact case-sensitive string matching against hardcoded patterns.",
          "solution": "Use case-insensitive comparison for configuration file names by converting to lowercase before comparison to support different naming conventions across platforms.",
          "context": "Cross-platform file validation where different systems may use different case conventions for configuration files",
          "implementation": [
            "Changed from exact case match to case-insensitive comparison",
            "Applied to both Cargo.toml and Cargo.lock validation",
            "Updated validation in multiple modules where file path checking occurs"
          ],
          "lesson": "Configuration file validation should be case-insensitive to support cross-platform compatibility and different naming conventions",
          "pattern": "Always use .lower() comparison for configuration file validation: path.name.lower() in ['cargo.toml', 'cargo.lock']",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["models.py", "cargo.py"],
          "affectedLines": ["models.py:1289", "cargo.py:396-399"],
          "codeExample": "# Before (case-sensitive):\nif path.name not in [\"Cargo.toml\", \"Cargo.lock\"]:\n    raise ValueError(\"Invalid file\")\n\n# After (case-insensitive):\nif path.name.lower() not in [\"cargo.toml\", \"cargo.lock\"]:\n    raise ValueError(\"Invalid file\")",
          "debuggingTechnique": "Test with various case combinations to identify validation failures and ensure cross-platform compatibility"
        },
        {
          "error": "Health Endpoint Missing Progress Information",
          "rootCause": "Health endpoints were not exposing ingestion progress information despite the data being tracked internally in _pre_ingestion_worker.crate_progress.",
          "solution": "Access the existing crate_progress data from the pre-ingestion worker and expose it through health endpoint responses to provide real-time progress visibility.",
          "context": "Users need visibility into ingestion progress for large operations or when monitoring system status through health endpoints",
          "implementation": [
            "Added progress data extraction from _pre_ingestion_worker.crate_progress",
            "Exposed total, completed, failed, current, and percent fields",
            "Updated both health_check and pre_ingestion_health endpoints"
          ],
          "lesson": "Always expose progress information for long-running operations through health and status endpoints to improve user experience and monitoring capabilities",
          "pattern": "Extract progress from worker: worker.crate_progress for real-time status reporting",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["app.py"],
          "codeExample": "\"ingestion_progress\": {\n    \"total\": worker.crate_progress[\"total\"],\n    \"completed\": worker.crate_progress[\"completed\"],\n    \"failed\": worker.crate_progress[\"failed\"],\n    \"current\": worker.crate_progress[\"current\"],\n    \"percent\": worker.crate_progress[\"percent\"]\n}",
          "debuggingTechnique": "Monitor health endpoints during ingestion operations to verify progress reporting accuracy"
        },
        {
          "error": "Pre-Ingestion Control Issue with Misleading Health Status",
          "rootCause": "Pre-ingestion health endpoints showed misleading 'not_initialized' status when MCP mode could control it, causing confusion between disabled vs available states. MCP tools were constrained by CLI flag dependencies.",
          "solution": "Added force_start parameter to bypass CLI flag dependency, updated health messages to show 'available' with clear guidance, and implemented health check caching for performance.",
          "context": "MCP mode requires independent control of features regardless of CLI flags, and health messages should guide users to available actions",
          "implementation": [
            "Added force_start parameter to startPreIngestion tool to bypass CLI flag checks",
            "Updated health status messages from 'not_initialized' to 'available' with actionable guidance",
            "Implemented health check response caching to meet <10ms performance targets",
            "Enabled MCP tools to control pre-ingestion independently of startup configuration"
          ],
          "lesson": "MCP tools should be able to control features independently of CLI flags. Health messages should clearly guide users to available actions rather than showing confusing status.",
          "pattern": "Use force_start or bypass parameters in MCP tools to enable independent feature control regardless of CLI configuration",
          "dateEncountered": "2025-08-18",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Add force_start parameter to bypass CLI dependencies\nif force_start or not args.pre_ingest:\n    # Enable feature regardless of CLI flags\n    return start_feature()\n\n# Update health messages for clarity\nreturn {'status': 'available', 'message': 'Use startPreIngestion to begin processing'}",
          "keyLearning": "Caching critical for meeting <10ms health check performance targets while providing real-time status information",
          "debuggingTechnique": "Test health endpoints both with and without CLI flags to verify independent MCP tool control"
        },
        {
          "error": "MCP Server Local Testing Difficulties",
          "rootCause": "Testing MCP servers locally can be challenging without proper REST mode setup, making it difficult to verify tool functionality and debug issues.",
          "solution": "Use REST mode for local testing of MCP servers, which provides HTTP endpoints that can be easily tested with curl or other HTTP clients.",
          "context": "Development and testing workflow for MCP server functionality requires easy local verification method",
          "implementation": [
            "Start server with --mode rest flag for HTTP endpoint access",
            "Use curl for direct tool testing with JSON payloads",
            "Background process management with nohup for clean testing"
          ],
          "lesson": "REST mode provides the easiest way to test MCP server functionality locally without MCP client complexity",
          "pattern": "Use REST mode for testing: uv run docsrs-mcp --mode rest, then test with curl",
          "dateEncountered": "2025-08-12",
          "relatedFiles": ["app.py"],
          "codeExample": "# Start server in REST mode\nuv run docsrs-mcp --mode rest\n\n# Test tool functionality\ncurl -X POST http://localhost:8000/tools/{tool_name} \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"params\": {\"parameter\": \"value\"}}'",
          "debuggingTechnique": "Use REST endpoints to isolate server-side issues from MCP client serialization or communication problems",
          "testingBestPractice": "Always verify MCP tools work correctly in REST mode before testing through MCP clients"
        },
        {
          "error": "Version Comparison Returns 0 Changes Due to Missing Data Ingestion",
          "rootCause": "The compare_versions command assumes versions are ingested when they may not be, leading to comparisons between empty datasets that always return 0 changes. ingest_crate() returns database paths without guaranteeing data presence.",
          "solution": "Add validation after ingest_crate to check for empty data. Implement automatic re-ingestion with validation and retry logic, or create a data availability service with proper contracts.",
          "context": "compare_versions tool produces misleading '0 changes' results when comparing versions that haven't been properly ingested",
          "lesson": "Always validate data presence after ingestion operations before proceeding with analysis. Empty databases should trigger errors, not silent processing.",
          "pattern": "Add data validation checkpoints: ingest → validate presence → process → return results",
          "dateEncountered": "2025-08-15",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py", "src/docsrs_mcp/ingest.py", "src/docsrs_mcp/database.py"],
          "codeExample": "# Testing command that reveals the issue:\ncurl -X POST http://localhost:8000/mcp/tools/compare_versions \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"crate_name\": \"serde\", \"version_a\": \"1.0.0\", \"version_b\": \"1.1.0\"}'",
          "debuggingTechnique": "Use REST mode to test version comparison directly and verify data presence in returned database paths before comparison",
          "solutionApproaches": [
            "Simple fix: Add validation after ingest_crate to check for empty data",
            "Comprehensive fix: Add automatic re-ingestion with validation and retry logic", 
            "Root cause fix: Create data availability service with proper ingestion contracts"
          ],
          "architecturalIssue": "Silent failure pattern - empty databases are processed normally instead of raising errors",
          "testingBestPractice": "Always verify both versions have actual data before running comparisons"
        },
        {
          "error": "Crate Name 'unwind' Error in MCP Mode",
          "rootCause": "All crates showing as 'unwind' when using MCP mode due to getCrateSummary tool missing from tools_to_fix dictionary in mcp_server.py schema override",
          "solution": "Add getCrateSummary to tools_to_fix dictionary in mcp_server.py to ensure proper schema override for Claude Code compatibility",
          "context": "MCP mode returning incorrect crate names, breaking crate identification and search functionality",
          "implementation": [
            "Added getCrateSummary to tools_to_fix dictionary alongside other MCP tools",
            "Ensured all MCP tools have proper schema overrides for Claude Code compatibility",
            "Verified tool parameter validation works correctly with schema override"
          ],
          "lesson": "Always include ALL MCP tools in schema override when supporting Claude Code - missing tools cause unexpected behavior",
          "pattern": "When adding new MCP tools, immediately add them to tools_to_fix for schema override compatibility",
          "dateEncountered": "2025-08-16",
          "relatedFiles": ["mcp_server.py"],
          "codeExample": "tools_to_fix = {\n    'searchItems': SearchItemsRequest,\n    'getCrateSummary': GetCrateSummaryRequest,  # Must include for proper schema override\n    'compareVersions': CompareVersionsRequest,\n    'startPreIngestion': StartPreIngestionRequest\n}",
          "debuggingTechnique": "Test all MCP tools in Claude Code to verify proper parameter handling and response formatting"
        },
        {
          "error": "Incomplete Ingestion Detection Failures",
          "rootCause": "Partial ingestion failures leave corrupted data that appears complete based on file existence checks, leading to inconsistent system state",
          "solution": "Implement ingestion_status tracking with checkpoint validation to explicitly track completion status rather than relying on file existence",
          "context": "Ingestion processes failing partway through leave databases in inconsistent state that passes basic existence checks",
          "implementation": [
            "Add ingestion_status field to track explicit completion state",
            "Implement checkpoint validation to verify data integrity",
            "Replace file existence checks with explicit completion tracking",
            "Add validation steps to verify ingestion completeness before marking as done"
          ],
          "lesson": "File existence != completion; need explicit completion tracking with validation checkpoints",
          "pattern": "Always track explicit completion status with validation rather than inferring from file presence",
          "dateEncountered": "2025-08-16",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/database.py"],
          "codeExample": "# Instead of:\nif os.path.exists(db_path):\n    return 'completed'\n\n# Use:\nif self.ingestion_status.get(crate_key) == 'completed' and self.validate_ingestion_checkpoint(db_path):\n    return 'completed'",
          "debuggingTechnique": "Check ingestion_status tracking and validate database integrity after partial failures"
        },
        {
          "error": "Pre-Ingestion 'not_initialized' Status Confusion",
          "rootCause": "Health endpoint shows 'not_initialized' when pre-ingestion is disabled by default, causing confusion between disabled vs not-started states",
          "solution": "Replace 'not_initialized' with 'available_not_started' and remove CLI flag dependency to distinguish between disabled and not-started states",
          "context": "Users see 'not_initialized' status and assume system is broken when pre-ingestion is simply not started",
          "implementation": [
            "Change status message from 'not_initialized' to 'available_not_started'",
            "Remove dependency on CLI flags for status determination",
            "Clarify status messages to distinguish between disabled, not-started, and initialized states",
            "Update health endpoint to provide clearer status information"
          ],
          "lesson": "Status messages must distinguish between disabled vs not-started states to avoid user confusion",
          "pattern": "Use explicit status messages that clearly indicate the current state and available actions",
          "dateEncountered": "2025-08-16",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "# Instead of:\nstatus = 'not_initialized' if not pre_ingest_enabled else 'running'\n\n# Use:\nstatus = 'available_not_started' if worker.status == 'idle' else worker.status",
          "debuggingTechnique": "Review health endpoint responses to ensure status messages are clear and actionable"
        },
        {
          "error": "Enhanced Fallback Ingestion Schema (COMPLETED)",
          "rootCause": "Tier 2/3 fallback ingestion produced incomplete schemas missing critical fields (parent_id, generic_params, trait_bounds) required for version comparison, causing MIN_ITEMS_THRESHOLD validation failures",
          "solution": "Implemented comprehensive fallback schema enhancement system with tier-aware validation and metadata synthesis",
          "context": "Crates ingested with fallback mechanisms failed version comparison due to insufficient data threshold checks and missing schema fields",
          "implementation": [
            "Added IngestionTier enum to track ingestion method (rustdoc_json, source_extraction, description_only)",
            "Created enhance_fallback_schema() function that synthesizes missing metadata fields from available information",
            "Added ingestion_tier column to database for tracking which method was used",
            "Implemented tier-aware MIN_ITEMS_THRESHOLD validation with different thresholds per tier",
            "Added is_fallback_tier() and get_tier_threshold() functions for tier-specific logic",
            "Updated error messages to be tier-aware, providing better context when fallback ingestion is used"
          ],
          "lesson": "Adaptive thresholds based on ingestion method prevent false failures and schema normalization through field synthesis improves compatibility",
          "pattern": "Track ingestion method in database to enable tier-aware validation logic with appropriate thresholds",
          "dateEncountered": "2025-08-16",
          "dateCompleted": "2025-08-18",
          "status": "RESOLVED",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/ingest.py", "src/docsrs_mcp/database.py", "src/docsrs_mcp/version_diff.py"],
          "codeExample": "class IngestionTier(Enum):\n    RUSTDOC_JSON = \"rustdoc_json\"\n    SOURCE_EXTRACTION = \"source_extraction\"\n    DESCRIPTION_ONLY = \"description_only\"\n\ndef enhance_fallback_schema(items: List[dict], tier: IngestionTier) -> List[dict]:\n    \"\"\"Synthesize missing metadata fields for fallback ingestion\"\"\"\n    for item in items:\n        if 'parent_id' not in item:\n            item['parent_id'] = None\n        if 'generic_params' not in item:\n            item['generic_params'] = []\n        if 'trait_bounds' not in item:\n            item['trait_bounds'] = []\n    return items\n\ndef get_tier_threshold(tier: IngestionTier) -> int:\n    \"\"\"Get appropriate MIN_ITEMS_THRESHOLD based on ingestion tier\"\"\"\n    base_threshold = 10\n    tier_multipliers = {\n        IngestionTier.RUSTDOC_JSON: 1.0,\n        IngestionTier.SOURCE_EXTRACTION: 0.5,\n        IngestionTier.DESCRIPTION_ONLY: 0.2\n    }\n    return int(base_threshold * tier_multipliers[tier])",
          "debuggingTechnique": "Check ingestion_tier column in database and verify enhanced schema fields are present before running version comparisons",
          "performanceImpact": "Version comparison now works for 80%+ of fallback-ingested crates with appropriate thresholds and clear error messages",
          "lessonsLearned": [
            "Clear tier-specific error messages help users understand limitations",
            "Tracking ingestion method in database enables better debugging",
            "Schema field synthesis from available information improves compatibility",
            "Different validation thresholds needed for different ingestion quality levels"
          ]
        },
        {
          "error": "Auto-Ingestion Pattern Consistency Issues",
          "rootCause": "Some tools may not trigger auto-ingestion consistently, causing unexpected failures when accessing non-ingested crates",
          "solution": "Audit all tools and standardize ingest_crate() pattern to ensure consistent auto-ingestion behavior across all entry points",
          "context": "Inconsistent auto-ingestion patterns across different tools lead to unexpected failures for non-ingested crates",
          "implementation": [
            "Audit all MCP tools for consistent ingest_crate() pattern usage",
            "Standardize auto-ingestion logic across all entry points",
            "Add validation to ensure ingestion is attempted before data access",
            "Document and enforce the auto-ingestion pattern for all new tools"
          ],
          "lesson": "Critical patterns must be enforced across all entry points - inconsistency leads to unreliable behavior",
          "pattern": "Always call ingest_crate() before attempting data access in any tool or endpoint",
          "dateEncountered": "2025-08-16",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Standard pattern for all tools:\nasync def tool_function(crate_name: str, ...):\n    # Always attempt ingestion first\n    db_path = await ingest_crate(crate_name, session)\n    if not db_path:\n        raise ValueError(f'Failed to ingest crate: {crate_name}')\n    \n    # Proceed with tool logic\n    return process_data(db_path, ...)",
          "debuggingTechnique": "Review all tool implementations to verify consistent auto-ingestion pattern usage"
        },
        {
          "error": "Variable Shadowing Bug - All Crates Returning 'unwind' as Name",
          "rootCause": "Variable shadowing in get_crate_summary function at line 1103 of app.py. The crate name variable was being overwritten by module names in a loop processing crate modules. The last module processed ('unwind') would replace the actual crate name.",
          "solution": "Rename loop variable from 'name' to 'module_name' to prevent shadowing the crate name variable when unpacking tuples in the module processing loop.",
          "context": "All crates returning 'unwind' as their name in MCP mode, breaking crate identification and search functionality",
          "implementation": [
            "Changed loop variable from 'name' to 'module_name' in tuple unpacking",
            "Preserved original crate name variable throughout function execution",
            "Fixed variable scope isolation to prevent unintended overwrites"
          ],
          "lesson": "Always check for variable shadowing in loops, especially when unpacking tuples. Loop variables can accidentally overwrite outer scope variables if named identically.",
          "pattern": "Use descriptive, scope-specific variable names in loops to avoid shadowing: use 'module_name' instead of 'name' when processing modules",
          "dateEncountered": "2025-08-18",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "affectedLines": ["app.py:1103"],
          "codeExample": "# Before (variable shadowing):\nfor name, path in modules:\n    # 'name' overwrites the crate name variable\n    \n# After (no shadowing):\nfor module_name, path in modules:\n    # 'module_name' doesn't conflict with crate name",
          "debuggingTechnique": "Test with multiple different crates to verify each returns its correct name rather than the last processed module name",
          "additionalNotes": [
            "The hardcoded crate_id = 1 was also fixed but was NOT the cause of this specific bug",
            "Old cached databases may need to be deleted and re-ingested if they contain corrupted data from previous buggy runs",
            "This bug only affected MCP mode because the variable shadowing occurred in the get_crate_summary function"
          ],
          "warningFlags": "Variable shadowing, loop variable naming, tuple unpacking scope issues"
        },
        {
          "error": "MCP Parameter Validation Issues - String vs Numeric Type Coercion",
          "rootCause": "MCP clients send all parameters as strings, even for numeric fields. Pydantic schema validation fails when expecting proper numeric types despite anyOf patterns.",
          "solution": "Use string-only schemas with Pydantic field validators using mode='before' for type coercion. Replace anyOf patterns with explicit string types and robust validators.",
          "context": "MCP tools rejecting valid numeric parameters sent as strings by Claude Code and other MCP clients",
          "lesson": "MCP protocol inherently sends string parameters - design schemas and validators accordingly rather than fighting the protocol",
          "pattern": "String-only schemas + mode='before' validators with coercion functions for all numeric parameters",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py", "src/docsrs_mcp/validators.py"],
          "codeExample": "# Preferred approach - string schema with validator\nclass SearchItemsRequest(BaseModel):\n    k: str = Field(description=\"Number of results to return\")\n    \n    @field_validator('k', mode='before')\n    @classmethod\n    def coerce_k(cls, v):\n        return coerce_to_int_with_bounds(v, min_val=1, max_val=100)\n\n# Avoid - anyOf patterns that MCP clients struggle with\n# k: Union[int, str] = Field(...)",
          "debuggingTechnique": "Test with curl in --mode rest to isolate MCP client vs server validation issues"
        },
        {
          "error": "Stdlib Documentation Unavailable on docs.rs",
          "rootCause": "docs.rs does not host stdlib JSON documentation by design. Three-tier ingestion system needed to handle stdlib crates differently from regular crates.",
          "solution": "Implement three-tier ingestion: docs.rs (primary) → rust-lang.org (stdlib fallback) → local rustup (complete stdlib). Add specialized stdlib detection and handling.",
          "context": "Users querying stdlib items (std::vec::Vec, core::option::Option) receive minimal fallback instead of complete documentation",
          "lesson": "External dependencies have architectural limitations - always design fallback strategies for critical functionality",
          "pattern": "Multi-tier ingestion with source-specific handling based on crate type detection",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/stdlib_handling.py"],
          "codeExample": "# Three-tier ingestion pattern\nasync def ingest_crate(crate_name: str, version: str):\n    if is_stdlib_crate(crate_name):\n        # Tier 3: Try local rustup first for complete docs\n        if json_data := await try_local_rustup_json(crate_name):\n            return await process_complete_stdlib_json(json_data)\n        # Tier 2: Fallback to rust-lang.org\n        elif json_data := await try_rust_lang_org(crate_name, version):\n            return await process_stdlib_json(json_data)\n        # Tier 1: Minimal fallback items\n        else:\n            return create_stdlib_fallback_documentation(crate_name)\n    else:\n        # Regular crates use docs.rs\n        return await ingest_from_docs_rs(crate_name, version)",
          "debuggingTechnique": "Use 'rustup component add --toolchain nightly rust-docs-json' to verify complete local stdlib documentation availability"
        },
        {
          "error": "Module Tree Pollution with Dependencies",
          "rootCause": "Module tree includes dependency crates alongside actual crate modules, making navigation confusing. No distinction between owned modules and external dependencies.",
          "solution": "Add is_dependency flag to modules table during ingestion. Filter dependency modules from tree navigation while preserving them for cross-crate search.",
          "context": "Users browsing module trees see overwhelming number of dependency modules mixed with actual crate structure",
          "lesson": "User-facing views should be filtered and curated - raw data structure is not always appropriate for presentation",
          "pattern": "Database schema enhancement with presentation-layer filtering based on user intent",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Enhanced module ingestion with dependency detection\nCREATE TABLE modules (\n    id INTEGER PRIMARY KEY,\n    name TEXT NOT NULL,\n    path TEXT NOT NULL,\n    crate_id INTEGER,\n    is_dependency BOOLEAN DEFAULT FALSE,  -- New field\n    FOREIGN KEY (crate_id) REFERENCES crates (id)\n);\n\n# Krate-based filtering during ingestion\ndef process_rustdoc_json(json_data: dict, target_crate: str):\n    for item_id, item in json_data.get('index', {}).items():\n        is_dep = item.get('crate_id', 0) != 0  # Non-zero = dependency\n        # Store dependency info for filtering\n        modules.append({\n            'name': item['name'],\n            'is_dependency': is_dep\n        })",
          "debuggingTechnique": "Compare crate_id field in rustdoc JSON index - 0 indicates owned items, non-zero indicates dependencies"
        },
        {
          "error": "Search System Limitations - No Regex, Cross-Crate, or Stability Filtering",
          "rootCause": "Current search only supports basic text matching within single crates. Missing advanced filtering capabilities that users expect from documentation systems.",
          "solution": "Implement parallel search federation with new search modes: regex patterns, cross-crate scope, stability filters (stable/unstable/deprecated), and result ranking.",
          "context": "Users cannot perform advanced searches like 'all Vec implementations across ecosystem' or 'stable APIs only'",
          "lesson": "Search is a core user experience - invest in comprehensive search capabilities early in development",
          "pattern": "Federated search architecture with mode-specific processors and result aggregation",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/search.py", "src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Enhanced search with multiple modes\nclass SearchMode(Enum):\n    TEXT = \"text\"           # Basic text search (current)\n    REGEX = \"regex\"         # Regex pattern matching\n    CROSS_CRATE = \"cross\"   # Search across all crates\n    STABILITY = \"stable\"    # Filter by stability level\n\nasync def federated_search(query: str, mode: SearchMode, filters: dict):\n    tasks = []\n    if mode == SearchMode.CROSS_CRATE:\n        # Parallel search across all ingested crates\n        for crate in await get_all_crates():\n            tasks.append(search_in_crate(query, crate.name, filters))\n    elif mode == SearchMode.REGEX:\n        # Compile regex and search with pattern matching\n        pattern = re.compile(query)\n        tasks.append(regex_search(pattern, filters))\n    \n    results = await asyncio.gather(*tasks)\n    return rank_and_deduplicate(results)",
          "debuggingTechnique": "Profile search performance with concurrent.futures for optimal parallelization strategy"
        },
        {
          "error": "Missing Type System Navigation - No Trait Implementation Discovery",
          "rootCause": "Database schema lacks trait relationship storage. Users cannot discover what types implement specific traits or find trait bounds.",
          "solution": "Extract and store trait relationships during ingestion. Add new database tables for traits, implementations, and bounds with dedicated MCP tools for navigation.",
          "context": "Users asking 'what implements Iterator?' or 'what traits does Vec implement?' cannot get answers",
          "lesson": "Type system relationships are core to Rust documentation - must be first-class citizens in data model",
          "pattern": "Relationship-first database design with specialized navigation tools for type system exploration",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/trait_analysis.py"],
          "codeExample": "# New database tables for trait relationships\nCREATE TABLE traits (\n    id INTEGER PRIMARY KEY,\n    name TEXT NOT NULL,\n    path TEXT NOT NULL,\n    crate_id INTEGER,\n    FOREIGN KEY (crate_id) REFERENCES crates (id)\n);\n\nCREATE TABLE trait_implementations (\n    id INTEGER PRIMARY KEY,\n    trait_id INTEGER,\n    implementor_type TEXT NOT NULL,\n    implementor_crate_id INTEGER,\n    is_conditional BOOLEAN DEFAULT FALSE,\n    where_clause TEXT,\n    FOREIGN KEY (trait_id) REFERENCES traits (id)\n);\n\n# MCP tool for trait discovery\nasync def find_trait_implementations(trait_name: str) -> List[dict]:\n    \"\"\"Find all types that implement a specific trait\"\"\"\n    query = '''\n        SELECT ti.implementor_type, c.name as crate_name, ti.where_clause\n        FROM trait_implementations ti\n        JOIN traits t ON ti.trait_id = t.id\n        JOIN crates c ON ti.implementor_crate_id = c.id\n        WHERE t.name = ?\n    '''\n    return await db.fetch_all(query, [trait_name])",
          "debuggingTechnique": "Parse rustdoc JSON 'impls' section to extract trait implementation relationships"
        },
        {
          "error": "Version Comparison NoneType Errors in semantic_changes",
          "rootCause": "Version comparison logic assumes non-None values but encounters None when version data is missing or malformed. Insufficient defensive programming.",
          "solution": "Add comprehensive None checking with safe string operations. Use pattern: (value or '').method() for safe operations on potentially None strings.",
          "context": "Version comparison crashes when analyzing crates with missing or incomplete version metadata",
          "lesson": "Always assume external data can be None or malformed - defensive programming is essential for data processing systems",
          "pattern": "Defensive None checking with safe fallback operations for all external data",
          "dateEncountered": "2025-08-19",
          "relatedFiles": ["src/docsrs_mcp/version_analysis.py", "src/docsrs_mcp/semantic_changes.py"],
          "codeExample": "# Defensive version comparison\ndef safe_version_compare(version_a: Optional[str], version_b: Optional[str]) -> int:\n    \"\"\"Compare versions with None safety\"\"\"\n    # Safe string operations with fallback\n    clean_a = (version_a or '').strip()\n    clean_b = (version_b or '').strip()\n    \n    # Handle empty/None cases\n    if not clean_a and not clean_b:\n        return 0\n    elif not clean_a:\n        return -1\n    elif not clean_b:\n        return 1\n    \n    # Actual comparison logic\n    return semver.compare(clean_a, clean_b)\n\n# Apply pattern throughout codebase\ndef extract_version_info(metadata: dict) -> dict:\n    return {\n        'version': (metadata.get('version') or '').strip(),\n        'yanked': bool(metadata.get('yanked')),\n        'created_at': (metadata.get('created_at') or '').strip()\n    }",
          "debuggingTechnique": "Add logging for None values encountered during version processing to identify data quality issues"
        },
        {
          "error": "SQL Error: no such column: m.description",
          "rootCause": "The modules table schema doesn't have a description column, but SQL query tried to SELECT m.description causing column not found error",
          "solution": "Remove m.description from SELECT statement and use empty string for CrateModule description field when the column doesn't exist in the database schema",
          "context": "app.py refactoring - SQL queries mismatched with actual database schema",
          "lesson": "Always verify database schema matches SQL queries, especially after refactoring or schema migrations",
          "pattern": "Query only columns that exist in the database schema, use appropriate default values for model fields",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py"],
          "codeExample": "# Instead of:\nSELECT m.id, m.name, m.description FROM modules m\n# Use:\nSELECT m.id, m.name FROM modules m\n# And in Python:\nCrateModule(id=row[0], name=row[1], description=\"\")",
          "debuggingTechnique": "Check database schema with PRAGMA table_info(table_name) to verify column existence before writing SQL queries"
        },
        {
          "error": "Pydantic ValidationError: inputSchema field name mismatch",
          "rootCause": "MCPTool model expected snake_case 'input_schema' but code used camelCase 'inputSchema' causing Pydantic validation to fail",
          "solution": "Replace all occurrences of 'inputSchema' with 'input_schema' to match Pydantic field naming conventions",
          "context": "app.py refactoring - MCP manifest endpoint field naming inconsistency",
          "lesson": "Pydantic models use snake_case by default, ensure field names in code match the model definition exactly",
          "pattern": "Always use snake_case for Pydantic model field names unless explicitly configured otherwise with Field aliases",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# Instead of:\nMCPTool(name='tool', inputSchema=schema)\n# Use:\nMCPTool(name='tool', input_schema=schema)",
          "debuggingTechnique": "Check Pydantic model definitions for exact field names and ensure code matches the model schema"
        },
        {
          "error": "Pydantic ValidationError: MCPResource mimeType field doesn't exist",
          "rootCause": "MCPResource model doesn't have a mimeType field but code tried to set it during resource instantiation",
          "solution": "Remove mimeType field assignment from MCPResource instantiation since it's not part of the model schema",
          "context": "app.py refactoring - MCP resources endpoint trying to set non-existent model fields",
          "lesson": "Check Pydantic model definitions to ensure only valid fields are set during object instantiation",
          "pattern": "Only assign fields that exist in the Pydantic model schema, remove any extra fields that cause validation errors",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# Instead of:\nMCPResource(uri=uri, name=name, mimeType=\"application/json\")\n# Use:\nMCPResource(uri=uri, name=name)",
          "debuggingTechnique": "Review Pydantic model definitions to identify valid fields before instantiating objects"
        },
        {
          "error": "ImportError: list_versions function not found after refactoring",
          "rootCause": "list_versions was imported from wrong module (endpoints.py) after refactoring moved it to endpoints_tools.py to maintain file size limits",
          "solution": "Update import statement to import list_versions from endpoints_tools.py instead of endpoints.py",
          "context": "app.py refactoring - function moved between modules to keep files under 500 LOC limit",
          "lesson": "When refactoring code into multiple files, update all import statements to reference the new module locations",
          "pattern": "Maintain a clear mapping of which functions belong in which modules during refactoring, update imports systematically",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py", "src/docsrs_mcp/endpoints_tools.py"],
          "codeExample": "# Instead of:\nfrom .endpoints import list_versions\n# Use:\nfrom .endpoints_tools import list_versions",
          "debuggingTechnique": "After refactoring, test all import statements and run the application to catch import errors early"
        },
        {
          "error": "Config AttributeError: HIDE_EMPTY_MODULES doesn't exist",
          "rootCause": "Code referenced config.HIDE_EMPTY_MODULES which doesn't exist in the configuration module, causing AttributeError",
          "solution": "Remove the filtering logic that depends on non-existent config variable or add TODO comment for future implementation",
          "context": "app.py refactoring - code referenced configuration that was never implemented",
          "lesson": "Verify all configuration variables exist before referencing them in code, especially during refactoring",
          "pattern": "Check configuration module for all referenced variables, implement missing config or remove dependent code",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py", "src/docsrs_mcp/config.py"],
          "codeExample": "# Instead of:\nif not config.HIDE_EMPTY_MODULES:\n    # filter logic\n# Use:\n# TODO: Implement HIDE_EMPTY_MODULES config option\n# if not config.HIDE_EMPTY_MODULES:\n#     # filter logic",
          "debuggingTechnique": "Review config module to verify all referenced configuration variables are properly defined"
        },
        {
          "error": "CrateModule Model Field Mismatch",
          "rootCause": "CrateModule model expected different fields (path, parent_id, depth) than what was being provided (description, has_children) from database query results",
          "solution": "Query the correct columns from database that match CrateModule model fields exactly, ensure database schema and model are synchronized",
          "context": "app.py refactoring - database query results didn't match Pydantic model field expectations",
          "lesson": "Database queries must return columns that exactly match the Pydantic model fields being instantiated",
          "pattern": "Always align database query column selection with target Pydantic model field requirements",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/endpoints.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# CrateModule model expects:\n# CrateModule(id=..., name=..., path=..., parent_id=..., depth=...)\n# Ensure query returns matching columns:\nSELECT m.id, m.name, m.path, m.parent_id, m.depth FROM modules m",
          "debuggingTechnique": "Compare database query column names with Pydantic model field names to ensure exact alignment"
        }
      ]
    },
    "commonErrors": {
      "description": "Frequently encountered errors and their solutions",
      "entries": [
        {
          "error": "SQLite threading error with aiosqlite",
          "context": "Database operations in async context",
          "solution": "Use aiosqlite properly with await db.execute() instead of synchronous calls",
          "prevention": "Always use await with aiosqlite operations, never mix sync/async database calls",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "no such function: vec_distance",
          "context": "Vector similarity search queries in SQLite with vss extension",
          "solution": "Use MATCH operator instead of vec_distance() function for vector searches",
          "prevention": "Reference sqlite-vss documentation for correct query syntax",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "LIMIT or 'k = ?' constraint required",
          "context": "Vector similarity search queries without proper constraints",
          "solution": "Add 'AND k = ?' parameter to MATCH queries to specify result count",
          "prevention": "Always include k parameter in vector search queries",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "MCP parameter validation with anyOf schema pattern conflicts",
          "context": "MCP clients send strings for numeric parameters but schema validation fails",
          "solution": "Use anyOf: [{'type': 'integer'}, {'type': 'string'}] patterns in MCP manifest with Pydantic field validators using mode='before' for type coercion",
          "prevention": "Always include anyOf patterns for parameters that MCP clients might send as strings",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "error": "ijson expects binary input but sometimes receives string",
          "context": "JSON streaming during ingestion pipeline processing",
          "solution": "Use io.BytesIO(json_content.encode()) instead of io.StringIO for binary input",
          "prevention": "Always ensure ijson receives bytes input by encoding strings first",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "AsyncMock context managers require proper setup",
          "context": "Testing async context managers with unittest.mock",
          "solution": "Set up __aenter__ and __aexit__ methods explicitly on AsyncMock objects",
          "prevention": "Use MagicMock for session objects or properly configure AsyncMock context manager methods",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["tests/test_ingest.py"]
        },
        {
          "error": "pytest-asyncio fixture compatibility issues in 0.23.x versions",
          "context": "Testing async functions and fixtures with pytest-asyncio",
          "solution": "Downgrade to pytest-asyncio==0.21.1 for stable async fixture support",
          "prevention": "Pin pytest-asyncio to 0.21.1 in development dependencies and avoid 0.23.x until issues are resolved",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["pyproject.toml", "tests/"],
          "command": "uv add --dev pytest-asyncio==0.21.1"
        },
        {
          "error": "prometheus-client memory leak warnings in high-cardinality scenarios",
          "context": "Prometheus metrics collection with many unique label combinations",
          "solution": "Monitor memory usage and implement label cardinality limits, use histogram buckets instead of individual metrics where possible",
          "prevention": "Design metric labels carefully to avoid high cardinality, regularly review metric memory footprint in production",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["monitoring/metrics.py"],
          "references": ["Prometheus best practices documentation on cardinality"]
        },
        {
          "error": "fetch_current_stable_version session parameter missing",
          "context": "HTTP session not properly passed to version fetching function",
          "solution": "Always pass aiohttp session parameter to fetch_current_stable_version function calls",
          "prevention": "Use type hints and validate session parameter in function signature",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/version_utils.py"],
          "pattern": "fetch_current_stable_version(session=session)"
        },
        {
          "error": "hypothesis module not found for property-based testing",
          "context": "Running property-based tests that require hypothesis library",
          "solution": "Install hypothesis for property-based testing support",
          "prevention": "Include hypothesis in development dependencies for comprehensive testing",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["tests/", "pyproject.toml"],
          "command": "uv add --dev hypothesis"
        },
        {
          "error": "Variable scope in exception handlers",
          "context": "Referencing variables in exception blocks that may not be defined",
          "solution": "Avoid referencing variables that may not be defined in exception scope",
          "prevention": "Initialize variables before try blocks or check existence in except blocks",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Version diff implementation performance considerations",
          "context": "Implementing semantic comparison between crate versions for Rust coding agents",
          "solution": "Use hash-based comparison instead of AST parsing for performance. Implement LRU caching for repeated version comparisons. Stream processing to stay under 1GB memory usage.",
          "implementation": [
            "VersionDiffEngine with LRU caching achieves sub-500ms cached comparisons",
            "Hash-based change detection provides efficient modification identification",
            "RustBreakingChangeDetector follows Rust RFC 1105 semver guidelines",
            "compare_versions MCP tool endpoint accessible via both REST and MCP modes"
          ],
          "lessons": {
            "performance": "Hash-based comparison significantly faster than AST parsing for large documentation sets",
            "caching": "LRU cache essential for practical response times - 10-30s initial vs <500ms cached",
            "memory": "Streaming processing keeps memory under 1GB even for large crate comparisons",
            "semver_compliance": "Following Rust RFC 1105 guidelines crucial for accurate breaking change detection"
          },
          "testValidation": "Successfully tested with serde, once_cell, anyhow - covers major version transitions, API evolution, and error handling pattern changes",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/version_diff.py", "src/docsrs_mcp/app.py"],
          "codeExample": "class VersionDiffEngine:\n    def __init__(self, cache_size: int = 100):\n        self._cache = LRUCache(maxsize=cache_size)\n        self._detector = RustBreakingChangeDetector()\n    \n    async def compare_versions(self, crate_name: str, version_a: str, version_b: str):\n        cache_key = f'{crate_name}:{version_a}:{version_b}'\n        if cache_key in self._cache:\n            return self._cache[cache_key]\n        \n        # Hash-based comparison implementation\n        result = await self._perform_comparison(crate_name, version_a, version_b)\n        self._cache[cache_key] = result\n        return result",
          "pattern": "Version diff system architecture",
          "prevention": "Design for performance from the start - caching, streaming, and efficient algorithms essential for production use"
        },
        {
          "error": "cursor.lastrowid returns None when using executemany() in aiosqlite",
          "context": "Batch insert operations needing to track inserted row IDs",
          "solution": "Use 'SELECT last_insert_rowid()' after executemany() to get the last inserted rowid",
          "prevention": "Never rely on cursor.lastrowid with executemany(), always use SQL query for rowid",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "SQLite parameter limit exceeded in batch operations",
          "context": "Inserting large batches with multiple parameters per row",
          "solution": "SQLite parameter limit is 999, not 1000 - calculate batch size as 999 // params_per_row",
          "prevention": "Always account for SQLite's 999 parameter limit when batching operations",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Loop variable overwriting in extract_code_examples",
          "context": "Variable name collision causing data loss in rustdoc parsing",
          "solution": "Use different variable names (cleaned_example vs example) to avoid overwriting loop variables",
          "prevention": "Always use distinct variable names in nested loops and data processing to prevent accidental overwrites",
          "dateEncountered": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Type matching too broad in rustdoc parsing",
          "context": "String matching 'type' in 'unknown_type' causing incorrect type categorization",
          "solution": "Use exact key matching in type_map dictionary instead of substring matching",
          "prevention": "Use precise key matching instead of substring matching for dictionary lookups to avoid false positives",
          "dateEncountered": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Path objects in test mocks must use MagicMock with proper spec",
          "context": "Testing functions that check Path.exists() method with mocked Path objects",
          "solution": "Use MagicMock(spec=Path) and configure exists() method explicitly: mock_path = MagicMock(spec=Path); mock_path.exists.return_value = True",
          "prevention": "Always use spec parameter with MagicMock when mocking complex objects to ensure method availability",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["tests/test_ingest.py", "tests/test_app.py"]
        },
        {
          "error": "sqlite-vec MATCH operator requires explicit k parameter",
          "context": "Vector similarity search queries failing with 'A LIMIT or 'k = ?' constraint is required' error",
          "solution": "Always include explicit k parameter in MATCH queries: 'SELECT * FROM vec_table WHERE vec_column MATCH ? AND k = ?'",
          "prevention": "Never use MATCH operator without k parameter - sqlite-vec requires this constraint for all vector searches",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/database.py"]
        },
        {
          "error": "See-also suggestions showing duplicate results from original search",
          "context": "Implementing see-also functionality that excludes original search results to avoid redundancy",
          "solution": "Filter out original search results from suggestions using path exclusion: exclude_paths = {result.path for result in original_results}",
          "prevention": "Always exclude original search results when generating related suggestions to provide truly additional value",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "Similarity score calculation incorrect for sqlite-vec cosine distance",
          "context": "Converting sqlite-vec distance to similarity score for ranking purposes",
          "solution": "Use similarity = 1.0 - distance formula for cosine distance in sqlite-vec to get proper similarity scores (higher = more similar)",
          "prevention": "Remember sqlite-vec returns distance (lower = more similar), convert to similarity (higher = more similar) with 1.0 - distance",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "Test mocks for ingest_crate returning string instead of Path object",
          "context": "Testing ingest_crate function where db_path.exists() is called but mock returns string",
          "solution": "Mock ingest_crate to return Path object with exists() method: mock_result = MagicMock(spec=Path); mock_result.exists.return_value = True; return mock_result",
          "prevention": "When mocking functions that return Path objects, ensure the mock returns objects with proper Path methods configured",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["tests/test_app.py"]
        },
        {
          "error": "Path resolution not finding items without explicit path mapping",
          "context": "Items without path mappings in rustdoc JSON causing lookup failures",
          "solution": "Implement fallback to item name when no path mapping exists in rustdoc data",
          "prevention": "Always provide fallback mechanisms when working with optional or incomplete data structures",
          "dateEncountered": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Mock aiohttp sessions need proper async context manager setup",
          "context": "Testing async HTTP operations with unittest.mock.AsyncMock",
          "solution": "Mock aiohttp sessions need __aenter__ and __aexit__ methods configured for async context manager usage",
          "prevention": "Always configure AsyncMock context manager methods when testing async sessions or use MagicMock for session objects",
          "dateEncountered": "2025-08-06",
          "relatedFiles": ["tests/test_ingest.py"]
        },
        {
          "error": "Rust version fetch failures break stdlib detection",
          "context": "Network issues or API failures when fetching current Rust version for stdlib crate filtering",
          "solution": "Always provide fallback version when fetching Rust version fails, use hardcoded recent version as default",
          "prevention": "Implement graceful degradation with fallback values for external API dependencies",
          "dateEncountered": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Rustdoc JSON URL pattern redirecting unexpectedly",
          "context": "Initial URL pattern /crate/{crate}/latest was redirecting to different endpoints",
          "solution": "Use new docs.rs API pattern /crate/{crate-name}/{version}/json for direct access",
          "prevention": "Always use version-specific URLs for docs.rs API to avoid redirect overhead",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Zstd compression not detected in HTTP responses",
          "context": "JSON responses were compressed but compression detection was failing",
          "solution": "Check magic bytes (0x28, 0xb5, 0x2f, 0xfd) to detect zstd compression instead of relying on headers",
          "prevention": "Always check magic bytes for compression detection as headers may be unreliable",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Module extraction receiving strings instead of dictionaries",
          "context": "build_module_hierarchy was receiving string paths instead of full path_info dictionaries",
          "solution": "Store full path_info dict in paths_data for hierarchy building instead of just path strings",
          "prevention": "Always preserve full data structures when building hierarchies to maintain context information",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Item kind field not directly available in rustdoc index",
          "context": "Kind field was not found directly in rustdoc JSON index items",
          "solution": "Extract kind from inner field as single-key dictionary instead of direct access",
          "prevention": "Always inspect rustdoc JSON structure carefully as fields may be nested unexpectedly",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Module names empty in hierarchy extraction",
          "context": "Module names were showing as empty in the extracted hierarchy structure",
          "solution": "Module name is last element of path array, not a separate name field",
          "prevention": "Understand rustdoc JSON path structure where item names are derived from path arrays",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "NameError: name 'Optional' is not defined",
          "context": "Code example extraction implementation missing Optional type import",
          "solution": "Added Optional to typing imports: 'from typing import Any, Optional'",
          "prevention": "Always import all required typing components when adding type hints",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "no such column: crate_version",
          "context": "Database schema missing crate_version column during code example queries",
          "solution": "Extract version from database filename pattern (e.g., '1.0.219.db' → '1.0.219')",
          "prevention": "Extract crate version from database file path when schema doesn't include version column",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/app.py"]
        },
        {
          "error": "no such function: vec_distance_L2",
          "context": "sqlite-vec extension not loaded before vector similarity queries",
          "solution": "Load extension before queries: await db.enable_load_extension(True); await db.execute(f'SELECT load_extension(\'{sqlite_vec.loadable_path()}\')'); await db.enable_load_extension(False)",
          "prevention": "Always load sqlite-vec extension before performing any vector operations",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/app.py"]
        },
        {
          "error": "'str' object has no attribute 'get'",
          "context": "Backward compatibility issue with old list format vs new JSON format for code examples",
          "solution": "Handle both old list format and new JSON format: if isinstance(examples_data, list) and all(isinstance(e, str) for e in examples_data): examples_data = [{'code': e, 'language': 'rust', 'detected': False} for e in examples_data]",
          "prevention": "Always implement backward compatibility checks when changing data formats",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "searchExamples character fragmentation - returns individual characters instead of code blocks",
          "context": "ingest.py:761 and app.py:614-620 - for loop iterates over string as characters when examples_data is string type",
          "solution": "Add type check before iteration: if isinstance(examples_data, str): examples_data = [examples_data]; for example in examples_data: # Now safely iterate list. Applied in both generate_example_embeddings (ingest.py:758-762) and searchExamples (app.py:614-620)",
          "prevention": "Always validate data types before iteration, especially when data might be either string or list",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/app.py"],
          "priority": "CRITICAL",
          "symptoms": [
            "Code examples unusable",
            "Each character returned as separate example",
            "Affects all crates with code examples"
          ],
          "rootCause": "String iteration returns characters when examples_data is string type instead of list",
          "testingVerification": "Verified with live MCP calls to serde crate",
          "resolutionStatus": "FIXED - Applied type guard pattern in both locations, tested and verified working",
          "fixPattern": "if isinstance(examples_data, str): examples_data = [examples_data]",
          "impact": "Fixed critical bug that rendered searchExamples unusable, now returns complete code blocks instead of individual characters"
        },
        {
          "error": "MCP parameter validation - numeric parameters like k=2 rejected",
          "context": "MCP manifest missing anyOf patterns for type flexibility with numeric values",
          "solution": "Update MCP manifest with anyOf pattern: 'k': {'anyOf': [{'type': 'integer'}, {'type': 'string'}]} in src/docsrs_mcp/app.py:151-297",
          "prevention": "Always use anyOf patterns in MCP manifests for parameters that may arrive as different types from various clients",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "note": "Models.py has coercion but manifest needs updating for JSON Schema validation"
        },
        {
          "error": "Path resolution exactness - common paths like serde::Deserialize return 404",
          "context": "Users expect common module paths to work but need exact rustdoc paths",
          "solution": "Add PATH_ALIASES dictionary in fuzzy_resolver.py with mappings like 'serde::Deserialize': 'serde::de::Deserialize', 'tokio::spawn': 'tokio::task::spawn', 'Result': 'std::result::Result'",
          "prevention": "Maintain common path aliases for frequently accessed items to improve user experience",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "currentBehavior": "Provides fuzzy suggestions but requires exact module paths"
        },
        {
          "error": "crates.io API returns different structure than expected",
          "context": "API response validation during crate data fetching",
          "solution": "Added response validation to check for required fields and anomalies (zero downloads for popular crates)",
          "prevention": "Always validate API responses for expected structure and detect data anomalies before processing",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/api.py"]
        },
        {
          "error": "Concurrent cache file access can cause corruption",
          "context": "Multiple processes accessing cache files simultaneously",
          "solution": "Implemented file locking with FileLock and atomic writes (temp file + rename)",
          "prevention": "Use file locking mechanisms and atomic write operations for concurrent file access",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/cache.py"]
        },
        {
          "error": "API failures can cascade and overwhelm system",
          "context": "Multiple API failures causing system overload",
          "solution": "Circuit breaker pattern with 5-minute cooldown after 3 failures",
          "prevention": "Implement circuit breaker patterns to prevent cascading failures and system overload",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/api.py"]
        },
        {
          "error": "Search filtering excluding function-level items",
          "context": "Overly restrictive crate_pattern and module_pattern filters in database search queries",
          "solution": "Review filter logic in database.py lines 487-491 to ensure function-level items are not excluded by restrictive path pattern matching",
          "prevention": "Test search queries against diverse item types including functions, methods, and traits to ensure inclusive filtering",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/database.py"]
        },
        {
          "error": "sqlite-vec requires explicit k parameter in WHERE clauses",
          "context": "Vector similarity queries failing when using only LIMIT without k constraint",
          "solution": "Always use 'WHERE vector_column MATCH ? AND k = N' instead of relying on LIMIT clause for sqlite-vec queries",
          "prevention": "Remember sqlite-vec requires explicit k constraint in WHERE clause, not just LIMIT in query",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/app.py"]
        },
        {
          "error": "AttributeError: 'FixtureDef' object has no attribute 'unittest' with pytest 8.4.1 and pytest-asyncio 0.21.1",
          "context": "Running async tests during re-export auto-discovery implementation",
          "solution": "Upgrade to pytest-asyncio 1.1.0 which has Python 3.13 support and resolves compatibility issues",
          "prevention": "Always check version compatibility matrix when encountering fixture-related errors, especially after Python version upgrades",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["pyproject.toml", "tests/test_*.py"],
          "upgradeCommand": "uv add --dev pytest-asyncio>=1.1.0",
          "versionMatrix": {
            "pytest": ">=8.0.0",
            "pytest-asyncio": ">=1.1.0",
            "python": ">=3.10"
          }
        },
        {
          "error": "AttributeError when calling .lower() on joined None values in semantic_changes lists",
          "context": "Processing semantic_changes lists that contain None values with operations like .lower() or string methods",
          "rootCause": "The semantic_changes list can contain None values but the code was attempting to call .lower() on these None values after joining, causing AttributeError",
          "solution": "Use list comprehension with 'is not None' filtering before join operations and string method calls",
          "implementation": [
            "Replace pattern: ' '.join(semantic_changes).lower() with ' '.join(x for x in semantic_changes if x is not None).lower()",
            "For any() expressions: any('keyword' in s.lower() for s in semantic_changes if s is not None)",
            "Always use explicit 'is not None' checks when processing lists that might contain None values"
          ],
          "pattern": "List comprehension with 'is not None' filtering before string operations",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/version_diff.py", "src/docsrs_mcp/change_analyzer.py"],
          "affectedLines": ["version_diff.py:369", "version_diff.py:384", "change_analyzer.py:300", "change_analyzer.py:310", "change_analyzer.py:316"],
          "codeExample": "# Before (causes AttributeError):\n' '.join(semantic_changes).lower()\nany('breaking' in s.lower() for s in semantic_changes)\n\n# After (handles None values correctly):\n' '.join(x for x in semantic_changes if x is not None).lower()\nany('breaking' in s.lower() for s in semantic_changes if s is not None)",
          "performanceImpact": "Minimal - list comprehensions with 'is not None' are 40% faster than filter() according to research",
          "bestPractice": "Always use explicit 'is not None' checks when processing lists that might contain None values, following PEP 8 guidelines",
          "testingNotes": "Verified with test script that the pattern correctly handles None values, all-None lists, and empty lists"
        },
        {
          "error": "Large models.py File Requiring Modular Organization",
          "rootCause": "Single models.py file grew to 1750+ lines containing diverse model categories (base, MCP, requests, responses, version diff) causing maintainability issues and slower development iteration",
          "solution": "Split models.py into focused modules: base.py (60 LOC), mcp.py (130 LOC), requests.py (950 LOC), responses.py (365 LOC), version_diff.py (245 LOC) with careful circular import prevention and compatibility preservation",
          "context": "Codebase organization and maintainability improvement through strategic file splitting",
          "implementation": [
            "Use TYPE_CHECKING blocks to prevent circular imports between model modules",
            "Preserve all field_validator mode='before' patterns for MCP client compatibility",
            "Re-export all models in __init__.py to maintain backward compatibility for existing imports",
            "Keep ConfigDict(extra='forbid') in all models for security validation",
            "Preserve forward reference resolution (ModuleTreeNode.model_rebuild()) for recursive models",
            "Let Ruff handle most import and formatting fixes automatically during refactoring"
          ],
          "lesson": "Strategic file organization improves development velocity and code clarity. Split when single files exceed ~1000 LOC or contain distinct functional groups",
          "pattern": "Module splitting: identify cohesive groups → prevent circular imports with TYPE_CHECKING → preserve backward compatibility with __init__.py re-exports → validate all functionality",
          "dateEncountered": "2025-08-23",
          "relatedFiles": ["src/docsrs_mcp/models/__init__.py", "src/docsrs_mcp/models/base.py", "src/docsrs_mcp/models/mcp.py", "src/docsrs_mcp/models/requests.py", "src/docsrs_mcp/models/responses.py", "src/docsrs_mcp/models/version_diff.py"],
          "codeExample": "# In each module - prevent circular imports\nfrom __future__ import annotations\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from .other_module import SomeModel\n\n# In __init__.py - maintain backward compatibility\nfrom .base import BaseModel, ConfigModel\nfrom .requests import SearchItemsRequest, CompareVersionsRequest\nfrom .responses import SearchResponse, VersionCompareResponse\nfrom .mcp import MCPRequest, MCPResponse\nfrom .version_diff import ItemChange, VersionDiff\n\n__all__ = ['BaseModel', 'ConfigModel', 'SearchItemsRequest', ...]\n\n# Preserve validators with mode='before' for MCP compatibility\n@field_validator('force', mode='before')\n@classmethod\ndef validate_force(cls, v: Any) -> bool:\n    if isinstance(v, bool):\n        return v\n    if isinstance(v, str):\n        return v.lower() in ('true', '1', 'yes', 'on')\n    return False",
          "debuggingTechnique": "After splitting, run all tests to catch validation error message format changes and verify MCP tool compatibility",
          "postSplitValidation": [
            "Verify all imports resolve correctly across modules", 
            "Test MCP tools still accept string parameters with proper type coercion",
            "Check that recursive model rebuilding still works for tree structures",
            "Confirm security validation (extra='forbid') preserved in all models",
            "Validate that Ruff fixes only handled formatting, not functional changes"
          ],
          "organizationalBenefit": "Improved code navigation, faster compilation, clearer separation of concerns, easier testing of model subgroups"
        }
      ]
    },
    "performanceIssues": {
      "description": "Performance bottlenecks and optimization strategies",
      "performance_insights": [
        "ONNX Runtime offline optimization reduces startup by 60-80%",
        "Use ORT_ENABLE_EXTENDED for balanced performance without layout overhead",
        "Model quantization (fp32 to int8) reduces memory by 4x",
        "Request-scoped dependency caching in FastAPI avoids recomputation",
        "Adaptive batch sizing based on memory monitoring prevents OOM",
        "Token optimization: analyze baseline metrics first, use soft validation over hard errors"
      ],
      "entries": [
        {
          "issue": "ONNX Runtime memory accumulation in FastEmbed",
          "impact": "Memory usage grows from 176MB to 1661MB after processing 3 crates",
          "solution": "Configure ONNX with sess_options.enable_cpu_mem_arena = False and implement explicit model lifecycle management",
          "optimizationStrategy": "Use lighter embedding models like all-MiniLM-L6-v2, implement explicit cleanup with del session and gc.collect()",
          "dateIdentified": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/ingest.py"],
          "measuredImpact": "Memory leak of ~1.5GB over 3 crate ingestions"
        },
        {
          "error": "Model loading delay on first request",
          "context": "Embedding model initialization causes slow first response",
          "solution": "Model loading happens on first embedding generation - expected behavior",
          "prevention": "Consider warming up models during server startup for production",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Large download and decompression memory usage",
          "context": "Ingesting large crates with streaming downloads and decompression",
          "solution": "Use streaming with reasonable limits: DOWNLOAD_CHUNK_SIZE=8KB, MAX_DOWNLOAD_SIZE=100MB, MAX_DECOMPRESSED_SIZE=100MB",
          "prevention": "Set appropriate memory limits and use chunked processing for large files",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "issue": "Example embeddings memory usage and search performance",
          "solution": "Implemented streaming generation with batch size 16 for CPU, hash-based deduplication to reduce storage by ~30%, and dedicated sqlite-vec tables for faster search",
          "context": "When generating embeddings for code examples, memory can accumulate quickly with FastEmbed. Using generators and explicit cleanup between batches keeps memory under control.",
          "dateDiscovered": "2025-08-07",
          "relatedFiles": ["ingest.py", "database.py"],
          "metrics": {
            "memoryUsage": "421MB for tokio crate",
            "searchLatency": "150-360ms warm, 1.4s cold (model loading)",
            "deduplicationRate": "~30% reduction in stored embeddings"
          }
        },
        {
          "issue": "Vector search performance bottlenecks",
          "solution": "Initial queries slow until vectors cached, implement cache warming for popular crates",
          "context": "First-time vector searches experience significant latency due to model loading and cache population",
          "dateDiscovered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "issue": "Memory spikes with large crates",
          "solution": "Already using streaming + generators, monitor with psutil for proactive management",
          "context": "Large crates can cause memory spikes despite streaming implementation",
          "dateDiscovered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Memory usage approaching 1GB limit during pre-ingestion",
          "context": "High memory usage during concurrent crate processing",
          "solution": "Added adaptive concurrency that reduces workers when RSS > 900MB",
          "prevention": "Monitor RSS memory usage and implement adaptive concurrency limits",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Cold start latency for popular crates",
          "context": "Initial requests for popular crates take too long to respond",
          "solution": "Pre-ingestion with priority queue ensures most-downloaded crates processed first",
          "prevention": "Implement pre-ingestion strategies with priority-based processing",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "error": "Cache staleness during high traffic",
          "context": "Cached data becomes stale during high-traffic periods",
          "solution": "Stale-while-revalidate pattern serves cached data while refreshing in background",
          "prevention": "Implement stale-while-revalidate caching patterns for high-traffic scenarios",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/cache.py"]
        },
        {
          "issue": "Fuzzy path matching performance bottleneck",
          "solution": "Consider Nucleo library for 6x faster path-specific fuzzy matching compared to current RapidFuzz implementation",
          "context": "Path resolution and fuzzy matching can be optimized for better search performance",
          "dateDiscovered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"]
        },
        {
          "issue": "Vector-only search lacking keyword relevance",
          "solution": "Implement hybrid search combining vector similarity (60%) with BM25 keyword search (40%) for better balanced results",
          "context": "Pure vector similarity may miss exact keyword matches that users expect",
          "dateDiscovered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/database.py"]
        },
        {
          "issue": "rustdoc JSON contains ~50% duplicate items",
          "impact": "Unnecessary processing and storage overhead during ingestion",
          "discovery": "Analysis of rustdoc JSON reveals up to 50% duplicate item_path entries across different crates",
          "solution": "Implemented in-batch deduplication using seen_paths set to skip duplicate processing",
          "optimization": "Deduplication reduces ingestion from 2806 to 1231 unique items for serde (~50% reduction in processing and storage)",
          "dateDiscovered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"],
          "measuredImpact": "50% reduction in database insertions and embedding calculations"
        },
        {
          "issue": "Token optimization analysis of MCP tool tutorials",
          "discovery": "Current MCP tool tutorials were already well-optimized (all under 200 tokens)",
          "lesson": "Always analyze baseline metrics before optimization",
          "solution": "Truncate text to 100k chars before tokenization to prevent tiktoken stack overflow",
          "context": "Token efficiency optimization for MCP tools and documentation",
          "implementation": [
            "Use 5 chars per token as upper bound for validation",
            "Implement soft validation (warnings) rather than hard errors for token limits",
            "Create specific tests for token efficiency across all MCP tools"
          ],
          "optimizationStrategy": "Character limit approximation prevents expensive tokenization on oversized content while maintaining accurate token counts for normal content",
          "dateDiscovered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py", "tests/test_token_efficiency.py"],
          "measuredImpact": "Prevented stack overflow errors while maintaining token optimization accuracy",
          "preventionPattern": "Always establish baseline metrics before implementing optimization strategies"
        },
        {
          "issue": "FastEmbed Memory Leak (GitHub issue #222)",
          "rootCause": "Memory grows from 1.5GB to 16GB+ with variable text lengths due to known issue in FastEmbed library",
          "impact": "Severe memory consumption making batch processing infeasible for large datasets",
          "solution": "Truncate text to 100 characters before embedding to prevent memory leak escalation",
          "context": "Batch processing enhancements for ingestion pipeline optimization",
          "implementation": [
            "Text truncation before embedding: text[:100] for all embedding operations",
            "Added batch counting and process recycling after 50 batches to prevent accumulation",
            "Monitor memory growth patterns and implement adaptive batch sizing"
          ],
          "pattern": "Proactive memory management with text preprocessing and process lifecycle control",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/batch_processor.py"],
          "codeExample": "# Truncate before embedding to prevent memory leak\ntruncated_text = text[:100] if text else ''\nembedding = await embed_model.embed([truncated_text])\n\n# Process recycling after batch limit\nif batch_count >= 50:\n    # Recycle process to prevent memory accumulation\n    restart_process()",
          "references": ["https://github.com/qdrant/fastembed/issues/222"],
          "measuredImpact": "Memory usage stabilized under 2GB instead of growing to 16GB+"
        },
        {
          "issue": "SQLite Parameter Limit Exceeded",
          "rootCause": "SQLite has hard limit of 999 parameters in queries, exceeded during large batch operations",
          "impact": "Batch insert operations failing with 'too many parameters' error",
          "solution": "Implement parameter counting and sub-batching to respect 999 parameter limit",
          "context": "Database operations during batch processing implementation",
          "implementation": [
            "Calculate max batch size as: 999 // parameters_per_row",
            "Sub-batch large operations when parameter count approaches limit",
            "Dynamic batch size adjustment based on query parameter requirements",
            "Parameter counting validation before query execution"
          ],
          "pattern": "Respect database engine limits through dynamic batch sizing",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/batch_processor.py"],
          "codeExample": "def calculate_max_batch_size(params_per_row: int) -> int:\n    return min(999 // params_per_row, DEFAULT_BATCH_SIZE)\n\n# Sub-batch when necessary\nif len(batch) * params_per_row > 999:\n    for sub_batch in chunk_list(batch, calculate_max_batch_size(params_per_row)):\n        await execute_batch_insert(sub_batch)",
          "limitation": "Applies to all SQLite deployments - cannot be increased",
          "measuredImpact": "Eliminated parameter limit errors while maintaining batch performance"
        },
        {
          "issue": "Database Lock Conflicts Under Concurrent Access",
          "rootCause": "Multiple concurrent operations causing 'database is locked' errors due to lock escalation",
          "impact": "Transaction failures and data integrity issues during high-concurrency operations",
          "solution": "Implemented RetryableTransaction with exponential backoff and jitter",
          "context": "Concurrent database access patterns during batch processing",
          "implementation": [
            "RetryableTransaction class with configurable retry attempts and backoff",
            "Exponential backoff with jitter: base_delay * (2 ** attempt) + random(0, jitter)",
            "Use BEGIN IMMEDIATE for write operations to avoid lock escalation",
            "Lock timeout configuration and graceful degradation patterns"
          ],
          "pattern": "Robust transaction management with intelligent retry and lock avoidance",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/transactions.py"],
          "codeExample": "class RetryableTransaction:\n    async def __aenter__(self):\n        for attempt in range(self.max_retries):\n            try:\n                await self.conn.execute('BEGIN IMMEDIATE')\n                return self\n            except aiosqlite.OperationalError as e:\n                if 'database is locked' in str(e) and attempt < self.max_retries - 1:\n                    delay = self.base_delay * (2 ** attempt) + random.uniform(0, self.jitter)\n                    await asyncio.sleep(delay)\n                    continue\n                raise",
          "configuration": {
            "max_retries": 3,
            "base_delay": 0.1,
            "jitter": 0.05,
            "lock_timeout": "30s"
          },
          "measuredImpact": "Reduced lock conflicts by 95% and improved transaction success rate"
        },
        {
          "issue": "Memory Pressure Detection and Adaptive Batch Sizing",
          "rootCause": "Fixed batch sizes causing memory pressure and potential OOM conditions during large dataset processing",
          "impact": "Memory exhaustion leading to process termination and incomplete batch processing",
          "solution": "Implemented adaptive batch sizing with memory monitoring and trend analysis",
          "context": "Dynamic resource management for sustainable batch processing",
          "implementation": [
            "Memory threshold monitoring at 80% (warning) and 90% (critical) levels",
            "Adaptive batch size reduction when memory pressure detected",
            "Memory trend analysis to predict future usage and prevent OOM",
            "Process memory tracking with psutil for accurate RSS monitoring"
          ],
          "pattern": "Proactive memory management with predictive scaling",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/batch_processor.py", "src/docsrs_mcp/memory_monitor.py"],
          "codeExample": "class AdaptiveBatchProcessor:\n    def adjust_batch_size(self):\n        memory_percent = psutil.Process().memory_percent()\n        \n        if memory_percent > 90:  # Critical threshold\n            self.current_batch_size = max(1, self.current_batch_size // 4)\n        elif memory_percent > 80:  # Warning threshold\n            self.current_batch_size = max(1, self.current_batch_size // 2)\n        elif memory_percent < 60:  # Can increase\n            self.current_batch_size = min(self.max_batch_size, \n                                        int(self.current_batch_size * 1.2))",
          "thresholds": {
            "warning_threshold": "80%",
            "critical_threshold": "90%",
            "recovery_threshold": "60%",
            "min_batch_size": 1,
            "scaling_factors": {
              "critical_reduction": 0.25,
              "warning_reduction": 0.5,
              "recovery_increase": 1.2
            }
          },
          "considerations": [
            "Memory trend analysis helps predict future pressure before OOM occurs",
            "Minimum batch size of 1 ensures progress even under extreme memory pressure",
            "Recovery scaling is conservative to prevent memory pressure oscillation"
          ],
          "measuredImpact": "Prevented OOM conditions and maintained processing throughput under memory constraints"
        }
      ]
    },
    "integrationChallenges": {
      "description": "Issues with third-party services and libraries",
      "entries": [
        {
          "error": "SQLite extension loading issues",
          "context": "Loading sqlite-vss extension for vector operations",
          "solution": "Use SELECT load_extension() SQL command instead of direct Python extension loading",
          "prevention": "Always use SQL-based extension loading for better compatibility",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/database.py"]
        },
        {
          "issue": "Cannot query vec_embeddings directly in sqlite3 CLI",
          "context": "Attempting to query vector tables from sqlite3 command line interface fails with extension errors",
          "rootCause": "sqlite-vec extension must be explicitly loaded in CLI sessions before accessing vec0 virtual tables",
          "workaround": "Load sqlite-vec extension first: .load /path/to/vec0 OR query through application that already has extension loaded",
          "lessonLearned": "Virtual table extensions require careful session management and aren't automatically available in all SQLite contexts",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/database.py"],
          "bestPractice": "Always verify extension is loaded before vec0 operations, whether in CLI or application context"
        }
      ]
    },
    "deploymentIssues": {
      "description": "Problems encountered during deployment",
      "entries": [
        {
          "error": "Server startup hanging terminal",
          "context": "Running development server blocks terminal session",
          "solution": "Use nohup and background process with PID tracking: 'nohup uv run docsrs-mcp > server.log 2>&1 & echo $!'",
          "prevention": "Always run servers in background for development, save PID for cleanup",
          "dateEncountered": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "Windows executable issues in CI/CD",
          "context": "Windows builds failing due to executable path resolution",
          "solution": "Use 'uv run' pattern consistently across all platforms instead of direct executable calls",
          "prevention": "Standardize on 'uv run' commands in CI workflows to ensure cross-platform compatibility",
          "dateEncountered": "2025-08-08",
          "relatedFiles": [".github/workflows/", "scripts/"]
        },
        {
          "error": "PyPI authentication token issues",
          "context": "Publishing to PyPI fails with authentication errors",
          "solution": "Use UV_PUBLISH_TOKEN environment variable, not UV_PUBLISH_PASSWORD for PyPI authentication",
          "prevention": "Always use UV_PUBLISH_TOKEN for PyPI publishing in CI/CD pipelines",
          "dateEncountered": "2025-08-08",
          "relatedFiles": [".github/workflows/publish.yml"]
        },
        {
          "error": "Background server testing hangs CI runners",
          "context": "CI/CD runners hang when testing servers without proper process management",
          "solution": "Use nohup with PID capture pattern: 'nohup uv run server > server.log 2>&1 & echo $!' and kill with captured PID",
          "prevention": "Never use bare background processes in CI, always capture PID for cleanup",
          "dateEncountered": "2025-08-08",
          "relatedFiles": [".github/workflows/test.yml", "scripts/test_server.sh"]
        },
        {
          "error": "UV cache deserialization errors between versions",
          "context": "Different UV versions in CI causing cache corruption and build failures",
          "solution": "Pin UV version in CI workflows or clear cache when UV version changes",
          "prevention": "Use consistent UV versions across all CI jobs and environments",
          "dateEncountered": "2025-08-08",
          "relatedFiles": [".github/workflows/", "uv.lock"]
        },
        {
          "error": "PyPI build compatibility issues",
          "context": "Package builds failing on PyPI due to source file inclusion",
          "solution": "Use 'uv build --no-sources' for PyPI-compatible builds that exclude source files",
          "prevention": "Test builds with --no-sources flag before publishing to ensure PyPI compatibility",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["pyproject.toml", ".github/workflows/publish.yml"]
        },
        {
          "error": "Self-hosted runner cache inefficiencies",
          "context": "Self-hosted runners using different cache strategies than GitHub-hosted runners",
          "solution": "Implement runner-specific cache strategies: local disk cache for self-hosted, GitHub Actions cache for hosted",
          "prevention": "Configure cache strategies based on runner type to optimize build performance",
          "dateEncountered": "2025-08-08",
          "relatedFiles": [".github/workflows/", "scripts/setup_cache.sh"]
        }
      ]
    },
    "mcpImplementation": {
      "description": "MCP server implementation patterns and solutions",
      "entries": [
        {
          "error": "STDIO corruption in MCP mode",
          "context": "Logging output interferes with MCP protocol communication",
          "solution": "Configure logging to stderr only in MCP mode to prevent STDIO corruption",
          "prevention": "Always configure logging handlers appropriately for MCP vs REST modes",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "FastAPI to MCP protocol conversion",
          "context": "Converting REST endpoints to MCP protocol automatically",
          "solution": "Use FastMCP.from_fastapi() to automatically convert REST endpoints to MCP protocol",
          "prevention": "Leverage FastMCP for seamless protocol conversion instead of manual implementation",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "MCP server testing difficulties",
          "context": "Testing MCP server requires background process management",
          "solution": "MCP server can be tested in background with nohup, kill with captured PID",
          "prevention": "Use proper background process management for MCP server testing",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "Claude Desktop MCP configuration",
          "context": "Configuring MCP server in Claude Desktop client",
          "solution": "Use simplified args: [\"docsrs-mcp\"] since MCP is now the default mode",
          "prevention": "MCP mode is default, no need for explicit --mode mcp flag in Claude Desktop config",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["claude_desktop_config.json"]
        },
        {
          "error": "MCP server debugging challenges",
          "context": "Debugging issues with MCP protocol communication",
          "solution": "Check server logs in stderr, use --mode rest flag for easier debugging",
          "prevention": "Use REST mode (--mode rest) for development debugging since MCP is now default",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "error": "MCP parameter type coercion: string numerics not converted to integers",
          "context": "MCP clients (Claude Code) send k parameter as string \"3\" instead of integer 3, causing Pydantic validation error",
          "solution": "Add Pydantic field validator with mode='before' to convert string numbers to integers: @field_validator('k', mode='before')",
          "prevention": "FastMCP's automatic type conversion has known issues with string-to-int conversion. Always use Pydantic field validators with mode='before' for numeric parameters that MCP clients might send as strings",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "error": "Pydantic field_validator decorator ordering with @classmethod",
          "context": "MCP parameter validation with custom field validators using @classmethod decorator",
          "solution": "Always use @field_validator BEFORE @classmethod decorator, not after. The correct order is: @field_validator('field_name', mode='before') followed by @classmethod",
          "prevention": "Remember decorator execution order: decorators are applied bottom-up, so @field_validator must come first to properly wrap the classmethod",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "resolutionStatus": "Critical decorator ordering pattern established for all future MCP parameter validators"
        },
        {
          "error": "MCP tool schema validation preventing field validator execution",
          "context": "searchItems tool fails with validation error when k parameter provided as string '5' by MCP clients. Error: \"'5' is not valid under any of the given schemas\"",
          "solution": "Update MCP manifest schema to use anyOf pattern accepting both string and integer types: 'anyOf': [{'type': 'integer'}, {'type': 'string'}]. This allows JSON Schema validation to pass so Pydantic field validator can perform type coercion",
          "prevention": "When FastMCP tools need to accept parameters that might come as different types, use anyOf schema pattern to handle double validation. MCP JSON Schema validates before Pydantic field validators can run, creating conflicts between type constraints and coercion logic",
          "dateEncountered": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "resolutionStatus": "Fixed and tested on 2025-08-05. Solution confirmed working with both integer and string k parameters"
        },
        {
          "error": "MCP client string parameter conversion validation patterns",
          "context": "Implementing robust parameter validation for MCP clients that send numeric values as strings",
          "solution": "Use comprehensive validation pattern: 1) Check for None first (return None or default), 2) Check if already correct type (return as-is), 3) Handle string conversion with try/catch, 4) Provide helpful error messages with examples, 5) Handle integer-to-float conversion for float fields",
          "prevention": "Always implement the full validation pattern for any numeric parameter that might arrive as a string from MCP clients. Test both native type and string conversion paths",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "resolutionStatus": "Comprehensive validation pattern established and tested with various input types"
        },
        {
          "error": "ValidationError vs ValueError in custom Pydantic validators",
          "context": "Testing MCP parameter validation with different error types from built-in vs custom validators",
          "solution": "Built-in Pydantic constraints raise ValidationError for direct type violations, while custom field_validator methods raise ValueError for string conversion failures. Test accordingly: expect ValidationError for direct types, ValueError for string conversion",
          "prevention": "Understand the distinction between Pydantic's built-in validation (ValidationError) and custom validator errors (ValueError) when writing tests",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["tests/test_app.py", "src/docsrs_mcp/models.py"],
          "resolutionStatus": "Error type patterns documented and test cases updated accordingly"
        },
        {
          "error": "Float string conversion error message patterns",
          "context": "Testing float parameter validation with invalid string inputs",
          "solution": "Use 'could not convert' in error message checks instead of 'invalid literal' for float string conversion failures. Python's float() function uses different error messages than int()",
          "prevention": "When testing string-to-float conversion errors, use appropriate error message patterns specific to float conversion",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["tests/test_app.py", "src/docsrs_mcp/models.py"],
          "resolutionStatus": "Float conversion error patterns identified and test assertions updated"
        },
        {
          "error": "MemoryMonitor import missing in fallback extraction sections",
          "context": "When implementing three-tier fallback system, MemoryMonitor imports were missing from fallback sections causing import errors during source extraction",
          "solution": "Add 'from memory_monitor import MemoryMonitor' import to all fallback extraction modules and ensure it's properly initialized in the source extractor context",
          "prevention": "Always verify all required imports are present in fallback code paths, especially when reusing patterns from main ingestion pipeline",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "extractors/source_extractor.py"],
          "pattern": "Import all dependencies required by fallback extraction logic",
          "implementation": "Ensure MemoryMonitor is imported and available in all extraction contexts for consistent memory management across tiers"
        },
        {
          "solution": "Three-tier fallback extraction system",
          "context": "Comprehensive documentation coverage using multiple extraction sources with intelligent fallback logic",
          "implementation": {
            "tier1": {
              "source": "Rustdoc JSON from docs.rs",
              "trigger": "Primary extraction method",
              "coverage": "~10-15% of crates",
              "quality": "Highest - structured JSON with complete metadata"
            },
            "tier2": {
              "source": "Source code extraction from crates.io CDN",
              "trigger": "RustdocVersionNotFoundError or parsing failure",
              "cdn_url": "https://static.crates.io/crates/{name}/{name}-{version}.crate",
              "rate_limits": "None - CDN has no rate limiting restrictions",
              "coverage": "80%+ of crates",
              "quality": "Medium-high with regex-based extraction",
              "enhanced_features": {
                "macro_extraction": "EnhancedMacroExtractor class with comprehensive pattern matching",
                "patterns": ["macro_rules!", "#[proc_macro]", "#[proc_macro_derive]", "#[proc_macro_attribute]"],
                "fragment_specifiers": ["expr", "ident", "pat", "ty", "stmt", "block", "item", "meta", "tt", "vis", "literal", "path"],
                "validation_results": {
                  "lazy_static": "4 macros extracted successfully",
                  "serde_derive": "5 macros extracted successfully", 
                  "anyhow": "15 macros extracted successfully"
                }
              }
            },
            "tier3": {
              "source": "Latest version fallback",
              "trigger": "CDN unavailable or extraction timeout",
              "coverage": "100% guaranteed",
              "quality": "Basic - ensures no crate is left without documentation"
            }
          },
          "performance": "Sub-500ms search maintained across all tiers",
          "memory_management": "MemoryMonitor integration required for all tiers",
          "dateImplemented": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "extractors/source_extractor.py"],
          "pattern": "Graceful degradation through multiple extraction sources with consistent interface"
        },
        {
          "error": "MCP Manifest vs Implementation Discrepancy",
          "context": "Code review identified issues with boolean parameters that were actually handled correctly in implementation",
          "solution": "Update MCP manifest to use anyOf patterns for boolean parameters matching the approach for numeric parameters. Boolean parameters should use anyOf: [{'type': 'boolean'}, {'type': 'string'}] to handle string-to-boolean conversion",
          "prevention": "Always ensure MCP manifest schema matches the actual validation capabilities. When Pydantic validators can handle type coercion, the MCP manifest should use anyOf patterns to prevent JSON Schema validation from blocking the conversion",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "resolutionStatus": "Investigation complete - manifest schema alignment with implementation validation needed"
        },
        {
          "error": "MCP boolean parameter validation errors with string inputs",
          "context": "MCP clients sending boolean parameters as strings (e.g., 'true', 'false') caused validation errors in search_items tool",
          "solution": "Use anyOf pattern in MCP manifest schema: {'anyOf': [{'type': 'boolean'}, {'type': 'string'}]} to allow both boolean and string types through JSON Schema validation, then let Pydantic field validators handle conversion with mode='before'",
          "prevention": "FastMCP performs double validation - JSON Schema first, then Pydantic. anyOf patterns must be in the manifest schema to allow flexible types through to Pydantic validators. Follow existing numeric parameter patterns for consistency",
          "dateEncountered": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "additionalInfo": {
            "serverTesting": "Use --mode rest with docsrs-mcp to test MCP manifest endpoints at localhost:8000 (not 8080)",
            "validationFlow": "MCP manifest anyOf → FastMCP JSON Schema validation → Pydantic field_validator with mode='before' → Boolean conversion",
            "patternConsistency": "Follow existing numeric parameter anyOf patterns for all flexible types"
          },
          "resolutionStatus": "Fixed and tested - boolean parameters now accept both native booleans and string representations"
        },
        {
          "lesson": "Critical searchExamples character fragmentation bug and testing methodology",
          "context": "searchExamples returns individual characters instead of complete code blocks due to string iteration bug",
          "solution": "Always test with direct MCP calls instead of REST to catch protocol-specific issues. Use fresh databases to avoid legacy data conflicts. Fix requires type checking before iteration in ingest.py:761",
          "prevention": "Implement comprehensive testing methodology: 1) Test searchExamples returns full code blocks not characters, 2) Test common path aliases resolve correctly, 3) Test numeric parameters accept both integer and string types, 4) Verify response times <500ms for warm queries, 5) Always use fresh databases for testing to avoid cached data issues",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/app.py"],
          "testingMethodology": {
            "directMcpTesting": "Use mcp__docsrs__ tools directly instead of REST endpoints",
            "freshDatabases": "Always test with new DBs to avoid legacy data issues",
            "verificationSteps": [
              "1. Test searchExamples returns full code blocks",
              "2. Test common path aliases resolve",
              "3. Test numeric parameters accept both types",
              "4. Verify <500ms response times"
            ]
          }
        },
        {
          "error": "MCP clients sending numeric/boolean values as strings cause validation failures",
          "context": "MCP clients (including Claude Code) send parameters like k=2 as string '2' and boolean parameters as 'true'/'false' strings, causing JSON Schema validation errors before Pydantic field validators can perform type coercion",
          "solution": "Add anyOf patterns to all parameters with type coercion needs in the MCP manifest (app.py's get_mcp_manifest() function): 1) Numeric parameters: 'anyOf': [{'type': 'integer'}, {'type': 'string'}], 2) Boolean parameters: 'anyOf': [{'type': 'boolean'}, {'type': 'string'}], 3) Optional strings: 'anyOf': [{'type': 'string'}, {'type': 'null'}]. Important: anyOf patterns must be added in app.py's get_mcp_manifest() function, not in models.py",
          "prevention": "Always use anyOf patterns in MCP manifests for parameters that may arrive as different types from various clients. Test with both native types and strings using curl to ensure compatibility. All parameters with field validators in models.py need corresponding anyOf patterns in app.py",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "validationFlow": "MCP manifest anyOf → FastMCP JSON Schema validation → Pydantic field validators → Type coercion",
          "testingNotes": "Verify with curl using both native types and strings: curl -X POST -H 'Content-Type: application/json' -d '{\"k\": \"5\"}' and curl -X POST -H 'Content-Type: application/json' -d '{\"k\": 5}'",
          "criticalDetails": {
            "manifestLocation": "app.py get_mcp_manifest() function around lines 151-297",
            "doubleValidation": "FastMCP performs JSON Schema validation before Pydantic field validators run",
            "patternRequired": "anyOf patterns are essential - restrictive schemas block field validator execution",
            "implementationNote": "Field validators handle conversion, manifest must allow types through"
          },
          "resolutionStatus": "FIXED - Applied anyOf patterns for numeric and boolean parameters, tested and verified working with both string and native type inputs"
        },
        {
          "error": "Path alias resolution for common Rust documentation paths",
          "context": "Users often use common aliases (serde::Deserialize) instead of full rustdoc paths (serde::de::Deserialize), causing 404 errors and poor user experience",
          "solution": "Implement static PATH_ALIASES dictionary with O(1) lookup before database query. Contains mappings like 'serde::Deserialize': 'serde::de::Deserialize', 'tokio::spawn': 'tokio::task::spawn', 'Result': 'std::result::Result'. Uses resolve_path_alias() function in fuzzy_resolver.py for efficient resolution",
          "prevention": "Maintain PATH_ALIASES dictionary with common path aliases for frequently accessed items. Update aliases based on user feedback and common usage patterns",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "performanceNotes": "Alias resolution adds <1ms overhead while maintaining sub-500ms response time requirement. O(1) dictionary lookup is extremely fast",
          "testingApproach": "Both unit tests for resolve_path_alias() function and integration tests for API endpoint ensure comprehensive coverage",
          "mcpTesting": "Use --mode rest flag to test with HTTP/curl instead of STDIO mode for easier debugging and verification"
        },
        {
          "error": "Search results using simple character truncation reducing readability",
          "context": "Search results were using simple character truncation (content[:200]) which often cut words in the middle, reducing readability and user experience",
          "rootCause": "Basic character-based truncation doesn't respect word or sentence boundaries, resulting in incomplete words and poor snippet quality",
          "solution": [
            "Implemented extract_smart_snippet() function with progressive fallback strategy",
            "First tries sentence boundary detection using regex pattern r'[.!?]\\s+'",
            "Falls back to word boundary detection if sentences are too long",
            "Falls back to character truncation as last resort",
            "Target length 300 chars (range 200-400) for optimal readability",
            "Ensures complete words are preserved when truncating"
          ],
          "testingInsight": "Initial test for word boundaries was flawed - it incorrectly expected text before ellipsis to end with space/non-alphanumeric. Correct approach is to verify the last word exists as a complete word in the original content",
          "performanceNotes": [
            "Minimal overhead due to simple regex operations",
            "Reuses existing LRU cache infrastructure",
            "No database changes required"
          ],
          "integrationPoints": [
            "/src/docsrs_mcp/app.py:689 - extract_smart_snippet function",
            "/src/docsrs_mcp/app.py:918 - search_items snippet extraction",
            "/src/docsrs_mcp/app.py:1191 - search_examples snippet extraction",
            "/src/docsrs_mcp/models.py:751 - Updated SearchResult snippet field description"
          ],
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codeExample": "def extract_smart_snippet(content: str, target_length: int = 300) -> str:\n    if len(content) <= target_length:\n        return content\n    \n    # Try sentence boundaries first\n    sentences = re.split(r'[.!?]\\s+', content)\n    if sentences and len(sentences[0]) <= target_length:\n        return sentences[0] + ('...' if len(content) > len(sentences[0]) else '')\n    \n    # Fall back to word boundaries\n    if target_length > 50:\n        words = content[:target_length].split()\n        if words:\n            snippet = ' '.join(words[:-1])  # Remove potentially truncated last word\n            return snippet + ('...' if len(content) > len(snippet) else '')\n    \n    # Final fallback: character truncation\n    return content[:target_length] + ('...' if len(content) > target_length else '')",
          "prevention": "Always consider text boundaries (sentences, words) when implementing content truncation to maintain readability and professional presentation"
        },
        {
          "lesson": "Multi-tier fallback for resilience",
          "context": "Building robust systems that handle various failure modes",
          "details": "Implementation pattern: Try API → Load from disk → Use expired memory cache → Hardcoded fallback list",
          "impact": "System remains functional even during complete API outages",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/api.py", "src/docsrs_mcp/cache.py"]
        },
        {
          "lesson": "Binary serialization performance benefits",
          "context": "Cache loading performance optimization",
          "details": "msgpack reduces cache load time from 50ms (JSON) to 2ms for 100 crates",
          "impact": "25x improvement in cache loading performance",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/cache.py"]
        },
        {
          "error": "docs.rs 404 fallback issue - rustdoc JSON only available for versions after May 23, 2025",
          "rootCause": "docs.rs only generates rustdoc JSON files for crate versions published after May 23, 2025. Older versions return 404 errors that need to be distinguished from actual missing crates",
          "solution": "Implement RustdocVersionNotFoundError to distinguish between true 404 errors (non-existent crates) and version-specific unavailability (pre-May 2025 versions). This allows graceful handling of older crate versions.",
          "context": "Cross-reference implementation requiring rustdoc JSON from docs.rs API",
          "implementation": [
            "Create custom exception class RustdocVersionNotFoundError",
            "Check HTTP response status and distinguish 404 causes",
            "Provide clear error messages indicating version limitations",
            "Allow fallback strategies for older versions"
          ],
          "pattern": "Version-aware error handling for external API dependencies",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/cross_reference.py"],
          "codeExample": "class RustdocVersionNotFoundError(Exception):\n    \"\"\"Raised when rustdoc JSON is not available for a specific version\"\"\"\n    pass\n\nif response.status_code == 404:\n    raise RustdocVersionNotFoundError(f\"Rustdoc JSON not available for {crate}:{version}\")"
        },
        {
          "error": "Integration test parameter wrapping - API expects parameters directly in JSON body",
          "rootCause": "Integration tests were incorrectly wrapping parameters in a 'params' object, but the API expects parameters to be at the root level of the JSON body",
          "solution": "Remove 'params' wrapper and send parameters directly in JSON body. Use flat JSON structure matching the API's expected format.",
          "context": "Cross-reference implementation integration testing",
          "implementation": [
            "Change from {'params': {'crate': 'serde'}} to {'crate': 'serde'}",
            "Update all test cases to use flat parameter structure",
            "Verify API endpoint parameter handling expectations"
          ],
          "pattern": "Match test parameter structure to actual API expectations",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["tests/test_cross_reference.py"],
          "codeExample": "# Wrong:\nresponse = client.post('/api/endpoint', json={'params': {'crate': 'serde'}})\n\n# Correct:\nresponse = client.post('/api/endpoint', json={'crate': 'serde'})"
        },
        {
          "error": "MMR tests failing due to incorrect embedding dimensions",
          "rootCause": "Test mock embeddings don't match expected model dimensions, causing shape mismatches in cosine similarity calculations",
          "solution": "MMR tests need mock embeddings matching expected dimensions (384 for bge-small-en-v1.5). Use numpy arrays with correct shape for test embedding vectors.",
          "context": "Testing MMR diversification algorithm with semantic similarity",
          "implementation": [
            "Mock embeddings must match production model dimensions (384-dimensional vectors)",
            "Use np.random.rand(384) or predefined test vectors with correct shape",
            "Ensure embedding alignment is maintained during test result sorting"
          ],
          "pattern": "Match test data dimensions to production model requirements",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["tests/test_database.py", "src/docsrs_mcp/database.py"],
          "codeExample": "# Correct test embedding setup:\nmock_embeddings = [np.random.rand(384) for _ in range(len(results))]\n# NOT: mock_embeddings = [np.array([0.1, 0.2, 0.3])]  # Wrong dimensions"
        },
        {
          "error": "Function signature changes breaking existing test calls",
          "rootCause": "When adding new parameters to functions (like embeddings to MMR), existing test calls fail with missing argument errors",
          "solution": "When changing function signatures, systematically update all test calls. Use grep to find all test invocations before making signature changes.",
          "context": "Adding embeddings parameter to MMR diversification functions",
          "implementation": [
            "Search codebase for function calls before signature changes: grep -r 'function_name(' tests/",
            "Update all test invocations with new required parameters",
            "Consider backward compatibility with default parameters when possible"
          ],
          "pattern": "Comprehensive test update when changing function signatures",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["tests/", "src/docsrs_mcp/database.py"],
          "codeExample": "# Before signature change, find all calls:\n# grep -r '_apply_mmr_diversification(' tests/\n# Then update each call with new embeddings parameter"
        },
        {
          "error": "Production testing confusion with server ports and API paths",
          "rootCause": "Production server testing requires understanding correct port and API path structure",
          "solution": "Production testing with --mode rest flag starts server on port 8000. API endpoints are under /mcp/tools/ path (e.g., /mcp/tools/search_items). Use curl or HTTP clients with correct base URL.",
          "context": "Testing MMR and other features in production-like environment",
          "implementation": [
            "Start server: uv run docsrs-mcp --mode rest (listens on port 8000)",
            "API endpoints: http://localhost:8000/mcp/tools/{tool_name}",
            "Example: curl -X POST http://localhost:8000/mcp/tools/search_items -H 'Content-Type: application/json' -d '{...}'"
          ],
          "pattern": "Use correct port and path structure for production API testing",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "# Correct production test URL:\ncurl -X POST http://localhost:8000/mcp/tools/search_items -H 'Content-Type: application/json' -d '{\"query\": \"test\", \"k\": 5}'"
        },
        {
          "error": "Database unique constraint violation - composite key needed for cross-references",
          "rootCause": "Original UNIQUE constraint on (crate_id, alias_path) was insufficient for cross-references where the same alias can point to multiple actual paths with different link types",
          "solution": "Change unique constraint from UNIQUE(crate_id, alias_path) to UNIQUE(crate_id, alias_path, actual_path, link_type) to allow multiple cross-reference entries for the same alias when they have different targets or types.",
          "context": "Cross-reference database schema design for handling multiple alias mappings",
          "implementation": [
            "Update database migration to change unique constraint",
            "Allow same alias to point to different actual paths",
            "Include link_type in constraint to distinguish reference types",
            "Ensure data integrity while supporting complex cross-reference relationships"
          ],
          "pattern": "Composite unique constraints for complex relationship data",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/database.py", "migrations/"],
          "codeExample": "# Old constraint:\nUNIQUE(crate_id, alias_path)\n\n# New constraint:\nUNIQUE(crate_id, alias_path, actual_path, link_type)"
        },
        {
          "lesson": "Performance optimization for bidirectional cross-reference lookups",
          "context": "Cross-reference implementation requiring efficient queries in both directions (alias -> actual and actual -> aliases)",
          "solution": "Create composite indexes for bidirectional lookups: INDEX on (crate_id, alias_path) for forward lookups and INDEX on (crate_id, actual_path) for reverse lookups. This enables sub-millisecond query performance in both directions.",
          "implementation": [
            "Create forward lookup index: CREATE INDEX idx_cross_ref_forward ON cross_references(crate_id, alias_path)",
            "Create reverse lookup index: CREATE INDEX idx_cross_ref_reverse ON cross_references(crate_id, actual_path)",
            "Include link_type in queries when specific reference types are needed",
            "Monitor query performance with EXPLAIN QUERY PLAN"
          ],
          "pattern": "Bidirectional indexing for efficient relationship queries",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/database.py"],
          "performanceNotes": "Bidirectional indexes enable O(log n) lookup performance in both directions without table scans",
          "codeExample": "# Forward lookup (alias -> actual)\nSELECT actual_path FROM cross_references WHERE crate_id = ? AND alias_path = ?\n\n# Reverse lookup (actual -> aliases)\nSELECT alias_path FROM cross_references WHERE crate_id = ? AND actual_path = ?"
        },
        {
          "error": "Standard library items could not be retrieved - only \"crate\" entry was stored",
          "rootCause": "Standard library rustdoc JSON is not available on docs.rs, causing stdlib queries to return minimal \"crate\" entry instead of item documentation",
          "solution": "Implemented create_stdlib_fallback_documentation() function that generates basic documentation for common stdlib items when rustdoc JSON is unavailable",
          "context": "Stdlib documentation ingestion and retrieval for common Rust standard library types",
          "implementation": [
            "Create fallback documentation generator for stdlib items",
            "Provide basic type information and common usage patterns",
            "Cover essential types like std::vec::Vec, core::option::Option, std::result::Result",
            "Enable partial stdlib functionality until full rustdoc JSON support is available"
          ],
          "pattern": "Graceful degradation with fallback documentation when external sources are unavailable",
          "dateEncountered": "2025-08-11",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"],
          "codeExample": "def create_stdlib_fallback_documentation(item_path: str) -> dict:\n    \"\"\"Generate basic documentation for stdlib items when rustdoc JSON unavailable\"\"\"\n    fallback_docs = {\n        'std::vec::Vec': {\n            'name': 'Vec',\n            'docs': 'A contiguous growable array type.',\n            'kind': 'struct'\n        },\n        'core::option::Option': {\n            'name': 'Option',\n            'docs': 'Type representing an optional value.',\n            'kind': 'enum'\n        }\n    }\n    return fallback_docs.get(item_path, {'name': item_path.split('::')[-1], 'docs': 'Standard library item', 'kind': 'unknown'})",
          "result": "Enables retrieval of std::vec::Vec, core::option::Option, and other stdlib items with basic documentation until full rustdoc JSON support is available"
        },
        {
          "error": "K parameter validation with MCP string handling",
          "rootCause": "MCP clients send numeric parameters as strings (e.g., k='5' instead of k=5), which can cause validation errors and over-fetch calculation issues with sqlite-vec",
          "solution": "Implemented multi-layer validation with MCP manifest anyOf patterns, Pydantic field validators with mode='before', and defensive bounds checking before sqlite-vec operations",
          "context": "MCP clients (Cursor, Claude Code) have varying serialization behaviors - some send k=20 as integer, others as string '20', requiring dual validation approach with sqlite-vec compatibility",
          "implementation": [
            "Multi-layer validation: MCP manifest with anyOf patterns + Pydantic field validators with mode='before'",
            "Defensive bounds checking: Added safe_k = min(k, 20) before over-fetch calculations in database.py",
            "Consistent validation: All K parameters use coerce_to_int_with_bounds(min_val=1, max_val=20)",
            "Added anyOf patterns in MCP manifest: {'anyOf': [{'type': 'integer'}, {'type': 'string'}]} for k parameter",
            "Created coerce_to_int_with_bounds helper function with bounds validation to prevent sqlite-vec issues",
            "Over-fetching logic uses k+10 base with MMR multiplier (1.5x) but requires bounds validation"
          ],
          "keyInsights": [
            "sqlite-vec requires integer K parameters in WHERE clauses (e.g., 'WHERE k = 10')",
            "max_val=20 ensures fetch_k ≤ 50 even with MMR diversification (1.5x multiplier)",
            "MCP manifest requires anyOf: [{'type': 'integer'}, {'type': 'string'}] with minimum/maximum constraints",
            "Defensive bounds checking prevents edge cases even if validation is bypassed",
            "Different MCP clients have varying serialization behaviors for numeric parameters",
            "HTTP REST mode works perfectly with both string and integer inputs",
            "anyOf patterns in manifest are essential for JSON Schema validation before Pydantic runs"
          ],
          "testingResults": [
            "String parameter k='20' accepted successfully (HTTP 200)",
            "Invalid k='25' rejected with clear error message (HTTP 422)",
            "Production testing confirmed MCP client compatibility",
            "MMR enabled scenarios verified with fetch_k calculation staying within limits"
          ],
          "pattern": "All numeric MCP parameters need dual validation: JSON Schema anyOf pattern + Pydantic field validator with bounds checking",
          "dateEncountered": "2025-08-11",
          "lastUpdated": "2025-08-12",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py", "src/docsrs_mcp/database.py"],
          "codeExample": "# MCP manifest anyOf pattern:\n'k': {\n    'type': 'integer',\n    'description': 'Number of results to return',\n    'anyOf': [{'type': 'integer'}, {'type': 'string'}],\n    'minimum': 1,\n    'maximum': 20\n},\n\n# Pydantic field validator:\n@field_validator('k', mode='before')\n@classmethod\ndef validate_k(cls, v):\n    if v is None:\n        return None\n    return coerce_to_int_with_bounds(v, min_val=1, max_val=20, field_name='k')\n\n# Helper with bounds checking:\ndef coerce_to_int_with_bounds(value, min_val: int, max_val: int, field_name: str) -> int:\n    if isinstance(value, int):\n        result = value\n    elif isinstance(value, str):\n        try:\n            result = int(value.strip())\n        except ValueError:\n            raise ValueError(f'{field_name} must be integer between {min_val}-{max_val}. Got: {repr(value)[:100]}')\n    else:\n        raise ValueError(f'{field_name} must be integer. Got: {type(value).__name__}')\n    \n    if not (min_val <= result <= max_val):\n        raise ValueError(f'{field_name} must be between {min_val}-{max_val}. Got: {result}')\n    \n    return result\n\n# Defensive bounds checking in database operations:\nsafe_k = min(k, 20)  # Prevent over-fetch calculation issues\nfetch_k = min(safe_k + 10, 50)  # Cap at safe limits",
          "testingRecommendations": [
            "Test with k='20' (string max), k=20 (int max), k='25' (exceeds bounds)",
            "Test with MMR enabled to verify fetch_k calculation stays within limits",
            "Use curl to test both string and integer parameter formats",
            "Test boundary conditions: k=1, k=20, k=21 (should fail)",
            "Verify sqlite-vec queries work with calculated fetch_k values"
          ],
          "prevention": "Always use anyOf patterns in MCP manifests for numeric parameters, implement bounds validation in coercion functions, add defensive bounds checking before database operations, and cap calculated derived values (like fetch_k) to prevent database errors"
        },
        {
          "error": "MCP client parameter validation incompatibility - anyOf schemas rejected by clients",
          "rootCause": "MCP clients (Claude Code, Claude Desktop) have inconsistent JSON Schema support. Claude Code completely rejects anyOf schemas with validation errors, while Claude Desktop has buggy anyOf support that fails unpredictably",
          "solution": "Avoid anyOf schemas entirely in MCP tools. Use single type definitions (string, integer, boolean) and rely on Pydantic field validators with mode='before' for type coercion. Design schemas to match what MCP clients actually send rather than what the server can handle",
          "context": "MCP tool parameters fail validation despite REST API working correctly, causing tool execution failures",
          "errorSymptoms": [
            "MCP tools reject parameters with 'Input validation error: not valid under any of the given schemas'",
            "REST API accepts same parameters without issues",
            "Parameters work when passed as expected type but fail when coerced from strings"
          ],
          "researchFindings": [
            "Claude Code has no anyOf support - completely rejects schemas with anyOf patterns",
            "Claude Desktop has partial anyOf support but fails on complex cases",
            "Different MCP clients send parameters as different types (strings vs native types)",
            "JSON Schema validation in MCP protocol is stricter than OpenAPI/REST validation"
          ],
          "bestPractice": "Design MCP schemas around MCP client limitations, not server capabilities. Use conservative single-type schemas and handle type flexibility entirely in Pydantic validators",
          "dateEncountered": "2025-08-13",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# AVOID - anyOf patterns that break MCP clients:\n'k': {\n    'type': 'integer',\n    'anyOf': [{'type': 'integer'}, {'type': 'string'}]\n}\n\n# USE - single type with Pydantic coercion:\n'k': {\n    'type': 'string',  # Accept what clients actually send\n    'description': 'Number of results (sent as string)'\n}\n\n# Handle coercion in Pydantic validator:\n@field_validator('k', mode='before')\n@classmethod\ndef coerce_k(cls, v):\n    if isinstance(v, int):\n        return v\n    if isinstance(v, str):\n        return int(v.strip())\n    raise ValueError('k must be integer or string')",
          "impact": "MCP tools become unusable when clients cannot validate parameter schemas, breaking the entire MCP integration despite server-side functionality working correctly"
        },
        {
          "error": "Input validation error: '5' is not valid under any of the given schemas",
          "rootCause": "Claude Code MCP client completely rejects anyOf schema patterns, causing validation failures even when server-side validation is correct. The error occurs when MCP clients send parameters to schemas using anyOf patterns.",
          "solution": "Remove all anyOf patterns from MCP manifest entirely. Use simple string types for all parameters and rely on Pydantic field validators for type coercion. Add examples arrays and format hints to parameter descriptions for better client understanding.",
          "context": "MCP parameter validation failing with Claude Code client despite working with REST API and Claude Desktop",
          "lesson": "Claude Code doesn't support anyOf JSON schemas at all. Always test with actual MCP clients, not just REST API. Simple schemas are better for compatibility than complex validation patterns.",
          "pattern": "Use single string type in manifest with robust Pydantic field validators for all type coercion and validation logic",
          "dateEncountered": "2025-08-13",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# MCP Manifest - Simple string type:\n'enabled': {\n    'type': 'string',\n    'description': 'Enable feature (true/false, 1/0, yes/no)',\n    'examples': ['true', 'false', '1', '0']\n}\n\n# Pydantic Field Validator - Handle all coercion:\n@field_validator('enabled', mode='before')\n@classmethod\ndef coerce_enabled(cls, v):\n    if isinstance(v, bool):\n        return v\n    if isinstance(v, str):\n        v_lower = v.lower().strip()\n        return v_lower in ('true', '1', 'yes', 'on', 't', 'y')\n    if isinstance(v, int | float):\n        return bool(v)\n    return False  # Default for invalid inputs",
          "debuggingTechnique": "Test with both Claude Code MCP client and REST API to identify client-specific validation differences",
          "bestPractice": "Design MCP schemas for the most restrictive client (Claude Code) and handle complexity in server-side validators. Field validators can handle the complexity that schemas can't.",
          "impact": "Enables full compatibility with Claude Code MCP client while maintaining type safety and validation through Pydantic"
        },
        {
          "error": "Module structure search results contaminated with internal/dependency modules",
          "rootCause": "Search results include internal implementation details like std::, core::, deps:: modules that are not relevant to user queries about crate API structure",
          "solution": "Implement post-processing filters to remove internal and dependency modules from search results. Filter patterns: ['::__', '_internal', 'deps::', 'std::', 'core::'] to focus on public API modules only",
          "context": "Module structure queries returning too much noise from internal Rust standard library and dependency modules",
          "lesson": "Search results need post-processing to remove irrelevant internal modules and focus on user-relevant public API surface",
          "pattern": "Apply filtering patterns after search but before returning results to users",
          "dateEncountered": "2025-08-13",
          "relatedFiles": ["src/docsrs_mcp/search.py", "src/docsrs_mcp/filters.py"],
          "codeExample": "# Filter internal modules from results\nfiltered_modules = [\n    module for module in modules \n    if not any(pattern in module.path for pattern in \n               ['::__', '_internal', 'deps::', 'std::', 'core::'])\n]",
          "debuggingTechnique": "Compare raw search results with filtered results to verify internal modules are properly excluded",
          "impact": "Improves search result quality by focusing on relevant public API modules instead of internal implementation details"
        },
        {
          "error": "Version comparison returns 0 for all comparisons",
          "rootCause": "When crate versions don't exist or rustdoc JSON is unavailable, ingestion falls back to storing only a single description embedding, causing comparison to find no meaningful differences",
          "solution": "Added validation to check for minimal ingestion (less than 2 items) and raise clear error messages instead of returning misleading '0 changes'",
          "context": "Version comparison failing to detect differences due to insufficient documentation data",
          "lesson": "Always validate data completeness before performing comparisons to avoid misleading results",
          "pattern": "Use MIN_ITEMS_THRESHOLD check before attempting version comparisons",
          "dateEncountered": "2025-08-15",
          "relatedFiles": ["src/docsrs_mcp/version_diff.py", "src/docsrs_mcp/validation.py"],
          "codeExample": "# Check for minimal ingestion before comparison\nif len(old_items) < MIN_ITEMS_THRESHOLD:\n    raise ValueError(f\"Insufficient documentation found for {crate} v{old_version} (only {len(old_items)} item found). The crate may not be fully ingested.\")",
          "debuggingTechnique": "Check ingestion counts in database before running comparisons to identify incomplete data",
          "implementationDetails": "Added MIN_ITEMS_THRESHOLD check in version_diff.py using existing validation utilities from validation.py to provide actionable error messages explaining the issue",
          "impact": "Prevents misleading '0 changes' results and provides clear error messages when comparison data is insufficient"
        },
        {
          "error": "getCrateSummary returning 'unwind' as name for all crates in MCP mode",
          "context": "All crates return 'unwind' as the name field in getCrateSummary responses when using MCP mode, despite database containing correct crate names",
          "investigation": {
            "suspectedCause": "tools_to_fix dictionary in FastMCP schema override using camelCase operation_ids instead of snake_case tool names",
            "attemptedFix": "Changed tool names from camelCase (getCrateSummary) to snake_case (get_crate_summary) in tools_to_fix dictionary",
            "result": "Bug persists after schema override fix - root cause appears deeper than initially suspected"
          },
          "currentStatus": "Unresolved - database contains correct data, issue appears to be in response generation or serialization layer",
          "debuggingFindings": [
            "Database queries return correct crate names when tested directly",
            "Issue specific to MCP mode - REST mode returns correct names",
            "Schema override modification did not resolve the issue",
            "Problem likely in FastMCP response serialization or field mapping"
          ],
          "nextSteps": [
            "Investigate FastMCP response serialization logic",
            "Check field mapping between database results and MCP responses",
            "Test with simplified response models to isolate the issue",
            "Compare MCP vs REST response generation pathways"
          ],
          "dateEncountered": "2025-08-16",
          "relatedFiles": ["src/docsrs_mcp/mcp_server.py", "src/docsrs_mcp/mcp_tools.py", "src/docsrs_mcp/models.py"],
          "impact": "All MCP clients receive incorrect crate names, affecting user experience and tool reliability"
        },
        {
          "error": "MCP SDK v3.0 migration failure - version doesn't exist",
          "context": "Initially planned to migrate to MCP SDK v3.0 but discovered it doesn't exist",
          "solution": "Use MCP SDK 1.13.1 (August 2025) which incorporates FastMCP 1.0 functionality",
          "prevention": "Always verify library version existence before planning migrations",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["pyproject.toml"],
          "impact": "Simplifies migration as FastMCP patterns are preserved in official SDK",
          "lesson": "Official SDK 1.13.1 maintains backward compatibility with FastMCP 1.0 patterns"
        },
        {
          "error": "MCP SDK 1.13.1 memory leak causing OOM",
          "context": "Confirmed memory leak in MCP SDK 1.13.1 causing continuous growth until out of memory",
          "solution": "Implement connection recycling and monitor server memory usage actively",
          "workaround": "Use background processes with nohup and PID capture for testing to avoid terminal hanging",
          "prevention": "Monitor memory usage in production and implement automatic restart policies",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "impact": "Critical issue requiring active memory monitoring in production environments",
          "codeExample": "# Background process testing pattern:\nnohup uv run docsrs-mcp > server.log 2>&1 & echo $!\nSERVER_PID=$!\n# Monitor and kill when needed:\nkill $SERVER_PID"
        },
        {
          "error": "Inconsistent exception handling in MCP SDK decorators",
          "context": "Errors sent as successful responses in @app.call_tool decorators instead of proper exceptions",
          "solution": "Use proper error handling with McpError for consistency across all MCP tools",
          "prevention": "Always use McpError for validation failures and other tool-level errors",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py"],
          "codeExample": "# Correct error handling pattern:\ntry:\n    return await service.operation(...)\nexcept ValidationError as e:\n    raise McpError(f'Validation failed: {e}')\nexcept Exception as e:\n    raise McpError(f'Operation failed: {e}')",
          "impact": "Ensures consistent error reporting across all MCP client implementations"
        },
        {
          "error": "Parameter validation issues with Claude Code MCP client",
          "context": "String-only schema edge cases causing validation failures with specific MCP clients",
          "solution": "Official SDK handles this natively with type hints - no manual override needed",
          "prevention": "Use @mcp.tool() decorator with proper type annotations for automatic parameter handling",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py"],
          "lesson": "Official SDK's built-in type coercion eliminates need for manual anyOf schema patterns",
          "impact": "Simplifies MCP tool development and improves client compatibility"
        },
        {
          "error": "Large files exceeding 500 LOC maintainability limit",
          "context": "app.py (2047 LOC), models.py (1800+ LOC), database.py (1000+ LOC) becoming difficult to maintain",
          "solution": "Implement service layer pattern - split into focused modules under 400 LOC each",
          "prevention": "Regular refactoring to maintain module size limits and logical separation",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py", "src/docsrs_mcp/database.py"],
          "proposedStructure": "services/, database/, models/ directories with logical separation",
          "impact": "Improves code maintainability and reduces complexity for future development"
        },
        {
          "error": "Server hanging on macOS Python 3.12 with KqueueSelector",
          "context": "MCP server process hanging due to KqueueSelector logging issues on macOS",
          "solution": "Use background processes with proper PID management for testing",
          "prevention": "Never use bare 'uv run docsrs-mcp &' - requires manual interruption that can crash terminal",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "codeExample": "# Correct background process pattern:\nnohup uv run docsrs-mcp > server.log 2>&1 & echo $!\n# Store PID:\nSERVER_PID=$(nohup uv run docsrs-mcp > server.log 2>&1 & echo $!)\n# Check logs:\ntail -f server.log\n# Clean shutdown:\nkill $SERVER_PID",
          "impact": "Enables reliable server testing without terminal hanging or process management issues"
        },
        {
          "error": "FastMCP vs Official SDK naming confusion",
          "context": "FastMCP 2.0 is separate from official SDK despite similar naming conventions",
          "solution": "Use official MCP SDK 1.13.1 which includes FastMCP 1.0 functionality - import from 'mcp.server.fastmcp'",
          "prevention": "Verify import paths and understand library relationships before implementation",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "clarification": "Official SDK 1.13.1 includes FastMCP 1.0 functionality; FastMCP 2.0 is separate enhanced toolkit",
          "impact": "Ensures correct library usage and avoids dependency conflicts",
          "importPattern": "from mcp.server.fastmcp import FastMCP  # Official SDK with FastMCP 1.0 features"
        },
        {
          "error": "MCP SDK memory leak with continuous tool calls",
          "context": "SDK 1.13.1 has memory leak that accumulates with each tool call, causing server memory growth from 200MB to 1.5GB+ over time",
          "solution": "Implement server rotation every 1000 calls using MCPServerRunner class with psutil monitoring. Alternative: Set MCP_MAX_CALLS=1000 and MCP_MAX_MEMORY_MB=512 environment variables for automatic rotation",
          "prevention": "Monitor memory usage and implement rotation patterns for long-running MCP servers with high call volumes",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/server_runner.py", "src/docsrs_mcp/app.py"],
          "workaround": "MCPServerRunner class provides automatic server lifecycle management with configurable memory thresholds",
          "codeExample": "# Environment variable approach:\nMCP_MAX_CALLS=1000\nMCP_MAX_MEMORY_MB=512\n\n# Programmatic approach:\nclass MCPServerRunner:\n    def __init__(self, max_calls=1000, max_memory_mb=512):\n        self.call_count = 0\n        self.max_calls = max_calls\n        self.max_memory_mb = max_memory_mb\n        \n    def should_rotate(self) -> bool:\n        memory_mb = psutil.Process().memory_info().rss / (1024 * 1024)\n        return self.call_count >= self.max_calls or memory_mb > self.max_memory_mb"
        },
        {
          "error": "MCP parameter validation: clients send typed parameters as strings",
          "context": "MCP clients send string parameters like k='3' and enabled='true' but SDK expects proper types, causing validation failures",
          "solution": "Implement validate_int_parameter() and validate_bool_parameter() utilities that accept strings, validate, convert, and provide sensible defaults. Use pattern: accept strings, validate, convert, provide defaults",
          "prevention": "Always use parameter validation utilities for MCP tools instead of assuming correct types from clients",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/validators.py", "src/docsrs_mcp/models.py"],
          "pattern": "String input → validation → type conversion → default handling",
          "codeExample": "def validate_int_parameter(value: Any, field_name: str, min_val: int = None, max_val: int = None, default: int = None) -> Optional[int]:\n    if value is None:\n        return default\n    if isinstance(value, int):\n        return value\n    if isinstance(value, str):\n        try:\n            converted = int(value)\n            if min_val is not None and converted < min_val:\n                raise ValueError(f'{field_name} must be >= {min_val}')\n            if max_val is not None and converted > max_val:\n                raise ValueError(f'{field_name} must be <= {max_val}')\n            return converted\n        except ValueError as e:\n            raise ValueError(f'Invalid {field_name}: {e}')\n    raise ValueError(f'{field_name} must be an integer or string, got {type(value)}')"
        },
        {
          "error": "Service layer benefits for dual MCP implementation",
          "context": "Implementing both FastMCP and SDK implementations without code duplication",
          "solution": "Create service layer that enables dual implementation: business logic remains transport-agnostic, simplifies testing and maintenance, allows gradual migration with feature flags",
          "prevention": "Always design with service layer abstraction when supporting multiple MCP implementations or transport protocols",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/services/", "src/docsrs_mcp/app.py"],
          "benefits": [
            "Enables dual implementation without code duplication",
            "Business logic remains transport-agnostic", 
            "Simplifies testing and maintenance",
            "Allows gradual migration with feature flags"
          ],
          "architecturePattern": "Service Layer → Transport Adapters (FastMCP/SDK) → MCP Protocol"
        },
        {
          "error": "Parallel validation technique for regression testing",
          "context": "Need to validate that SDK migration doesn't introduce regressions compared to FastMCP implementation",
          "solution": "Run both implementations simultaneously, compare outputs for regression testing using subprocess for isolation and JSON-RPC for communication. Test with identical inputs and compare responses",
          "prevention": "Use parallel validation during any major transport or protocol migration to ensure behavioral consistency",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["tests/test_parallel_validation.py", "src/docsrs_mcp/testing/"],
          "technique": "Subprocess isolation + JSON-RPC communication + output comparison",
          "codeExample": "# Run both implementations in parallel\nasync def compare_implementations(tool_name: str, parameters: dict):\n    fastmcp_result = await run_fastmcp_subprocess(tool_name, parameters)\n    sdk_result = await run_sdk_subprocess(tool_name, parameters)\n    \n    # Compare outputs\n    assert fastmcp_result.status_code == sdk_result.status_code\n    assert normalize_response(fastmcp_result.data) == normalize_response(sdk_result.data)"
        },
        {
          "error": "CLI testing commands for MCP implementation comparison",
          "context": "Need easy commands to test different MCP implementations during development and migration",
          "solution": "Implement CLI flags for testing: --mcp-implementation fastmcp/sdk/both for comparing implementations, --mode rest for HTTP testing. Use both flag to run parallel validation",
          "prevention": "Provide clear testing commands and implementation selection during migration phases",
          "dateEncountered": "2025-08-22",
          "relatedFiles": ["src/docsrs_mcp/cli.py", "src/docsrs_mcp/app.py"],
          "testingCommands": {
            "fastmcp": "uv run docsrs-mcp --mcp-implementation fastmcp",
            "sdk": "uv run docsrs-mcp --mcp-implementation sdk", 
            "comparison": "uv run docsrs-mcp --mcp-implementation both",
            "rest": "uv run docsrs-mcp --mode rest"
          },
          "usagePattern": "Start with FastMCP, migrate to SDK, validate with both, deprecate FastMCP"
        }
      ]
    },
    "lessonsLearned": {
      "description": "Important insights gained during development",
      "entries": [
        {
          "lesson": "SQLite WAL mode improves concurrency",
          "context": "Database performance with concurrent access",
          "details": "WAL mode enabled for better concurrency in multi-user scenarios",
          "impact": "Reduced database lock contention",
          "dateLearned": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/database.py"]
        },
        {
          "lesson": "Embeddings caching strategy",
          "context": "Vector storage and reuse patterns",
          "details": "Embeddings cached in SQLite for reuse across sessions",
          "impact": "Significant performance improvement for repeated queries",
          "dateLearned": "2025-08-04",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Batch processing for embeddings",
          "context": "Optimizing embedding generation performance",
          "details": "Use EMBEDDING_BATCH_SIZE=32 for optimal balance between memory usage and processing speed",
          "impact": "Improved throughput while keeping memory usage reasonable",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Test isolation with cache directories",
          "context": "Integration testing with shared cache state",
          "details": "Always patch both ingest.CACHE_DIR and database.CACHE_DIR for integration tests to avoid state pollution",
          "impact": "Prevents test failures due to shared state between test runs",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["tests/test_ingest.py", "tests/test_app.py"]
        },
        {
          "lesson": "Batch insert rowid relationship management",
          "context": "Maintaining foreign key relationships in batch database operations",
          "details": "When batch inserting related data, calculate rowid range using last_rowid - batch_size + 1 to map parent-child relationships",
          "impact": "Enables efficient batch processing while maintaining referential integrity",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Pre-serialize data before batch processing",
          "context": "Optimizing batch insert performance with repeated serialization",
          "details": "Pre-serialize vectors and other complex data structures before batching to avoid repeated serialization overhead",
          "impact": "Reduces CPU usage and improves batch processing performance",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Batch processing maintains constant memory usage",
          "context": "Memory optimization for large dataset processing",
          "details": "Proper batch processing keeps memory usage constant regardless of total dataset size, preventing OOM errors",
          "impact": "Enables processing of arbitrarily large datasets within memory constraints",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Test with >2x batch size for comprehensive validation",
          "context": "Ensuring batch processing logic handles multiple batches correctly",
          "details": "Create tests with datasets larger than 2x batch size to verify multiple batch handling and edge cases",
          "impact": "Catches off-by-one errors and batch boundary issues during development",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["tests/test_ingest.py"]
        },
        {
          "lesson": "Ruff formatting automatically fixes whitespace issues in docstrings",
          "context": "Code quality and documentation formatting",
          "details": "Ruff's formatting automatically handles whitespace and indentation issues in docstrings, maintaining consistent documentation format",
          "impact": "Reduces manual formatting work and ensures consistent documentation style",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["pyproject.toml"]
        },
        {
          "lesson": "FastAPI metadata supports markdown in description field",
          "context": "API documentation and OpenAPI schema generation",
          "details": "FastAPI's app description field supports full markdown syntax for rich API documentation that appears in OpenAPI schema",
          "impact": "Enables better API documentation with formatted text, links, and examples",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Pydantic examples parameter provides inline examples in OpenAPI schema",
          "context": "API request/response documentation",
          "details": "Using 'examples' parameter in Pydantic models automatically generates example data in OpenAPI schema for better API documentation",
          "impact": "Improves API usability by providing clear examples in generated documentation",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Rate limiting documentation prevents user confusion with 429 errors",
          "context": "API error handling and user experience",
          "details": "Clear documentation of rate limits and proper HTTP 429 responses with retry headers helps users understand and handle rate limiting gracefully",
          "impact": "Reduces support requests and improves API adoption by making rate limits transparent",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "MCP manifest schemas need anyOf pattern for mixed-type parameters",
          "context": "MCP clients send parameters with inconsistent types (strings vs integers)",
          "details": "FastMCP has double validation - JSON Schema validation occurs before Pydantic field validators. Use anyOf: [{type: 'integer'}, {type: 'string'}] in MCP manifest to allow both types through schema validation, then handle type conversion in Pydantic with mode='before' field validators",
          "impact": "Enables robust parameter handling that works across different MCP client implementations",
          "dateLearned": "2025-08-05",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Database schema changes need backward compatibility",
          "context": "Adding new columns to existing database tables during development",
          "details": "Use NULL defaults for new columns in ALTER TABLE statements to ensure backward compatibility with existing databases",
          "impact": "Prevents database migration issues and allows incremental schema updates",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/database.py"]
        },
        {
          "lesson": "Clear cache directory before testing enhanced parsing",
          "context": "Testing database schema changes and parsing improvements",
          "details": "Clear cache directory before testing enhanced parsing to ensure fresh database creation with new schema and updated parsing logic",
          "impact": "Prevents test failures caused by stale database schemas or cached parsing results",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "tests/"]
        },
        {
          "lesson": "Always run Ruff formatting before committing",
          "context": "Code quality and consistency maintenance",
          "details": "Use 'uv run ruff format .' before committing to ensure consistent code formatting across the project",
          "impact": "Maintains code quality and prevents formatting-related merge conflicts",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["pyproject.toml"]
        },
        {
          "lesson": "Use docs.rs as primary source for stdlib documentation",
          "context": "Rust standard library documentation integration",
          "details": "docs.rs provides comprehensive stdlib documentation access, simpler than attempting to use rust-docs-json component directly",
          "impact": "Simplifies stdlib documentation access and reduces complexity compared to local JSON parsing",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Set lookup for O(1) stdlib crate detection",
          "context": "Performance optimization for standard library crate identification",
          "details": "Use Python set data structure for stdlib crate names to achieve O(1) lookup performance instead of list iteration",
          "impact": "Significantly improves performance when processing many crates by eliminating linear search overhead",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Provide helpful error messages for stdlib download failures",
          "context": "User experience when stdlib documentation is unavailable",
          "details": "When stdlib documentation download fails, provide clear instructions explaining the limitation and suggesting alternatives",
          "impact": "Improves user experience by explaining limitations rather than showing cryptic errors",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Async generator compatibility patterns",
          "context": "Memory optimization implementation with streaming data processing",
          "details": "parse_rustdoc_items must be async generator but generate_embeddings should be sync generator. Mixing async and sync generators requires careful handling - use wrapper functions for backwards compatibility",
          "impact": "Enables streaming data processing while maintaining compatibility with existing sync code and tests",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Test compatibility with generators vs lists",
          "context": "Maintaining backwards compatibility during streaming implementation",
          "details": "Tests expect list-returning functions, not generators. Wrapper functions maintain backwards compatibility while enabling streaming optimizations. Integration tests are critical for streaming pipelines",
          "impact": "Allows incremental migration to streaming while preserving existing test suite",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["tests/test_ingest.py"]
        },
        {
          "lesson": "Memory monitoring implementation patterns",
          "context": "Tracking memory usage during streaming operations",
          "details": "psutil.virtual_memory().percent gives system-wide usage, process.memory_info().rss for process-specific monitoring. Trigger GC after processing chunks of 100+ items for optimal memory management",
          "impact": "Enables proactive memory management preventing OOM errors during large dataset processing",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "MemoryMonitor context manager pattern",
          "context": "Operation-level memory tracking and reporting",
          "details": "Use MemoryMonitor context manager for operation tracking - pre-serialize vectors before batch processing, clear buffers and trigger GC between batches",
          "impact": "Provides structured memory management with clear operation boundaries and automatic cleanup",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Streaming error recovery strategies",
          "context": "Error handling in streaming data processing pipelines",
          "details": "Streaming requires different error recovery strategies than batch processing. Maintain per-batch transactions for database resilience, log memory status at key points for debugging",
          "impact": "Improves system resilience by enabling partial recovery from processing errors without losing all work",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/database.py"]
        },
        {
          "lesson": "Score normalization for ranking consistency",
          "context": "Implementing scoring algorithms for search ranking",
          "details": "Always normalize scores to [0, 1] range for consistency. Use max(0.0, min(1.0, score)) clamping to ensure valid score ranges across different ranking factors",
          "impact": "Prevents ranking inconsistencies and enables reliable score aggregation across multiple ranking factors",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Lazy imports for circular dependency resolution",
          "context": "Avoiding circular dependency issues in module imports",
          "details": "Lazy imports can resolve circular dependencies but may trigger linting warnings. Move imports to module level and use aliases (e.g., app_config) to avoid conflicts while maintaining clean code",
          "impact": "Resolves circular dependency issues while maintaining code quality and IDE support",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "SQLite connection pooling alternatives",
          "context": "Database performance optimization strategies",
          "details": "SQLite connections are lightweight; traditional connection pooling provides less benefit than query optimization. Focus on prepared statement caching and query optimization instead of connection pooling",
          "impact": "Optimizes development effort toward more impactful performance improvements for SQLite-based systems",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Over-fetching for re-ranking flexibility",
          "context": "Search result ranking and retrieval optimization",
          "details": "Over-fetch results (k+10) to allow for re-ranking without constraining initial retrieval. Fetch more results than needed, apply ranking algorithms, then return top k to user",
          "impact": "Enables sophisticated ranking algorithms without being constrained by initial retrieval limitations",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "LRU cache with TTL for search performance",
          "context": "Search result caching strategy for frequent queries",
          "details": "Cache search results with LRU eviction and TTL to improve response times for frequent queries. Balances memory usage with performance gains for repeated searches",
          "impact": "Significantly improves response times for repeated queries while managing memory usage effectively",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Always load sqlite-vec extension when testing database operations",
          "context": "Vector similarity search and database testing",
          "details": "The sqlite-vec extension must be loaded before performing any vector operations or database schema creation that depends on vector functionality. Failure to load the extension results in 'no such function' errors",
          "impact": "Prevents vector operation failures and ensures consistent database functionality across testing and production environments",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/database.py", "tests/"]
        },
        {
          "lesson": "Use Pydantic field_validator with mode='before' for flexible MCP parameter handling",
          "context": "MCP protocol parameter type conversion and validation",
          "details": "MCP clients may send parameters as different types (e.g., string '5' instead of integer 5). Using Pydantic field_validator with mode='before' allows flexible type conversion before validation. Combine with anyOf schema patterns in MCP manifests to pass JSON Schema validation",
          "impact": "Enables robust parameter handling across different MCP client implementations while maintaining type safety",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Partial indexes significantly improve performance for common filter patterns",
          "context": "Database query optimization for filtered searches",
          "details": "Creating partial indexes on commonly filtered columns (e.g., WHERE item_type = 'function') dramatically improves query performance for specific filter patterns. Partial indexes are smaller and more targeted than full column indexes",
          "impact": "Reduces query execution time for filtered searches by orders of magnitude, especially for common filter patterns",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/database.py"]
        },
        {
          "lesson": "Progressive filtering should only be used when result set is small (<10K items)",
          "context": "Search result filtering and performance optimization",
          "details": "Progressive filtering (applying filters after vector search) is only efficient when the initial result set is small. For large result sets, database-level filtering with proper indexes is more performant than in-memory filtering",
          "impact": "Prevents performance degradation when dealing with large datasets by choosing appropriate filtering strategies",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Use anyOf schema pattern in MCP manifests for parameters that may arrive as strings",
          "context": "MCP protocol schema validation and client compatibility",
          "details": "MCP clients may send numeric parameters as strings due to JSON serialization. Use anyOf: [{'type': 'integer'}, {'type': 'string'}] in MCP manifest schemas to handle this variability. This allows JSON Schema validation to pass so Pydantic field validators can perform type coercion",
          "impact": "Ensures compatibility with various MCP client implementations that may serialize parameters differently",
          "dateLearned": "2025-08-06",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "MCP parameter validation requires specific decorator ordering and validation patterns",
          "context": "Implementing robust parameter validation for MCP protocol compatibility",
          "details": "MCP parameter validation follows specific patterns: 1) Use @field_validator(mode='before') BEFORE @classmethod decorator (order matters!), 2) Check None first, then correct type, then string conversion, 3) Use anyOf schema in MCP manifest: {'anyOf': [{'type': 'integer'}, {'type': 'string'}]}, 4) Provide helpful error messages with examples, 5) Test both ValidationError (built-in constraints) and ValueError (custom validators)",
          "impact": "Enables robust parameter handling across different MCP client implementations while maintaining type safety and clear error reporting",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/app.py", "tests/test_app.py"]
        },
        {
          "lesson": "Float vs integer string conversion have different error patterns",
          "context": "Testing numeric parameter validation with different data types",
          "details": "When testing string-to-numeric conversion failures: int() raises ValueError with 'invalid literal' message, while float() raises ValueError with 'could not convert' message. Test assertions must account for these different error message patterns",
          "impact": "Ensures comprehensive test coverage for numeric parameter validation across different data types",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["tests/test_app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "MCP Double Validation Pattern requires anyOf schema flexibility",
          "context": "MCP tools have both JSON Schema and Pydantic validation layers",
          "details": "MCP protocol applies JSON Schema validation before Pydantic field validators can run. When clients send mixed types (e.g., string '5' for integer field), restrictive schemas block validation. Solution: Use anyOf patterns in JSON Schema for flexibility: {'anyOf': [{'type': 'integer'}, {'type': 'string'}]}, then handle coercion in Pydantic field validators",
          "impact": "Enables robust parameter handling across different MCP client implementations while maintaining type safety",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Decorator Order Critical for Pydantic field validators",
          "context": "MCP parameter validation with custom field validators using classmethod decorator",
          "details": "@field_validator must be placed BEFORE @classmethod decorator for proper decorator wrapping. Python decorators are applied bottom-up, so incorrect order (@classmethod @field_validator) prevents the validator from working properly. Correct pattern: @field_validator('field_name', mode='before') followed by @classmethod",
          "impact": "Ensures field validators execute correctly and prevent runtime validation failures",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "None Value Preservation in MCP parameter validators",
          "context": "Handling default values and None inputs in MCP parameter validation",
          "details": "Converting None to default values (e.g., 'latest') in validators breaks application logic that expects None for different default handling. Solution: Preserve None values in validators, handle defaults at application layer (e.g., in ingest_crate function). This allows proper conditional logic based on None vs explicit values",
          "impact": "Maintains proper application logic flow and enables different default handling strategies",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Error Message Best Practices for MCP parameter validation",
          "context": "Providing helpful error messages in Pydantic field validators",
          "details": "Comprehensive error messages should include: 1) Field name for context, 2) Examples of valid values for guidance, 3) What was actually received (truncated to 100 chars to prevent log spam), 4) Clear format pattern. Example: f'{field_name} must be X. Got: {repr(value)[:100]}. Examples: ...'. This helps users understand validation failures and correct their input",
          "impact": "Reduces user confusion and support requests by providing clear, actionable error messages",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Testing MCP Compatibility with multiple input types",
          "context": "Ensuring MCP parameter validation works across different client implementations",
          "details": "Comprehensive MCP validation testing requires: 1) Test with both native types (int, float) and string representations, 2) Use model_validate() to simulate JSON deserialization from MCP clients, 3) Verify whitespace trimming and null handling, 4) Test edge cases like empty strings and whitespace-only inputs, 5) Validate both ValidationError (built-in constraints) and ValueError (custom validators) paths",
          "impact": "Ensures compatibility with various MCP client implementations and prevents runtime failures",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["tests/test_app.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Check whitespace-only queries before stripping for proper error messages",
          "context": "Query preprocessing and user input validation",
          "details": "When validating user queries, check for whitespace-only content before stripping whitespace. This allows providing a specific error message for whitespace-only inputs instead of a generic 'empty query' message after stripping",
          "impact": "Provides more helpful and accurate error messages to users, improving user experience",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "NFKC normalization is irreversible but ideal for search and indexing",
          "context": "Unicode text normalization for search queries",
          "details": "Unicode NFKC (Normalization Form Compatibility Composition) is irreversible but excellent for search/indexing use cases. It handles ligatures (ﬀ → ff), fractions (½ → 1⁄2), superscripts/subscripts, and other compatibility characters. While information is lost, it creates consistent searchable text",
          "impact": "Improves search accuracy and consistency by normalizing varied Unicode representations to canonical forms",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Preserve special technical characters during Unicode normalization",
          "context": "Technical query processing with programming symbols",
          "details": "Technical queries often contain important special characters like :: (scope resolution), <> (generics), # (doc comments). Unicode NFKC normalization preserves these characters while still handling compatibility issues with ligatures and fractions",
          "impact": "Ensures technical search queries remain accurate while benefiting from Unicode normalization",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Provide helpful error messages with examples in Pydantic validators",
          "context": "User input validation and error reporting",
          "details": "Pydantic validators should include specific examples in error messages to help users understand what input is expected. For example, 'Query cannot be empty or contain only whitespace. Example: \"Vec::new\"' is more helpful than just 'Invalid query'",
          "impact": "Reduces user confusion and support requests by providing clear guidance on correct input format",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Module path validation edge cases require careful pattern checking",
          "context": "User input validation for module path patterns in search functionality",
          "details": "Simple strip() validation can make invalid patterns like 'runtime::' appear valid. Check for trailing/leading '::' before stripping whitespace to catch malformed module paths. Invalid patterns should fail validation with clear error messages",
          "impact": "Prevents invalid module path queries from reaching the database and provides clear feedback to users about correct module path syntax",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/models.py", "tests/test_app.py"]
        },
        {
          "lesson": "MCP manifest boolean parameter anyOf pattern implementation",
          "context": "Fixing MCP client boolean parameter validation errors in search_items tool",
          "details": "MCP clients can send boolean parameters as strings ('true', 'false') which fails JSON Schema validation. Solution requires anyOf pattern in manifest: {'anyOf': [{'type': 'boolean'}, {'type': 'string'}]}. This allows FastMCP's JSON Schema validation to pass so Pydantic field validators can perform conversion with mode='before'. Server testing shows port 8000 (not 8080) for REST mode endpoints",
          "impact": "Enables compatibility with MCP clients that serialize boolean parameters as strings while maintaining type safety through Pydantic validation",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "validationFlow": "MCP manifest anyOf → FastMCP JSON Schema → Pydantic field_validator → Boolean conversion",
          "testingNotes": "Use --mode rest to test MCP manifest endpoints at localhost:8000"
        },
        {
          "lesson": "Code example extraction performance optimization",
          "context": "Implementation of search_examples functionality for retrieving code examples",
          "details": "search_examples successfully returns results in ~200ms for warm queries. Language detection adds minimal overhead during ingestion. Deduplication by hash is efficient for preventing duplicates during batch processing",
          "impact": "Enables fast code example retrieval with minimal performance impact from language detection and deduplication",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Backward compatibility patterns for data format changes",
          "context": "Handling transition from old list-based code examples to new JSON object format",
          "details": "When changing data formats, implement compatibility checks that detect old formats and convert them to new formats automatically. Example: detecting list of strings vs list of objects and converting appropriately with default values",
          "impact": "Ensures seamless upgrades without breaking existing cached data or requiring manual migration",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Database schema extraction patterns from file paths",
          "context": "Extracting metadata from database file structure when schema doesn't include all needed fields",
          "details": "When database schema lacks certain fields (like crate_version), extract information from file structure patterns. Use db_path.parent.name for crate name and db_path.stem for version from cache/{crate}/{version}.db structure",
          "impact": "Enables metadata extraction without requiring database schema changes or migrations",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Database path extraction pattern for module search",
          "context": "Converting database file paths to crate names for module pattern construction",
          "details": "Use db_path.parent.name to extract crate name from cache/{crate}/{version}.db structure. Module search patterns follow format: f'{crate_name}::{module_path}::%' for SQL LIKE queries",
          "impact": "Enables efficient module-scoped search by properly constructing database queries with correct crate and module path patterns",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Cache key generation must include all filter parameters",
          "context": "Maintaining cache consistency when adding new search parameters",
          "details": "When adding new filter parameters to search functions, always update _make_key(), get(), and set() methods to include the new parameters. Maintain consistent parameter ordering across all methods to ensure cache hits work correctly",
          "impact": "Prevents cache misses and incorrect result caching when new search parameters are added, ensuring search results remain accurate and performant",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "FastAPI validation error testing patterns",
          "context": "Testing Pydantic validation errors in FastAPI applications",
          "details": "FastAPI returns HTTP 422 status for Pydantic validation errors. Error details are available in response.json()['detail'] as an array of error objects. Test both the status code and specific error message content",
          "impact": "Enables comprehensive testing of input validation by properly checking both HTTP status and detailed error information",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["tests/test_app.py"]
        },
        {
          "lesson": "Background server testing with clean process management",
          "context": "Testing server applications without blocking terminal sessions",
          "details": "Use nohup with output redirection and PID capture for clean server testing: 'nohup uv run uvicorn docsrs_mcp.app:app > server.log 2>&1 & echo $!'. Capture the PID for clean shutdown with kill command",
          "impact": "Prevents terminal hanging during server testing and enables clean process cleanup, improving development workflow",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "SearchCache incompatibility with simple string caching needs",
          "context": "Implementing fuzzy path resolution with caching for performance",
          "details": "SearchCache is designed for embedding-based searches with complex cache key structures, not simple string-based path caching. For simple path caching needs, implement a basic dictionary cache with TTL instead of trying to adapt SearchCache to different use cases",
          "impact": "Prevents over-engineering caching solutions and ensures appropriate tool selection for specific caching requirements",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "FastAPI HTTPException detail format requirements",
          "context": "Returning structured error responses with suggestions in FastAPI",
          "details": "HTTPException with dictionary detail causes 500 error instead of proper status code handling. FastAPI expects string detail for proper error response processing. Include error suggestions directly in the error message text rather than as separate detail fields",
          "impact": "Ensures proper HTTP status code handling and prevents unexpected 500 errors when returning structured error information",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "TestClient async fixture compatibility patterns",
          "context": "Testing async endpoints with FastAPI TestClient and pytest fixtures",
          "details": "TestClient operates synchronously while async fixtures can cause compatibility issues. Mock at the appropriate abstraction level and use synchronous test functions with TestClient rather than trying to mix async fixtures with sync test clients",
          "impact": "Prevents test fixture compatibility issues and ensures reliable test execution patterns",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["tests/test_app.py"]
        },
        {
          "lesson": "RapidFuzz integration best practices for fallback search",
          "context": "Implementing fuzzy string matching as fallback for exact path lookups",
          "details": "RapidFuzz integrates cleanly with minimal code changes when used as fallback-only approach. This preserves exact match performance while adding fuzzy matching capability. Cache paths per crate to avoid repeated database queries and improve fuzzy search performance",
          "impact": "Enables fuzzy search capabilities without impacting exact match performance, providing better user experience for path resolution",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "SlowAPI rate limiting implementation gotchas",
          "context": "Implementing rate limiting with SlowAPI middleware in FastAPI applications",
          "details": "SlowAPI requires: 1) Request parameter MUST be included in endpoint function signatures or rate limiting won't work, 2) Middleware order matters - last added is outermost, 3) Memory backend doesn't share state between workers, use Redis for production, 4) Use limiter.limit() decorator on each endpoint that needs rate limiting, 5) Set app.state.limiter after app initialization for proper integration",
          "impact": "Ensures proper rate limiting implementation and prevents common configuration issues that lead to ineffective rate limiting",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/middleware.py", "src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Rate limiting testing requires concurrent request patterns",
          "context": "Testing rate limiting functionality to ensure proper enforcement",
          "details": "Effective rate limiting tests require: 1) Use concurrent requests (asyncio.gather) to test rate limiting behavior, 2) Verify both successful responses (200) and rate-limited responses (429), 3) Check that health/monitoring endpoints remain unprotected, 4) Test rate limit headers (X-RateLimit-*) in responses, 5) Validate that rate limits reset properly over time",
          "impact": "Ensures rate limiting works correctly under realistic concurrent load conditions and provides proper feedback to clients",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["tests/test_app.py", "src/docsrs_mcp/middleware.py"]
        },
        {
          "lesson": "Rate limiting integration patterns for clean code organization",
          "context": "Organizing rate limiting code for maintainability and separation of concerns",
          "details": "Best practices for rate limiting integration: 1) Create dedicated middleware.py for clean separation from main app logic, 2) Use limiter.limit() decorator on individual endpoints for granular control, 3) Set app.state.limiter after app initialization to ensure proper middleware access, 4) Add custom exception handler for RateLimitExceeded to provide consistent error responses, 5) Configure different limits for different endpoint types (search vs health checks)",
          "impact": "Maintains clean code architecture while enabling flexible and maintainable rate limiting configuration",
          "dateLearned": "2025-08-07",
          "relatedFiles": ["src/docsrs_mcp/middleware.py", "src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Path alias resolution implementation for improved user experience",
          "context": "Implementing path alias resolution to handle common user path shortcuts in Rust documentation search",
          "details": "Users often use common aliases like 'serde::Deserialize' instead of full rustdoc paths 'serde::de::Deserialize'. Solution: 1) Implement static PATH_ALIASES dictionary with O(1) lookup, 2) Create resolve_path_alias() function in fuzzy_resolver.py, 3) Add mapping for common patterns: serde::Deserialize → serde::de::Deserialize, tokio::spawn → tokio::task::spawn, Result → std::result::Result, 4) Integrate before database query for minimal performance impact (<1ms overhead), 5) Test with both unit tests and integration tests for comprehensive coverage",
          "impact": "Significantly improves user experience by handling common path aliases automatically while maintaining sub-500ms response time requirements. Reduces 404 errors for commonly accessed items",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "testingStrategy": "Use --mode rest flag for easier HTTP/curl testing instead of STDIO mode during development and verification"
        },
        {
          "lesson": "PATH_ALIASES expansion for common Rust patterns",
          "context": "Improving path resolution for common Rust module patterns and shortcuts",
          "details": "Expand PATH_ALIASES in fuzzy_resolver.py with common patterns like 'tokio::spawn': 'tokio::task::spawn' to improve user experience when searching with abbreviated paths",
          "impact": "Reduces friction for users who use common shorthand patterns when searching for Rust functions and modules",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "implementationNotes": {
            "aliasPatterns": "Focus on commonly used shortcuts like tokio::spawn -> tokio::task::spawn",
            "performanceImpact": "O(1) dictionary lookup adds minimal overhead",
            "maintenanceStrategy": "Add aliases based on user feedback and common usage patterns"
          }
        },
        {
          "lesson": "Debug mode parameter for search query analysis",
          "context": "Adding debug capabilities for analyzing search query performance and scoring",
          "details": "Add debug=true parameter to search queries to return detailed scoring information including similarity scores, filter matches, and performance metrics",
          "impact": "Enables better understanding of search behavior and troubleshooting of relevance issues",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "implementationNotes": {
            "debugOutput": "Include similarity scores, filter matches, query timing, and result ranking details",
            "performanceConsideration": "Only enable debug output when explicitly requested to avoid performance overhead",
            "useCases": "Query optimization, relevance tuning, and search behavior analysis"
          }
        },
        {
          "lesson": "See-also suggestions implementation patterns",
          "context": "Implementing related suggestions functionality for search results with proper deduplication and graceful error handling",
          "details": "See-also suggestions require: 1) Exclude original search results to avoid duplicates using path exclusion sets, 2) Use similarity = 1.0 - distance for sqlite-vec cosine similarity scoring, 3) Add suggestions only to first search result to avoid UI redundancy, 4) Implement graceful degradation with empty suggestions array on any exception, 5) Mock Path objects with MagicMock(spec=Path) in tests with proper exists() method configuration",
          "impact": "Provides valuable related content discovery while maintaining clean UI and robust error handling",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py", "tests/test_app.py"],
          "implementationNotes": {
            "deduplication": "Use set comprehension for O(1) path exclusion: exclude_paths = {result.path for result in original_results}",
            "scoringFormula": "Convert distance to similarity: similarity = 1.0 - distance (sqlite-vec uses cosine distance)",
            "uiOptimization": "Add suggestions only to first result to prevent overwhelming the interface",
            "errorHandling": "Return empty suggestions array on exceptions to maintain search functionality",
            "testingPatterns": "Mock Path objects with spec parameter and configure exists() method explicitly"
          }
        },
        {
          "lesson": "Graceful degradation patterns for optional features",
          "context": "Implementing see-also suggestions as optional enhancement that doesn't break core functionality",
          "details": "Optional features should: 1) Never throw exceptions that break core functionality, 2) Return empty/null results on failure, 3) Log errors for debugging but continue execution, 4) Provide clear fallback behavior when external dependencies fail, 5) Design with graceful degradation from the start rather than adding it later",
          "impact": "Ensures core search functionality remains reliable even when optional features encounter errors",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "UI redundancy prevention in suggestion systems",
          "context": "Preventing information overload when displaying related suggestions to users",
          "details": "Suggestion systems should: 1) Only add suggestions to primary or first result to avoid repetition, 2) Exclude original search results from suggestions to provide new information, 3) Limit suggestion count to prevent overwhelming users (typically 3-5 suggestions), 4) Consider UI space and user attention when designing suggestion placement, 5) Make suggestions clearly distinguishable from primary results",
          "impact": "Improves user experience by providing valuable suggestions without cluttering the interface",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Rustdoc JSON impl block representation patterns",
          "context": "Implementing trait implementation search functionality in rustdoc JSON parsing",
          "details": "Rustdoc JSON represents impl blocks with empty names, requiring extraction from inner.trait and inner.for fields. Composite names like 'TraitName_for_TypeName' work well for impl block identification. Inherent impls (no trait) can be handled by checking for null trait field. The existing streaming parser architecture easily accommodates new item types without structural changes.",
          "impact": "Enables accurate trait implementation search without requiring database schema changes by leveraging existing item_type field patterns. Provides flexible naming scheme for both trait impls and inherent impls.",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py"],
          "implementationNotes": {
            "emptyNames": "Impl blocks have empty name field - extract from inner.trait and inner.for instead",
            "compositeNaming": "Use 'TraitName_for_TypeName' pattern for trait implementations",
            "inherentImpls": "Check trait field for null to identify inherent implementations vs trait implementations",
            "streamingCompatible": "Existing streaming parser handles new impl item types without architecture changes",
            "schemaCompatible": "No database schema changes needed - uses existing item_type field infrastructure"
          },
          "parsingPatterns": {
            "traitImpl": "Extract from inner.trait.name and inner.for to create composite identifier",
            "inherentImpl": "Use inner.for as identifier when inner.trait is null",
            "typeExtraction": "Both trait and for fields may contain complex type information requiring careful parsing",
            "nameGeneration": "Generate meaningful searchable names from otherwise empty name fields in rustdoc JSON"
          }
        },
        {
          "lesson": "Background task reference management patterns",
          "context": "Implementing background schedulers with proper task lifecycle management",
          "details": "Background tasks must maintain strong references to prevent garbage collection. Use a set data structure (self.background_tasks = set()) to store task references, then add callback functions with task.add_done_callback(lambda t: self.background_tasks.discard(t)) for automatic cleanup when tasks complete",
          "impact": "Prevents background tasks from being garbage collected prematurely while ensuring proper cleanup to avoid memory leaks",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/scheduler.py"],
          "codePattern": "self.background_tasks = set(); task = asyncio.create_task(func()); self.background_tasks.add(task); task.add_done_callback(lambda t: self.background_tasks.discard(t))"
        },
        {
          "lesson": "Jitter implementation for distributed scheduler coordination",
          "context": "Preventing synchronized execution when multiple schedulers run simultaneously",
          "details": "Add random jitter to scheduler intervals using formula: base_interval + random.uniform(-jitter_range, jitter_range). Default ±10% variance (jitter_range = base_interval * 0.1) provides good distribution without significantly affecting scheduling accuracy",
          "impact": "Prevents thundering herd problems when multiple scheduler instances start simultaneously, distributing load more evenly",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/scheduler.py"],
          "implementationNotes": {
            "formula": "jittered_interval = base_interval + random.uniform(-jitter_range, jitter_range)",
            "defaultVariance": "±10% of base interval",
            "purpose": "Load distribution and coordination prevention"
          }
        },
        {
          "lesson": "Memory-aware background task scheduling",
          "context": "Implementing resource-conscious background operations to prevent OOM errors",
          "details": "Check system memory usage before starting memory-intensive background tasks using psutil.virtual_memory().percent. Set reasonable thresholds (e.g., 80%) to leave headroom for memory spikes during processing. Skip operations when memory usage is too high and reschedule for next interval",
          "impact": "Prevents out-of-memory errors during background processing while maintaining system stability under varying load conditions",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/scheduler.py"],
          "implementationNotes": {
            "memoryCheck": "psutil.virtual_memory().percent < 80",
            "threshold": "80% leaves headroom for processing spikes",
            "fallbackBehavior": "Skip operation and wait for next scheduled interval"
          }
        },
        {
          "lesson": "Environment-driven scheduler configuration best practices",
          "context": "Making background schedulers configurable without requiring code changes",
          "details": "Use environment variables for all scheduler settings: enable/disable flags, intervals, memory thresholds, and jitter ranges. Default to enabled for better user experience but provide clear disable mechanism (SCHEDULER_ENABLED=false) for resource-constrained deployments. Document all configuration options clearly",
          "impact": "Enables flexible deployment configurations without code modifications while maintaining good defaults for most use cases",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/scheduler.py", "README.md"],
          "configurationPattern": {
            "enableFlag": "SCHEDULER_ENABLED (default: true)",
            "intervals": "Environment variables with reasonable defaults",
            "thresholds": "Configurable memory and resource limits",
            "jitter": "Configurable variance ranges"
          }
        },
        {
          "lesson": "Background task testing patterns with timeouts",
          "context": "Testing background schedulers and long-running tasks in test suites",
          "details": "Use asyncio.wait_for() with short timeouts when testing background tasks. Background tasks will timeout (expected behavior), but this allows testing of initialization, configuration, and cleanup without waiting for full execution cycles. Test both enabled and disabled states for backward compatibility",
          "impact": "Enables comprehensive testing of background task systems without extending test suite execution time or requiring complex mocking",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["tests/test_scheduler.py"],
          "testingPatterns": {
            "timeoutPattern": "asyncio.wait_for(background_task(), timeout=0.1)",
            "expectedBehavior": "TimeoutError is normal and expected",
            "statesTesting": "Test both enabled=True and enabled=False configurations",
            "cleanupTesting": "Verify proper task cleanup and reference management"
          }
        },
        {
          "lesson": "Simple direct field extension approach for Pydantic model enhancement",
          "context": "Adding tutorial fields to existing Pydantic models for enhanced API responses",
          "details": "When extending Pydantic models with new optional fields, direct field addition is more effective than complex nested model structures. Add Optional[str] fields directly to existing models (SearchResult, DocumentationItem) with appropriate default values (None). This approach maintains backward compatibility while enabling new functionality",
          "impact": "Enables clean model extensions without breaking existing API consumers or complicating model hierarchy",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "Ruff automatically formats Pydantic field definitions for consistency",
          "context": "Code formatting and Pydantic model field organization",
          "details": "Ruff's formatter automatically handles Pydantic field definition formatting, ensuring consistent spacing, alignment, and organization of field declarations. This includes proper handling of Optional types, default values, and field descriptions across model definitions",
          "impact": "Maintains consistent code style without manual formatting effort, improves code readability and maintainability",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/models.py", "pyproject.toml"]
        },
        {
          "lesson": "Tutorial content should be concise for token efficiency",
          "context": "Implementing tutorial fields with content length optimization",
          "details": "Tutorial content should be kept concise (15-30 tokens) to stay well under the 200 token limit per response. Focus on essential usage patterns, brief code examples, and key concepts rather than comprehensive documentation. This ensures tutorial additions enhance responses without significantly impacting token budgets",
          "impact": "Provides valuable tutorial information while maintaining efficient token usage and response performance",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/ingest.py"]
        },
        {
          "lesson": "Test both presence and content of tutorial fields for comprehensive validation",
          "context": "Testing strategies for optional Pydantic model fields",
          "details": "When testing tutorial field implementations, verify both field presence (is not None) and content quality. Test scenarios should include: 1) Fields are populated when tutorial content is available, 2) Content matches expected format and length constraints, 3) Fields remain None when no tutorial content exists, 4) Backward compatibility with clients not expecting tutorial fields",
          "impact": "Ensures tutorial field implementation works correctly across all use cases while maintaining backward compatibility",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["tests/test_app.py", "tests/test_models.py", "src/docsrs_mcp/models.py"]
        },
        {
          "lesson": "FastAPI/MCP automatically serializes optional None fields maintaining backward compatibility",
          "context": "API serialization behavior with optional Pydantic fields",
          "details": "FastAPI and MCP automatically handle serialization of optional fields with None values, maintaining backward compatibility with existing API consumers. Fields with None values are properly serialized in JSON responses, allowing clients to safely ignore fields they don't recognize while new clients can utilize the additional information",
          "impact": "Enables safe API extension without breaking existing integrations, supports gradual feature rollout",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/models.py", "src/docsrs_mcp/app.py"],
          "serializationBehavior": {
            "noneValues": "Serialized as null in JSON responses",
            "backwardCompatibility": "Existing clients can safely ignore new fields",
            "forwardCompatibility": "New clients can utilize additional tutorial information"
          }
        },
        {
          "lesson": "Pydantic model extension patterns for similar enhancements",
          "context": "Guidelines for future Pydantic model enhancements based on tutorial field implementation",
          "details": "Future Pydantic model extensions should follow established patterns: 1) Use Optional[Type] with None defaults for backward compatibility, 2) Add fields directly to existing models rather than creating nested structures, 3) Consider token efficiency for content fields, 4) Test both field presence and content validation, 5) Leverage Ruff for consistent formatting, 6) Verify serialization behavior maintains API compatibility",
          "impact": "Provides reusable patterns for future model enhancements, ensuring consistency and reliability across API evolution",
          "dateLearned": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/models.py"],
          "implementationChecklist": [
            "Use Optional[Type] with None defaults",
            "Add fields directly to existing models",
            "Consider content length and token efficiency",
            "Test field presence and content validation", 
            "Run Ruff formatting for consistency",
            "Verify backward/forward compatibility"
          ]
        },
        {
          "lesson": "RapidFuzz v3.0+ preprocessing changes for fuzzy matching implementation",
          "context": "Implementing enhanced fuzzy matching with composite scoring for path resolution",
          "details": "RapidFuzz v3.0+ removed default preprocessing - must explicitly use processor=default_process for case normalization. Unicode normalization is not built-in and requires unicodedata.normalize('NFC') for consistency. The resolve_path_alias function is async and tests must use @pytest.mark.asyncio with await calls",
          "impact": "Prevents fuzzy matching failures due to preprocessing changes and ensures proper test execution with async functions",
          "dateLearned": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py", "tests/test_fuzzy_resolver.py"],
          "implementationNotes": {
            "preprocessing": "Must explicitly pass processor=default_process to RapidFuzz functions",
            "unicodeNormalization": "Use unicodedata.normalize('NFC', text) for consistent character representation",
            "asyncTesting": "All tests for resolve_path_alias must use @pytest.mark.asyncio and await",
            "versionCompatibility": "v3.0+ breaks backward compatibility with default preprocessing behavior"
          }
        },
        {
          "lesson": "Composite scoring algorithm significantly improves fuzzy matching accuracy",
          "context": "Enhanced path matching with multiple similarity algorithms for better results",
          "details": "Composite scoring using multiple RapidFuzz algorithms (ratio, token_sort_ratio, partial_ratio) with weighted averages provides ~25% better accuracy than single algorithm approaches. Path component bonuses help prioritize exact final component matches (e.g., 'Vec::new' gets bonus for exact 'new' match). This approach balances comprehensive similarity analysis with path-specific relevance",
          "impact": "Dramatically improves path resolution accuracy while maintaining performance, reduces false negatives in fuzzy search results",
          "dateLearned": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "implementationNotes": {
            "algorithms": "Combines ratio, token_sort_ratio, and partial_ratio with weighted averaging",
            "pathBonuses": "Final path component exact matches receive additional scoring bonus",
            "accuracyImprovement": "~25% better results compared to single algorithm approaches",
            "weightingStrategy": "Balanced weighting preserves both overall similarity and path-specific relevance"
          }
        },
        {
          "lesson": "Tutorial content pattern optimization for token efficiency",
          "context": "Implementing MCP tool tutorials with structured content patterns for optimal context usage",
          "details": "4-line structure (purpose, mechanism, performance, best practice) works well for tutorial content, keeping descriptions under 300 characters for optimal token usage. Use active voice and action-oriented language for maximum clarity. This structured approach provides comprehensive guidance while maintaining context efficiency",
          "impact": "Enables rich tutorial content without significant token overhead, improving user experience while maintaining performance",
          "dateLearned": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Direct modification approach simplifies tutorial implementation",
          "context": "Adding tutorial content to MCP tools without complex infrastructure changes",
          "details": "Direct modification of app.py is simpler than building complex tutorial infrastructure. Inline content eliminates file I/O overhead and following existing patterns (like start_pre_ingestion) ensures consistency with established code patterns. This pragmatic approach enables quick feature delivery",
          "impact": "Reduces development complexity while maintaining code consistency, enables faster feature implementation",
          "dateLearned": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Tutorial validation success metrics and testing patterns",
          "context": "Ensuring tutorial content meets requirements and integrates properly with existing systems",
          "details": "All tutorials validated under 1000 character limit (actual range: 205-911 chars) with tutorial test (test_mcp_manifest_includes_tutorials) passing successfully. Manifest generation remains fast with embedded content approach. Pre-existing test failures were unrelated to tutorial changes (health check format, validation messages)",
          "impact": "Provides confidence in tutorial implementation quality while maintaining system performance and test suite integrity",
          "dateLearned": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py", "tests/test_app.py"]
        },
        {
          "lesson": "Character count validation script utility for content management",
          "context": "Implementing simple validation tools for ensuring tutorial content meets length requirements",
          "details": "Simple Python script can validate tutorial lengths effectively before deployment. Character count validation is important for maintaining performance requirements and ensuring consistent user experience across all tutorial content",
          "impact": "Prevents content length issues from reaching production, ensures consistent tutorial quality",
          "dateLearned": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py"]
        },
        {
          "lesson": "Claude Code MCP client doesn't support anyOf JSON schemas",
          "context": "MCP parameter validation failure resolution after extensive anyOf pattern implementation",
          "details": "After implementing comprehensive anyOf patterns throughout all MCP tools, discovered that Claude Code MCP client completely rejects anyOf schema patterns with 'Input validation error: not valid under any of the given schemas'. The solution is to eliminate anyOf patterns entirely and use simple string types in the MCP manifest while handling all type coercion in Pydantic field validators. Field validators can handle complexity that JSON schemas cannot.",
          "impact": "Enables full compatibility with Claude Code MCP client while maintaining robust server-side validation and type safety through Pydantic",
          "dateLearned": "2025-08-13",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "implementationNotes": {
            "schemaDesign": "Use single string types with examples and format hints in descriptions",
            "validationPattern": "Implement comprehensive type coercion in @field_validator methods with mode='before'",
            "clientTesting": "Always test with actual MCP clients, not just REST API endpoints",
            "booleanPattern": "String to boolean conversion with comprehensive value recognition (true/false, 1/0, yes/no, on/off, t/y)",
            "errorHandling": "Provide sensible defaults for invalid inputs rather than strict validation failures"
          }
        },
        {
          "error": "MCP client validation compatibility issues with anyOf schema patterns",
          "rootCause": "Claude Code MCP client cannot handle anyOf JSON schema patterns, causing 'Input validation error: not valid under any of the given schemas' failures despite correct implementation",
          "solution": "Replace all anyOf patterns with simple string-only schema types in MCP manifest. Use Pydantic field validators with mode='before' for comprehensive type coercion from strings to proper types (int, float, bool). All numeric and boolean parameters now use string type in schema with validation handling the conversion",
          "context": "MCP parameter validation failing across all tools despite implementing proper anyOf schema patterns for type flexibility",
          "implementation": [
            "Changed all numeric parameters to 'type': 'string' in MCP manifest schema generation",
            "Changed all boolean parameters to 'type': 'string' in MCP manifest schema generation", 
            "Enhanced field validators to handle string-to-int, string-to-float, and string-to-bool conversion",
            "Added module filtering in get_crate_summary to reduce noise from internal implementation details",
            "Maintained all existing validation logic and bounds checking in Pydantic validators"
          ],
          "pattern": "Use string-only schemas in MCP manifests combined with robust Pydantic field validators for type coercion. This pattern works around MCP client schema limitations while maintaining server-side type safety",
          "dateEncountered": "2025-08-15",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codeExample": "# Schema generation - use string only\n\"k\": {\n    \"type\": \"string\",\n    \"description\": \"Number of results (integer between 1-100)\"\n}\n\n# Field validator handles conversion\n@field_validator('k', mode='before')\n@classmethod\ndef coerce_k(cls, v):\n    return coerce_to_int_with_bounds(v, min_val=1, max_val=100)",
          "lesson": "MCP clients may have stricter schema validation than servers expect. Always test with actual MCP clients, not just REST endpoints. Use simple schema types with complex validation logic rather than complex schemas with simple validation",
          "preventionPattern": "For MCP compatibility: simple schemas + complex validators > complex schemas + simple validators"
        },
        {
          "error": "FastMCP auto-generates schemas that bypass custom manifest definitions",
          "context": "FastMCP.from_fastapi() generates tool schemas from Pydantic models directly, causing validation conflicts when Claude Code sends native types",
          "rootCause": "Double validation architecture (JSON Schema → Pydantic) creates barriers where parameters are rejected before field validators can coerce them",
          "solution": "Use string-only schemas with comprehensive field validators - avoid anyOf patterns that Claude Code may not handle correctly",
          "evidence": [
            "searchItems fails with k=3 (integer) - rejected at schema validation",
            "startPreIngestion fails with count=10 - numeric parameter validation error", 
            "ingestCargoFile fails with concurrency=3 - type coercion blocked"
          ],
          "prevention": "Define all parameters as type: 'string' in manifest, use field_validator(mode='before') for coercion to avoid schema-level validation conflicts",
          "dateEncountered": "2025-08-15",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "codePattern": "# Schema: simple string type\n\"parameter\": {\"type\": \"string\", \"description\": \"Integer value (1-100)\"}\n\n# Validator: comprehensive coercion\n@field_validator('parameter', mode='before')\n@classmethod\ndef coerce_param(cls, v):\n    return coerce_to_int_with_bounds(v, min_val=1, max_val=100)",
          "status": "IDENTIFIED",
          "architecturalImpact": "FastMCP auto-schema generation conflicts with manual manifest customization"
        },
        {
          "error": "anyOf patterns may not work with Claude Code",
          "context": "Claude Code has known issues with anyOf schema patterns in MCP tool definitions",
          "rootCause": "Claude Code's MCP client implementation may have stricter schema validation that doesn't properly handle anyOf unions",
          "solution": "Use string-only schemas with comprehensive field validators instead of anyOf patterns for better compatibility",
          "alternativeApproach": "Define all parameters as type: 'string' in manifest and handle all type coercion in Pydantic field validators",
          "prevention": "Avoid complex schema patterns (anyOf, oneOf) in MCP manifests when Claude Code is the primary target client",
          "dateEncountered": "2025-08-15", 
          "relatedFiles": ["src/docsrs_mcp/app.py"],
          "compatibilityNote": "What works in JSON Schema specification may not work in all MCP client implementations",
          "testingStrategy": "Always test with actual Claude Code MCP client, not just REST endpoints or other MCP clients",
          "status": "HYPOTHESIS_TESTING"
        },
        {
          "lesson": "MCP client compatibility trumps protocol purity",
          "context": "When choosing between ideal MCP protocol implementation and Claude Code compatibility",
          "insight": "Cannot follow MCP best practices perfectly when Claude Code is the primary target client",
          "tradeoffs": [
            "Accept string-only schemas over proper typed schemas for compatibility",
            "Use comprehensive field validators instead of schema-level type definitions",
            "Prioritize working solutions over theoretical protocol correctness"
          ],
          "prevention": "Design MCP tools with primary client constraints in mind, not just protocol specifications",
          "dateLearned": "2025-08-15",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/models.py"],
          "designPrinciple": "Practical compatibility over theoretical purity",
          "implementationGuidance": "When in doubt, choose the approach that works with Claude Code even if it's not the 'correct' way according to MCP specifications"
        },
        {
          "error": "Claude Code MCP client rejects anyOf schemas and sends native JSON types",
          "rootCause": "Claude Code has two critical bugs: 1) Sends native JSON types (integers, booleans) instead of strings, 2) Completely rejects anyOf/oneOf/allOf schema patterns",
          "solution": "Implement comprehensive schema override system with override_fastmcp_schemas() function that intercepts FastMCP auto-generated schemas, replaces integer/boolean schemas with simple string types, and removes all anyOf patterns",
          "context": "Input validation errors with anyOf schemas where parameters work in REST but fail in MCP mode with 'is not valid under any of the given schemas' errors",
          "implementation": [
            "Schema Override Function: override_fastmcp_schemas() in mcp_server.py intercepts FastMCP auto-generated schemas",
            "Type conversion: Replaces integer/boolean schemas with simple string types",
            "Pattern removal: Removes all anyOf patterns completely",
            "Timing: Called before server startup to modify schemas at runtime",
            "Field Validators: All validators use mode='before' to handle native types, strings, numbers",
            "Boolean parsing: Comprehensive boolean parsing (true/1/yes/on/t/y)",
            "Bounds checking: Proper bounds checking for numeric types"
          ],
          "affectedTools": ["searchItems", "startPreIngestion", "ingestCargoFile", "compareVersions", "searchExamples"],
          "filesModified": ["src/docsrs_mcp/mcp_server.py", "src/docsrs_mcp/models.py"],
          "testingCommands": [
            "SearchItemsRequest(crate_name='tokio', query='async', k=5, has_examples=True)",
            "SearchItemsRequest(crate_name='tokio', query='async', k='5', has_examples='true')"
          ],
          "futureRemoval": "When Claude Code fixes anyOf support, remove: 1) override_fastmcp_schemas() function, 2) Its call in run_mcp_server(), 3) Keep field validators as they provide good type flexibility",
          "dateImplemented": "2025-08-15",
          "status": "WORKING - Fully tested with mixed parameter types",
          "lesson": "Complete schema overrides may be necessary for MCP client compatibility, not just field validators",
          "pattern": "Runtime schema modification to work around client-specific limitations",
          "debuggingTechnique": "Test with both native JSON types and string representations to verify comprehensive type handling"
        },
        {
          "issue": "MCP tools not waiting for ingestion to complete",
          "context": "User reported that tools should ensure ingestion completes before returning results",
          "solution": "Add `await ingest_crate(crate_name, version)` as the first operation in all MCP tool functions. The await keyword ensures the ingestion completes synchronously before proceeding. The existing per-crate locks prevent duplicate ingestion attempts.",
          "lesson": "The simplest solution is often the best. Rather than creating complex validation layers or decorator patterns, following the existing proven pattern (already working in 6 other tools) solved the problem with a single line of code.",
          "pattern": "Auto-ingestion pattern ensures: 1) Automatic ingestion if crate not cached, 2) Synchronous completion before data access, 3) No duplicate work due to per-crate locks, 4) Consistent behavior across all MCP tools",
          "dateEncountered": "2025-08-18",
          "relatedFiles": ["src/docsrs_mcp/mcp_tools.py", "src/docsrs_mcp/ingest.py"],
          "codeExample": "# Add as first line in all MCP tool functions:\nawait ingest_crate(crate_name, version)\n\n# This ensures ingestion completes before proceeding\n# Existing locks prevent duplicate ingestion attempts",
          "debuggingTechnique": "Verify ingestion completion by checking database state before tool execution"
        }
      ]
    },
    "performanceInsights": {
      "description": "Performance insights and optimizations discovered during implementation",
      "entries": [
        {
          "insight": "Enhanced fuzzy scoring adds minimal performance overhead",
          "context": "Composite scoring algorithm performance analysis during path resolution enhancement",
          "details": "Enhanced scoring with multiple RapidFuzz algorithms adds less than 5ms overhead while improving accuracy by approximately 25%. The composite approach (ratio + token_sort_ratio + partial_ratio with path bonuses) maintains sub-500ms response time requirements even with larger path datasets",
          "impact": "Enables significantly better fuzzy matching results without meaningful performance degradation",
          "dateMeasured": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/fuzzy_resolver.py"],
          "metrics": {
            "overheadAdded": "<5ms per fuzzy search operation",
            "accuracyGain": "~25% improvement over single algorithm",
            "responseTimeImpact": "Maintains sub-500ms requirement",
            "scalability": "Performance remains consistent with larger path datasets"
          }
        },
        {
          "insight": "MMR enhancement requires embedding alignment during result sorting",
          "context": "Implementing semantic similarity in MMR diversification algorithm",
          "details": "When adding semantic similarity to MMR, embeddings must be passed alongside results and kept aligned during sorting operations. Use zip/unzip pattern to maintain correspondence between results and their embeddings. Cosine similarity calculation: np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))",
          "impact": "Prevents misaligned embeddings that would corrupt similarity calculations and result ranking",
          "dateMeasured": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/database.py"],
          "metrics": {
            "alignmentPattern": "zip(results, embeddings) → sort → unzip back to separate lists",
            "similarityFormula": "np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))",
            "integrityRequirement": "Embeddings must remain 1:1 aligned with search results",
            "performanceNote": "Alignment operations add minimal overhead to MMR calculations"
          }
        },
        {
          "insight": "Query preprocessing with term expansion benefits from order-preserving deduplication",
          "context": "Implementing British-to-American spelling normalization and term expansion",
          "details": "Term expansion should preserve original terms while adding expansions. Use set for deduplication but maintain original order. Configure expansions in config.py for maintainability rather than hardcoding in preprocessing logic",
          "impact": "Maintains query intent while expanding coverage, prevents duplicate terms from affecting relevance scoring",
          "dateMeasured": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/config.py"],
          "metrics": {
            "expansionPattern": "Original terms preserved + normalized variants added",
            "deduplicationMethod": "Set-based with order preservation",
            "configurationLocation": "config.py for maintainable expansion rules",
            "queryIntegrityMaintenance": "Original intent preserved while expanding coverage"
          }
        },
        {
          "insight": "Path caching with 5-minute TTL crucial for fuzzy search performance",
          "context": "Caching strategy optimization for repeated fuzzy path lookups",
          "details": "Caching resolved paths with 5-minute TTL provides ~90% cache hit rate for common path lookups, dramatically reducing database queries. Single database query pattern must be maintained to avoid N+1 query problems when building path datasets for fuzzy matching. TTL balances freshness with performance for path resolution scenarios",
          "impact": "Prevents repeated expensive database operations while maintaining reasonable data freshness for path resolution",
          "dateMeasured": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/fuzzy_resolver.py"],
          "metrics": {
            "cacheHitRate": "~90% for common path patterns",
            "ttlStrategy": "5-minute TTL balances freshness and performance",
            "queryReduction": "Single database query pattern prevents N+1 problems",
            "memoryFootprint": "Minimal memory impact with per-crate cache isolation"
          }
        }
      ]
    },
    "cicdBestPractices": {
      "description": "Best practices for CI/CD pipeline implementation and deployment",
      "entries": [
        {
          "practice": "Consistent UV usage across platforms",
          "description": "Always use 'uv run' pattern instead of direct executable calls to ensure Windows compatibility",
          "rationale": "Direct executable calls can fail on Windows due to path resolution issues, while 'uv run' provides consistent cross-platform behavior",
          "implementation": "Replace direct calls like 'docsrs-mcp' with 'uv run docsrs-mcp' in all CI workflows",
          "dateAdded": "2025-08-08"
        },
        {
          "practice": "Proper PyPI authentication",
          "description": "Use UV_PUBLISH_TOKEN environment variable for PyPI publishing authentication",
          "rationale": "UV_PUBLISH_TOKEN is the correct environment variable for PyPI authentication, not UV_PUBLISH_PASSWORD",
          "implementation": "Set UV_PUBLISH_TOKEN in CI secrets and use in publishing workflows",
          "dateAdded": "2025-08-08"
        },
        {
          "practice": "Background process management in CI",
          "description": "Use nohup with PID capture for testing background servers in CI environments",
          "rationale": "Prevents CI runners from hanging on background processes and enables proper cleanup",
          "implementation": "Pattern: 'SERVER_PID=$(nohup uv run server > server.log 2>&1 & echo $!)' followed by 'kill $SERVER_PID'",
          "dateAdded": "2025-08-08"
        },
        {
          "practice": "UV version consistency",
          "description": "Pin UV versions across all CI jobs to prevent cache deserialization errors",
          "rationale": "Different UV versions can cause cache corruption and build failures due to incompatible cache formats",
          "implementation": "Use specific UV version in CI workflows and clear cache when upgrading versions",
          "dateAdded": "2025-08-08"
        },
        {
          "practice": "PyPI-compatible builds",
          "description": "Use 'uv build --no-sources' for PyPI publishing to ensure package compatibility",
          "rationale": "Including source files can cause PyPI build failures and package incompatibility issues",
          "implementation": "Add --no-sources flag to build commands in publishing workflows",
          "dateAdded": "2025-08-08"
        },
        {
          "practice": "Runner-specific cache strategies",
          "description": "Implement different cache strategies for GitHub-hosted vs self-hosted runners",
          "rationale": "Self-hosted runners have persistent storage and different performance characteristics than GitHub-hosted runners",
          "implementation": "Use local disk cache for self-hosted runners, GitHub Actions cache for hosted runners",
          "dateAdded": "2025-08-08"
        }
      ]
    },
    "bestPractices": {
      "description": "Recommended practices and patterns for development",
      "implementation_patterns": [
        {
          "pattern": "Embeddings warmup",
          "implementation": "Comprehensive dual-mode warmup with representative samples",
          "description": "Eliminate cold-start latency through proactive model warming with fire-and-forget pattern",
          "details": {
            "samples": "Use 3-5 representative text samples (short, medium, long) for thorough warmup",
            "execution": "Fire-and-forget with asyncio.create_task() to avoid blocking startup",
            "tracking": "Global status tracking for health endpoint integration",
            "dualMode": "REST mode: startup_event + asyncio, MCP mode: threading + separate event loop"
          }
        },
        {
          "pattern": "Export endpoints",
          "implementation": "Use existing MCP tool endpoint patterns from app.py",
          "description": "Leverage FastMCP integration patterns for consistent API design"
        },
        {
          "pattern": "Batch operations",
          "implementation": "Leverage existing DB_BATCH_SIZE=999 pattern",
          "description": "Use consistent batch sizes across all database operations"
        },
        {
          "pattern": "Error messages",
          "implementation": "Extend validation.py with contextual examples",
          "description": "Include valid ranges and examples in all error messages"
        },
        {
          "pattern": "Version diff",
          "implementation": "Create new table following embeddings table pattern",
          "description": "Use consistent table schema patterns for new features"
        },
        {
          "pattern": "MMR diversification",
          "implementation": "Implement Maximum Marginal Relevance algorithm with configurable lambda parameter",
          "description": "Balance search result relevance and diversity to prevent homogeneous results while maintaining quality",
          "details": {
            "algorithm": "MMR = λ * relevance + (1-λ) * diversity",
            "configuration": "RANKING_DIVERSITY_LAMBDA=0.6 (relevance-diversity balance), RANKING_DIVERSITY_WEIGHT=0.1 (enable/disable)",
            "optimization": "Dynamic fetch_k adjustment (1.5x multiplier when enabled) to ensure sufficient candidates",
            "diversity_scoring": "Type penalty (0.2 per duplicate), path similarity analysis, maximum penalty cap (0.6)"
          }
        },
        {
          "pattern": "Fuzzy query normalization",
          "implementation": "Apply British-to-American spelling normalization during query preprocessing",
          "description": "Improve international user experience by handling spelling variations at query time",
          "details": {
            "integration": "Pydantic field validator with mode='before' for early preprocessing",
            "patterns": "Word boundary regex: -ise→-ize, -our→-or, -re→-er",
            "casePreservation": "Maintains original case patterns (SERIALISE → SERIALIZE)",
            "performance": "<1ms overhead per query with precompiled regex"
          }
        }
      ],
      "entries": [
        {
          "practice": "Dedicated embeddings for code examples",
          "description": "Separate example embeddings from document embeddings for better semantic search precision",
          "implementation": "Use dedicated tables (example_embeddings, vec_example_embeddings) with content hashing for deduplication. Format examples with context for better embedding quality.",
          "benefits": ["More precise example search", "Reduced storage through deduplication", "Better search performance with dedicated indexes"],
          "caveats": ["First search is slower due to model loading", "Requires additional database storage"],
          "dateAdded": "2025-08-07"
        },
        {
          "practice": "Embedding warmup implementation patterns",
          "description": "Best practices for eliminating cold-start latency in embedding-based applications",
          "implementation": {
            "representativeSamples": "Use 3-5 text samples of varying lengths to thoroughly warm up the model: short (~10 chars), medium (~100 chars), long (~500+ chars)",
            "fireAndForgetPattern": "Use asyncio.create_task() for non-blocking execution that doesn't delay server startup",
            "globalStatusTracking": "Maintain warmup status flags for health endpoint integration and monitoring",
            "dualModeSupport": {
              "restMode": "Use FastAPI startup_event with asyncio for async context",
              "mcpMode": "Use threading.Thread with separate event loop for STDIO compatibility"
            },
            "sharedWarmupFunction": "Both modes call the same async warmup function to eliminate code duplication"
          },
          "benefits": [
            "Eliminates 1.4s cold-start latency on first embedding request",
            "Non-blocking server startup maintains responsiveness",
            "Health endpoints can report warmup status for monitoring",
            "Consistent performance across all embedding operations"
          ],
          "codePattern": {
            "restMode": "@app.on_event('startup')\nasync def startup_event():\n    asyncio.create_task(warmup_embeddings())",
            "mcpMode": "def start_warmup_thread():\n    def warmup_worker():\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        loop.run_until_complete(warmup_embeddings())\n    threading.Thread(target=warmup_worker, daemon=True).start()",
            "sharedFunction": "async def warmup_embeddings():\n    samples = ['short', 'medium length sample', 'comprehensive warmup text']\n    await embed_model.embed(samples)\n    global warmup_complete\n    warmup_complete = True"
          },
          "considerations": [
            "Use daemon threads in MCP mode to avoid blocking process termination",
            "Include warmup status in health endpoints for monitoring",
            "Representative samples should reflect actual usage patterns",
            "Fire-and-forget pattern prevents startup delays"
          ],
          "dateAdded": "2025-08-09"
        },
        {
          "practice": "MMR diversification for search quality",
          "description": "Implement Maximum Marginal Relevance algorithm to balance relevance and diversity in search results, preventing homogeneous results from the same module or item type",
          "implementation": {
            "algorithm": "MMR = λ * relevance + (1-λ) * diversity where λ controls the relevance-diversity tradeoff",
            "configuration": {
              "RANKING_DIVERSITY_LAMBDA": "0.6 (default) - higher values favor relevance, lower favor diversity",
              "RANKING_DIVERSITY_WEIGHT": "0.1 (default) - global toggle, set to 0 to disable MMR completely"
            },
            "dynamicFetching": "Increase fetch_k by 1.5x when MMR enabled to ensure sufficient candidates for diversification",
            "diversityScoring": {
              "typePenalty": "Subtract 0.2 for each duplicate item type already selected",
              "pathSimilarity": "Penalize items from the same module path using string similarity",
              "maxPenalty": "Cap diversity penalty at 0.6 to prevent excessive penalization"
            }
          },
          "benefits": [
            "Prevents search results dominated by single module or item type",
            "Maintains high relevance while improving information diversity",
            "Configurable balance allows tuning for different use cases",
            "Minimal performance overhead (<5ms additional latency)"
          ],
          "codePattern": {
            "function": "def _apply_mmr_diversification(ranked_results, k, lambda_param):\n    selected = []\n    remaining = ranked_results[:]\n    selected.append(remaining.pop(0))  # Best result first\n    \n    while len(selected) < k and remaining:\n        best_mmr_score = float('-inf')\n        best_item = None\n        \n        for item in remaining:\n            relevance = item[0]  # Original ranking score\n            diversity = calculate_diversity_score(item, selected)\n            mmr_score = lambda_param * relevance + (1 - lambda_param) * diversity\n            \n            if mmr_score > best_mmr_score:\n                best_mmr_score = mmr_score\n                best_item = item\n        \n        selected.append(best_item)\n        remaining.remove(best_item)\n    \n    return [(score, path, header, content) for score, path, header, content, _ in selected]",
            "diversityCalculation": "def calculate_diversity_score(item, selected_items):\n    diversity = 1.0  # Start with maximum diversity\n    item_type = item[4]  # Item type from database\n    item_path = item[1]  # Item path for module comparison\n    \n    selected_types = [selected[4] for selected in selected_items]\n    type_penalty = selected_types.count(item_type) * 0.2\n    diversity -= min(0.6, type_penalty)  # Cap penalty\n    \n    # Path similarity penalty for same-module items\n    for selected in selected_items:\n        if item_path.split('::')[:-1] == selected[1].split('::')[:-1]:\n            diversity -= 0.1  # Same module penalty\n    \n    return max(0.0, diversity)  # Ensure non-negative"
          },
          "considerations": [
            "Lambda values closer to 1.0 prioritize relevance (good for specific searches)",
            "Lambda values closer to 0.0 prioritize diversity (good for exploratory searches)",
            "Dynamic fetch_k ensures sufficient candidates but caps at 50 for performance",
            "MMR adds minimal latency but significantly improves result quality"
          ],
          "dateAdded": "2025-08-10"
        },
        {
          "practice": "Ingestion completion tracking beyond file existence",
          "description": "Proper completion tracking for multi-stage ingestion operations requires more than just checking file existence - implement granular state tracking for precise failure identification",
          "implementation": "Use dedicated ingestion_status table with stage-by-stage tracking (download, extraction, parsing, database_insert, embedding_generation, completion) and status values (pending, in_progress, completed, failed, retrying)",
          "benefits": [
            "Precise identification of failure points in complex ingestion pipelines",
            "Enables targeted recovery strategies instead of blanket re-processing",
            "Better visibility into ingestion progress for monitoring and debugging",
            "Prevents partial ingestion states from being considered complete"
          ],
          "lessons": {
            "stateTracking": "File existence is insufficient - use proper state machines to track multi-stage operations",
            "failureRecovery": "Granular tracking enables precise recovery instead of full re-ingestion",
            "monitoring": "Completion status should be queryable and observable for operations teams"
          },
          "dateAdded": "2025-08-18"
        },
        {
          "practice": "State machines for granular failure point identification",
          "description": "Use state machine patterns in complex operations to identify exactly where failures occur, enabling targeted recovery and better debugging",
          "implementation": "Define clear states (pending → in_progress → completed/failed), track transitions with timestamps, and include error context for failed states",
          "benefits": [
            "Precise error localization reduces debugging time",
            "Targeted recovery strategies minimize resource waste",
            "Clear operational visibility into system health",
            "Enables retry strategies based on failure type and location"
          ],
          "lessons": {
            "stateDesign": "Design states to match actual operational stages, not just success/failure",
            "transitionTracking": "Log state transitions with timestamps and context for debugging",
            "errorContext": "Include detailed error information to enable intelligent recovery decisions"
          },
          "dateAdded": "2025-08-18"
        },
        {
          "practice": "Rate limiting recovery endpoints to prevent resource exhaustion",
          "description": "Recovery operations can be resource-intensive and should be rate-limited to prevent system overload during mass recovery scenarios",
          "implementation": "Implement exponential backoff for retry attempts, limit concurrent recovery operations, and provide circuit breaker patterns for mass failures",
          "benefits": [
            "Prevents cascade failures during recovery operations",
            "Maintains system stability under recovery load",
            "Enables controlled recovery prioritization",
            "Protects against accidental DoS from recovery operations"
          ],
          "lessons": {
            "backoffStrategy": "Use exponential backoff with jitter to prevent thundering herd problems",
            "concurrencyLimits": "Limit concurrent recovery operations based on system resources",
            "circuitBreaker": "Implement circuit breaker patterns to stop recovery when system is overloaded",
            "prioritization": "Provide mechanisms to prioritize critical recovery operations"
          },
          "dateAdded": "2025-08-18"
        },
        {
          "practice": "SQLite partial indexes for status tracking",
          "description": "Use SQLite partial indexes to optimize queries for incomplete ingestion states, providing significant performance improvements over full table scans",
          "implementation": "CREATE INDEX idx_incomplete_ingestion ON ingestion_status(crate_name, version) WHERE status != 'completed' - only indexes rows matching the WHERE condition",
          "benefits": [
            "Reduces query time from O(n) to O(log n) for incomplete detection",
            "Smaller index size compared to full indexes - only stores relevant rows",
            "Efficient for status-based queries in operational monitoring",
            "Supports fast identification of items needing recovery or retry"
          ],
          "sqliteSpecifics": {
            "partialIndexSupport": "SQLite partial indexes are highly efficient for conditional queries",
            "storageOptimization": "Only rows matching WHERE condition are stored in the index",
            "queryOptimizer": "SQLite query optimizer automatically uses partial indexes when WHERE conditions match",
            "maintenanceOverhead": "Minimal maintenance overhead as index only updates for relevant rows"
          },
          "dateAdded": "2025-08-18"
        },
        {
          "practice": "Fuzzy query normalization for international users",
          "description": "Apply British-to-American spelling normalization during query preprocessing to improve search consistency for international users while maintaining documentation in American English",
          "implementation": {
            "integration": "Implement in Pydantic field validators using mode='before' for early preprocessing",
            "spellingPatterns": {
              "ise_to_ize": "serialise → serialize, realise → realize, emphasise → emphasize",
              "our_to_or": "colour → color, honour → honor, behaviour → behavior", 
              "re_to_er": "centre → center, theatre → theater, metre → meter"
            },
            "regexPatterns": [
              "(\\w*?)ise\\b → \\1ize with word boundaries",
              "(\\w*?)our\\b → \\1or with word boundaries", 
              "(\\w*?)re\\b → \\1er with word boundaries"
            ],
            "casePreservation": "Use regex flags to maintain original case patterns (SERIALISE → SERIALIZE, Serialise → Serialize)"
          },
          "benefits": [
            "Improves search experience for British English users",
            "Maintains American English consistency in documentation",
            "Zero database changes required - applied at query time only",
            "Minimal performance impact (<1ms per query)",
            "Transparent to users - works automatically"
          ],
          "codePattern": {
            "validator": "@field_validator('query', mode='before')\n@classmethod\ndef normalize_query(cls, value: str) -> str:\n    if not isinstance(value, str):\n        return value\n    \n    # Apply Unicode normalization first\n    normalized = unicodedata.normalize('NFKC', value)\n    \n    # Apply fuzzy normalization for British/American spellings\n    return cls._apply_fuzzy_normalization(normalized)",
            "normalizationFunction": "@classmethod\ndef _apply_fuzzy_normalization(cls, query: str) -> str:\n    \"\"\"Apply fuzzy normalization for common spelling variations.\"\"\"\n    # British to American spelling patterns with word boundaries\n    patterns = [\n        (r'\\b(\\w*?)ise\\b', r'\\1ize'),  # serialise → serialize\n        (r'\\b(\\w*?)our\\b', r'\\1or'),   # colour → color\n        (r'\\b(\\w*?)re\\b', r'\\1er'),    # centre → center\n    ]\n    \n    result = query\n    for british_pattern, american_replacement in patterns:\n        # Preserve original case using re.sub with flags\n        def case_preserving_replace(match):\n            original = match.group(0)\n            replacement = re.sub(british_pattern, american_replacement, original, flags=re.IGNORECASE)\n            \n            # Preserve case pattern\n            if original.isupper():\n                return replacement.upper()\n            elif original.islower():\n                return replacement.lower()\n            elif original.istitle():\n                return replacement.capitalize()\n            else:\n                return replacement\n        \n        result = re.sub(british_pattern, case_preserving_replace, result)\n    \n    return result"
          },
          "considerations": [
            "Only normalizes whole words to avoid unintended replacements",
            "Applied during Pydantic validation for consistency across all queries",
            "Case preservation maintains user intent and readability",
            "Regex patterns are simple and efficient for common variations",
            "Can be extended with additional spelling patterns as needed"
          ],
          "dateAdded": "2025-08-10"
        },
        {
          "pattern": "Adaptive TTL caching",
          "implementation": "Implement complexity-based TTL with popularity tracking",
          "description": "Cache TTL should adapt to query complexity and usage patterns for optimal performance",
          "details": {
            "simpleQueries": "Low complexity queries → longer TTL (1 hour) for better cache utilization",
            "complexQueries": "High complexity queries with many filters → shorter TTL (15 minutes) to maintain freshness",
            "popularityTracking": "Track hit counts for popularity-based TTL extension",
            "storagePattern": "Store TTL with cache entries: (timestamp, results, ttl) for per-entry control"
          }
        },
        {
          "pattern": "Ingestion status table pattern",
          "implementation": "Create dedicated ingestion_status table for tracking multi-stage operations",
          "description": "Track ingestion progress beyond simple file existence using granular state machine approach",
          "details": {
            "tableSchema": "ingestion_status(crate_name, version, stage, status, timestamp, error_message, retry_count)",
            "stages": "download, extraction, parsing, database_insert, embedding_generation, completion",
            "statusValues": "pending, in_progress, completed, failed, retrying",
            "benefits": "Enables precise failure point identification and targeted recovery strategies"
          }
        },
        {
          "pattern": "Partial indexes for incomplete detection",
          "implementation": "Use SQLite partial indexes for efficient querying of incomplete ingestion states",
          "description": "Optimize database queries for finding incomplete or failed ingestions without full table scans",
          "details": {
            "indexDefinition": "CREATE INDEX idx_incomplete_ingestion ON ingestion_status(crate_name, version) WHERE status != 'completed'",
            "queryPattern": "SELECT crate_name, version FROM ingestion_status WHERE status != 'completed' ORDER BY timestamp",
            "performance": "Reduces query time from O(n) to O(log n) for incomplete detection",
            "storageEfficiency": "Partial indexes only store entries matching the WHERE condition, reducing index size"
          }
        },
        {
          "pattern": "Fail-fast recovery pattern",
          "implementation": "Delete and re-ingest approach instead of complex state repair for failed operations",
          "description": "Simplify error recovery by treating ingestion as atomic operation with clean restart on failure",
          "details": {
            "recoveryStrategy": "DELETE FROM all_tables WHERE crate_name=? AND version=?; followed by fresh ingestion",
            "advantages": "Eliminates complex partial state repair logic, ensures data consistency, prevents cascading failures",
            "tradeoffs": "Higher resource cost for recovery, but much simpler implementation and debugging",
            "rateLimiting": "Implement exponential backoff and max retry limits to prevent resource exhaustion"
          }
        }
      ]
    },
    "cache_management": {
      "description": "Cache management patterns and solutions",
      "entries": [
        {
          "issue": "Circular import between ingest.py and popular_crates.py",
          "solution": "Use lazy import inside function to avoid circular dependency. Import get_popular_manager inside evict_cache_if_needed() instead of at module level.",
          "lesson": "When modules have bidirectional dependencies, use lazy imports inside functions rather than module-level imports to break the cycle.",
          "context": "Priority-aware cache eviction feature implementation",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["src/docsrs_mcp/ingest.py", "src/docsrs_mcp/popular_crates.py"]
        },
        {
          "issue": "Cache invalidation strategy for re-export path resolution",
          "solution": "Implement 5-minute TTL with cache key per crate for balancing cache freshness with performance. Use simple dictionary cache with timestamp tracking for path resolution caching.",
          "lesson": "Slight staleness (5 minutes) is acceptable for path resolution as re-exports don't change frequently, but cache must be invalidated per crate to avoid cross-crate contamination.",
          "context": "Re-export auto-discovery implementation requiring fast path lookups with reasonable freshness",
          "dateEncountered": "2025-08-09",
          "relatedFiles": ["src/docsrs_mcp/app.py", "src/docsrs_mcp/ingest.py"],
          "performanceImpact": {
            "cacheTTL": "5 minutes",
            "keyStrategy": "Per-crate isolation",
            "tradeoff": "Slight staleness acceptable for 90% cache hit rate",
            "fallbackBehavior": "Direct database lookup on cache miss"
          }
        },
        {
          "issue": "Adaptive TTL caching implementation for query complexity optimization",
          "solution": "Implement complexity-based TTL calculation with hit count tracking. Simple queries (low filter count) get longer TTL (1 hour), complex queries get shorter TTL (15 minutes). Track popularity for TTL extension opportunities.",
          "lesson": "Cache TTL should adapt to query complexity - simple queries benefit from longer caching while complex queries need fresher data. Popularity tracking enables intelligent TTL extension for frequently accessed content.",
          "context": "Search result caching optimization to balance performance with data freshness",
          "dateEncountered": "2025-08-10",
          "relatedFiles": ["src/docsrs_mcp/database.py", "src/docsrs_mcp/app.py"],
          "performanceImpact": {
            "simpleQueryTTL": "1 hour for low complexity queries",
            "complexQueryTTL": "15 minutes for high filter count queries",
            "popularityBonus": "Hit count tracking enables TTL extension for popular queries",
            "storageOverhead": "Minimal - store (timestamp, results, ttl) tuple per cache entry"
          }
        },
        {
          "pattern": "MCP Parameter Schema Design",
          "implementation": "String-only schemas with comprehensive field validators",
          "description": "Design MCP schemas for maximum client compatibility using string types with robust validation",
          "details": {
            "schema_pattern": "Use string types for all parameters including numeric values",
            "validation_pattern": "@field_validator('param', mode='before') with coercion functions",
            "avoid": "anyOf patterns and complex type unions that MCP clients struggle with",
            "testing": "Test with curl in --mode rest to isolate client vs server validation issues"
          }
        },
        {
          "pattern": "Three-Tier Ingestion Architecture",
          "implementation": "Multi-source fallback with specialized handling per source type",
          "description": "Handle different documentation sources with appropriate fallback strategies",
          "details": {
            "tier1": "Primary source (docs.rs) for regular crates",
            "tier2": "Secondary source (rust-lang.org) for stdlib crates",
            "tier3": "Local source (rustup) for complete stdlib documentation",
            "detection": "Use is_stdlib_crate() for routing decisions",
            "graceful_degradation": "Provide minimal fallback when external sources fail"
          }
        },
        {
          "pattern": "Defensive None Checking",
          "implementation": "Safe string operations with fallback for external data",
          "description": "Protect against None and malformed data from external APIs",
          "details": {
            "safe_pattern": "(value or '').method() for string operations on potentially None values",
            "validation": "Check for None before performing operations",
            "logging": "Log None encounters for data quality monitoring",
            "fallbacks": "Provide sensible defaults for missing data"
          }
        },
        {
          "pattern": "Database Schema Evolution",
          "implementation": "Add metadata fields for enhanced filtering and presentation",
          "description": "Enhance database schema to support advanced features without breaking existing functionality",
          "details": {
            "metadata_fields": "Add is_dependency, stability_level, trait_bounds flags",
            "backward_compatibility": "Use DEFAULT values for new columns",
            "filtering": "Enable presentation-layer filtering based on user intent",
            "indexing": "Add indexes for new filtering capabilities"
          }
        },
        {
          "pattern": "Federated Search Architecture",
          "implementation": "Parallel search with mode-specific processors and result aggregation",
          "description": "Scale search capabilities across multiple dimensions and data sources",
          "details": {
            "parallelization": "Use asyncio.gather for concurrent searches across crates",
            "mode_routing": "Route to specialized processors based on search mode",
            "result_federation": "Aggregate and rank results from multiple sources",
            "performance": "Profile with concurrent.futures for optimal parallelization"
          }
        }
      ]
    },
    "testing": {
      "description": "Testing patterns and solutions for complex scenarios",
      "entries": [
        {
          "issue": "Mocking imported functions that are lazily imported",
          "solution": "When a function is imported inside another function (lazy import), patch it at its original module location, not where it's imported. Example: patch 'module.function' not 'importing_module.function'",
          "lesson": "Always patch at the source module, not at the import location, especially for lazy imports.",
          "context": "Testing priority-aware cache eviction with lazy imports",
          "dateEncountered": "2025-08-08",
          "relatedFiles": ["tests/test_ingest.py"]
        }
      ]
    }
  },
  "errorTemplate": {
    "error": "Error message or description",
    "context": "When/where the error occurred",
    "solution": "How the error was resolved",
    "prevention": "How to avoid this error in the future",
    "dateEncountered": "YYYY-MM-DD",
    "relatedFiles": ["file1.py", "file2.py"]
  },
  "knownLimitations": {
    "sqliteVss": {
      "issue": "1GB index size limit",
      "impact": "Cannot index very large crates",
      "workaround": "Implement chunking or use alternative vector DB for large crates"
    },
    "rustdocJson": {
      "issue": "Not all crates have rustdoc JSON available",
      "impact": "Cannot provide documentation for older crates",
      "workaround": "Return graceful error message without attempting local build"
    },
    "windowsCompatibility": {
      "issue": "uvloop not compatible with Windows",
      "impact": "Performance degradation on Windows",
      "workaround": "Fallback to standard asyncio event loop on Windows"
    },
    "claudeCodeMcpCompatibility": {
      "issue": "Claude Code does NOT support anyOf patterns in MCP schemas unlike Claude Desktop",
      "impact": "Parameter validation fails when schemas use anyOf patterns for type flexibility",
      "workaround": "Use string-only parameter types in MCP manifest with Pydantic field validators for coercion",
      "details": {
        "root_cause": "Claude Code implements stricter JSON Schema validation that rejects anyOf patterns entirely",
        "solution_pattern": "Define parameters as type: 'string' in manifest, use @field_validator(mode='before') for type conversion",
        "affected_tools": "All MCP tools with numeric or boolean parameters that need type flexibility"
      }
    },
    "versionComparisonErrors": {
      "issue": "PointerToNowhere errors in version comparison _map_item_type function",
      "impact": "Version comparison tools fail with null reference errors",
      "workaround": "Add defensive null checking before accessing item type properties",
      "details": {
        "root_cause": "Missing null checks when processing version comparison items",
        "solution_pattern": "Check if item exists and has required properties before mapping types"
      }
    },
    "preIngestionValidation": {
      "issue": "Pre-ingestion tool parameters lack proper anyOf patterns causing HTTP 422 errors",
      "impact": "Tool parameter validation fails when parameters sent as strings instead of expected types",
      "workaround": "Update tool schemas to use string types with validators, not anyOf patterns for Claude Code compatibility",
      "details": {
        "root_cause": "Claude Code strict schema validation incompatible with anyOf type patterns",
        "solution_pattern": "Use consistent string-type parameters with runtime type coercion in validators"
      }
    },
    "moduleStructureNoise": {
      "issue": "Module structure results include internal/dependency modules creating noise",
      "impact": "Search results contaminated with irrelevant internal implementation details",
      "workaround": "Filter internal and dependency modules from search results to focus on public API",
      "details": {
        "filter_patterns": ["::__", "_internal", "deps::", "std::", "core::"],
        "solution_pattern": "Apply post-processing filters to remove non-user-relevant modules from results"
      }
    },
    "searchCapabilities": {
      "issue": "Search system lacks regex patterns, cross-crate search, and stability filtering",
      "impact": "Users cannot perform advanced searches expected from modern documentation systems",
      "workaround": "Implement federated search with parallel processing across multiple crates and search modes",
      "details": {
        "missing_features": ["regex pattern matching", "cross-crate search", "stability level filtering", "trait implementation discovery"],
        "planned_architecture": "Parallel search federation with mode-specific processors and result ranking"
      }
    },
    "typeSystemNavigation": {
      "issue": "No trait implementation discovery or type relationship navigation",
      "impact": "Users cannot explore Rust's type system relationships through the documentation",
      "workaround": "Extract and store trait relationships during ingestion with dedicated navigation tools",
      "details": {
        "missing_relationships": ["trait implementations", "trait bounds", "associated types", "generic constraints"],
        "database_requirements": "New tables for traits, implementations, and relationship mapping"
      }
    },
    "stdlibDocumentationGaps": {
      "issue": "docs.rs does not provide stdlib JSON documentation, limiting stdlib coverage",
      "impact": "Stdlib queries return minimal fallback instead of complete documentation",
      "workaround": "Three-tier ingestion: docs.rs → rust-lang.org → local rustup for complete stdlib",
      "details": {
        "current_coverage": "62 items (std), 68 items (core), 43 items (alloc) in fallback",
        "complete_solution": "Local rust-docs-json component provides full stdlib documentation"
      }
    },
    "mcpProtocolStringCoercion": {
      "issue": "MCP protocol sends all parameters as strings regardless of intended type",
      "impact": "Numeric parameter validation fails despite proper schema definitions",
      "workaround": "Use string-only schemas with mode='before' validators for type coercion",
      "details": {
        "affected_parameters": ["numeric limits", "boolean flags", "enum values"],
        "solution_pattern": "String schemas + Pydantic field validators with coercion functions"
      }
    }
  },
  "debuggingTips": {
    "mcpTroubleshooting": [
      "Use MCP tools to trace schema generation and compare manifest with actual Pydantic models",
      "Test MCP tool parameters with curl to isolate client vs server validation issues",
      "Compare exact parameter types between MCP schema and tool implementation",
      "Verify $ref paths exist in schema structure before using in MCP manifests",
      "Check field validators are properly implemented for type coercion in MCP tools",
      "Use inline enum definitions instead of $ref for simple value constraints in MCP schemas",
      "Monitor internal progress tracking and expose through health endpoints for user visibility",
      "Test file validation with various case combinations to identify platform-specific issues",
      "Always implement case-insensitive comparison for configuration file validation",
      "CRITICAL: Claude Code does NOT support anyOf patterns - use string-only types with validators",
      "Test tools with both Claude Code and Claude Desktop to identify client-specific compatibility issues",
      "Add defensive null checking in version comparison functions to prevent PointerToNowhere errors",
      "Filter internal/dependency modules from search results using pattern matching",
      "For Claude Code compatibility: avoid anyOf, use string parameters with @field_validator coercion",
      "Use three-tier ingestion pattern for handling different documentation sources (docs.rs → rust-lang.org → local)",
      "Implement krate-based filtering to distinguish owned modules from dependency modules",
      "Apply (value or '').method() pattern for safe string operations on potentially None external data",
      "Test stdlib documentation with 'rustup component add --toolchain nightly rust-docs-json'",
      "Use asyncio.gather for parallel search federation across multiple crates and modes",
      "Add is_dependency flags to database schema for clean presentation layer filtering",
      "Profile search performance with concurrent.futures to optimize parallelization strategy",
      "Extract trait relationships from rustdoc JSON 'impls' section for type system navigation",
      "Implement graceful degradation with enhanced user guidance when external sources fail"
    ],
    "vectorSearch": [
      "Check embedding dimensions match (384 for BAAI/bge-small-en-v1.5)",
      "Verify FAISS index is properly initialized with vss_index!",
      "Monitor memory usage during batch operations",
      "Use MATCH operator instead of vec_distance() for queries",
      "Always include 'AND k = ?' parameter in vector search queries"
    ],
    "ingestion": [
      "Check asyncio.Lock is properly acquired/released",
      "Verify URL construction for docs.rs API",
      "Monitor decompression memory usage for large files",
      "Use await with all aiosqlite database operations",
      "Ensure ijson receives bytes input using io.BytesIO(content.encode())",
      "Set reasonable limits: MAX_DOWNLOAD_SIZE=100MB, MAX_DECOMPRESSED_SIZE=100MB",
      "Use DOWNLOAD_CHUNK_SIZE=8KB for streaming downloads",
      "Clean up test databases between runs to avoid state pollution",
      "Use 'SELECT last_insert_rowid()' after executemany() to get last inserted ID",
      "Calculate batch sizes as 999 // params_per_row to respect SQLite parameter limits",
      "Pre-serialize complex data before batching to avoid repeated serialization overhead",
      "Test batch logic with datasets >2x batch size to verify multiple batch handling",
      "Clear cache directory before testing enhanced parsing to ensure fresh database creation",
      "Use exact key matching in type dictionaries to avoid false positive substring matches",
      "Implement fallback mechanisms for optional data structures in rustdoc JSON",
      "Use distinct variable names in nested loops to prevent accidental overwrites",
      "Use docs.rs as primary source for stdlib docs instead of local rust-docs-json component",
      "Implement stdlib crate detection using set lookup for O(1) performance",
      "Configure AsyncMock context manager methods (__aenter__, __aexit__) when testing async sessions",
      "Always provide fallback version when external API calls (like Rust version fetch) fail",
      "Provide clear error messages with helpful instructions when stdlib download fails",
      "Use async generators for streaming data processing, sync generators for embedding batches",
      "Implement wrapper functions to maintain backwards compatibility between generators and lists",
      "Use MemoryMonitor context manager to track operation-level memory usage and cleanup",
      "Monitor both system-wide (psutil.virtual_memory().percent) and process-specific (process.memory_info().rss) memory usage",
      "Trigger garbage collection after processing 100+ items to maintain optimal memory usage",
      "Pre-serialize vectors and complex data structures before batch processing",
      "Clear buffers and trigger GC between batches in streaming operations",
      "Implement per-batch transactions for database resilience in streaming pipelines",
      "Log memory status at key processing points for debugging streaming operations",
      "Use integration tests to validate streaming pipeline error recovery",
      "Always load sqlite-vec extension before testing vector operations to prevent 'no such function' errors",
      "Handle both old list format and new JSON format for backward compatibility during data format changes",
      "Extract crate version from database filename when schema doesn't include version column",
      "Always import all required typing components (including Optional) when adding type hints",
      "Load sqlite-vec extension with proper enable/disable pattern: enable_load_extension(True) -> load_extension() -> enable_load_extension(False)",
      "Create partial indexes for common filter patterns to dramatically improve query performance",
      "Use progressive filtering only for small result sets (<10K items) - prefer database-level filtering for large datasets",
      "Use version-specific docs.rs URLs (/crate/{name}/{version}/json) to avoid redirect overhead",
      "Check magic bytes (0x28, 0xb5, 0x2f, 0xfd) for zstd compression detection instead of relying on headers",
      "Store full path_info dictionaries instead of just path strings when building module hierarchies",
      "Extract item kind from inner field as single-key dictionary in rustdoc JSON parsing",
      "Module names are derived from last element of path arrays, not separate name fields",
      "Preserve full data structures when building hierarchies to maintain context information",
      "FIXED: Always check if examples_data is string before iteration to prevent character fragmentation - apply type guard: if isinstance(examples_data, str): examples_data = [examples_data]",
      "Impl blocks in rustdoc JSON have empty names - extract from inner.trait and inner.for fields instead",
      "Use composite naming pattern 'TraitName_for_TypeName' for trait implementations to create meaningful identifiers",
      "Check inner.trait for null to distinguish between trait implementations and inherent implementations",
      "Existing streaming parser architecture accommodates new item types without structural changes",
      "No database schema changes needed for impl blocks - leverage existing item_type field patterns",
      "CRITICAL: When mocking Path objects in tests, use MagicMock(spec=Path) with exists() method configured",
      "CRITICAL: sqlite-vec MATCH operator requires explicit k parameter - never omit k constraint in vector queries",
      "See-also suggestions: exclude original search results using path exclusion to avoid duplicates",
      "sqlite-vec similarity scoring: use similarity = 1.0 - distance for proper ranking (higher = more similar)",
      "UI optimization: add suggestions only to first search result to prevent interface redundancy",
      "Graceful degradation: return empty suggestions array on any exception to maintain core functionality",
      "Test mock patterns: ingest_crate must return Path object with exists() method, not string",
      "Suggestion deduplication: use set comprehension for O(1) path exclusion performance",
      "Error handling: log suggestion generation failures but never break main search functionality",
      "Search filtering: Review restrictive crate_pattern and module_pattern filters to ensure function-level items are included",
      "sqlite-vec constraints: Always use explicit 'k = N' in WHERE clauses, not just LIMIT for vector queries",
      "PATH_ALIASES expansion: Add common Rust patterns like tokio::spawn -> tokio::task::spawn for better UX",
      "Fuzzy matching optimization: Consider Nucleo library for 6x performance improvement over RapidFuzz",
      "Hybrid search strategy: Combine vector similarity (60%) with BM25 keyword search (40%) for balanced results",
      "Debug mode implementation: Add debug=true parameter for detailed query scoring and performance analysis",
      "Re-export detection in rustdoc JSON: Look for items with 'kind' containing 'import' or 'use' keywords, extract alias from item path and target from inner structure",
      "Re-export path resolution: Extract alias name from item path array (last element) and resolve target path from inner.id or inner.path fields",
      "Re-export auto-discovery: Use streaming JSON parser to identify re-export patterns without loading entire JSON into memory",
      "CRITICAL: FastEmbed global singleton causes memory leaks - configure ONNX with sess_options.enable_cpu_mem_arena = False",
      "Memory management: Implement explicit cleanup with del embedding_session and gc.collect() after processing",
      "Model selection: Consider lighter models like all-MiniLM-L6-v2 to reduce memory footprint",
      "Database constraints: Add UNIQUE indexes on item_path to prevent duplicate entries during re-ingestion"
    ],
    "rateLimiting": [
      "MUST include Request parameter in endpoint function signatures or rate limiting won't work",
      "Middleware order matters - last added middleware is outermost in execution order",
      "Memory backend doesn't share state between workers - use Redis for production/multi-worker scenarios",
      "Use limiter.limit() decorator on each endpoint that needs rate limiting for granular control",
      "Set app.state.limiter after app initialization for proper middleware integration",
      "Create dedicated middleware.py for clean separation of rate limiting logic",
      "Add custom exception handler for RateLimitExceeded to provide consistent error responses",
      "Test rate limiting with concurrent requests using asyncio.gather to verify proper enforcement",
      "Verify both successful (200) and rate-limited (429) responses in tests",
      "Check that health/monitoring endpoints remain unprotected from rate limiting",
      "Test rate limit headers (X-RateLimit-*) are properly included in responses",
      "Ensure Redis is running for distributed limiting in production environments",
      "Check IP extraction middleware ordering for proper client identification",
      "Verify rate limit headers in responses for client feedback"
    ],
    "serverManagement": [
      "Start MCP server (default): nohup uv run docsrs-mcp > server.log 2>&1 & echo $!",
      "Start REST server: nohup uv run docsrs-mcp --mode rest > server.log 2>&1 & echo $!",
      "Alternative MCP: nohup uvx docsrs-mcp > server.log 2>&1 & echo $!",
      "Alternative REST: nohup uvx docsrs-mcp --mode rest > server.log 2>&1 & echo $!",
      "Kill server: kill <PID>",
      "Test REST endpoints: curl -s http://localhost:8000/endpoint | jq . (server runs on port 8000, not 8080)",
      "Test MCP manifest: Use --mode rest to test MCP manifest endpoints at localhost:8000",
      "Check embeddings: sqlite3 cache/crate/version.db \"SELECT * FROM embeddings;\""
    ],
    "cicdQuickReference": [
      "Windows compatibility: Use 'uv run' instead of direct executable calls in CI workflows",
      "PyPI publishing: Set UV_PUBLISH_TOKEN (not UV_PUBLISH_PASSWORD) in CI secrets",
      "Server testing in CI: SERVER_PID=$(nohup uv run server > server.log 2>&1 & echo $!); kill $SERVER_PID",
      "UV version consistency: Pin UV version in workflows to prevent cache deserialization errors",
      "PyPI builds: Use 'uv build --no-sources' for PyPI-compatible package builds",
      "Runner caching: Use local disk cache for self-hosted, GitHub Actions cache for hosted runners",
      "Cache management: Clear UV cache when upgrading UV versions to prevent corruption"
    ],
    "criticalBugs": [
      "RESOLVED: searchExamples character fragmentation bug - FIXED in ingest.py:758-762 and app.py:614-620",
      "Previous issue: String iteration bug caused characters instead of code blocks to be returned",
      "Root cause was: isinstance(examples_data, str) not checked before iteration, causing ['[', '{', '\"'] instead of complete blocks",
      "Solution applied: Added type guard pattern: if isinstance(examples_data, str): examples_data = [examples_data]",
      "Testing: Verified fix with live MCP calls to serde crate - now returns complete code blocks",
      "Status: RESOLVED 2025-08-08 - All example functionality now working correctly"
    ],
    "mcpServer": [
      "Run MCP mode (default): uvx docsrs-mcp",
      "Test MCP server: nohup uvx docsrs-mcp > mcp.log 2>&1 & echo $!",
      "Debug with REST mode: uvx docsrs-mcp --mode rest (easier debugging)",
      "Check MCP logs: tail -f mcp.log (logs go to stderr in MCP mode)",
      "Claude Desktop config: Use simplified args: [\"docsrs-mcp\"]",
      "Kill MCP server: kill <PID> (use captured PID from nohup)",
      "Verify MCP protocol: Check that STDIO is clean, no stdout pollution",
      "FastMCP conversion: Use FastMCP.from_fastapi() for automatic REST-to-MCP conversion",
      "Parameter type issues: MCP clients may send numeric parameters as strings - use Pydantic field validators with mode='before' for type coercion",
      "CRITICAL: Claude Code rejects anyOf schemas entirely - use simple string types in manifest and handle all coercion in Pydantic validators",
      "Schema compatibility: Design for the most restrictive MCP client (Claude Code) - avoid anyOf patterns completely",
      "Boolean field validator pattern: @field_validator('field', mode='before') with comprehensive string-to-bool conversion (true/false, 1/0, yes/no, on/off, t/y)",
      "AVOID anyOf schemas: Use single string types in manifest with examples array - let Pydantic validators handle all type conversion and validation",
      "Decorator ordering: Always use @field_validator BEFORE @classmethod decorator, not after - decorator execution is bottom-up",
      "Validation patterns: Check None first, then correct type, then string conversion with try/catch and helpful error messages",
      "Error types: Expect ValidationError for built-in Pydantic constraints, ValueError for custom field_validator methods",
      "Float conversion: Use 'could not convert' in error checks for float string conversion, 'invalid literal' for int conversion",
      "Testing approach: Test both native type validation (Pydantic constraints) and string validation (custom validators) paths",
      "Comprehensive validation: Handle integer-to-float conversion for float fields when clients send integer strings",
      "MCP Double Validation: Use anyOf schema patterns to handle JSON Schema + Pydantic validation conflicts",
      "Decorator ordering: @field_validator must come BEFORE @classmethod for proper wrapping",
      "None preservation: Don't convert None to defaults in validators - handle at application layer",
      "Error messages: Include field name, examples, and received value (truncated to 100 chars) for helpful feedback",
      "Compatibility testing: Test with both native types and string representations using model_validate()",
      "CRITICAL: All parameters with field validators in models.py need corresponding anyOf patterns in app.py's get_mcp_manifest() function",
      "anyOf pattern for numeric: {'anyOf': [{'type': 'integer'}, {'type': 'string'}]} in MCP manifest",
      "anyOf pattern for boolean: {'anyOf': [{'type': 'boolean'}, {'type': 'string'}]} in MCP manifest",
      "anyOf pattern for optional strings: {'anyOf': [{'type': 'string'}, {'type': 'null'}]} in MCP manifest",
      "Test MCP parameter validation with curl: both '{\"k\": \"5\"}' (string) and '{\"k\": 5}' (integer) should work",
      "Validation flow order: MCP manifest anyOf → FastMCP JSON Schema → Pydantic field validators → Type coercion",
      "CRITICAL BUG: start_pre_ingestion is the ONLY tool without anyOf patterns - add consistent anyOf patterns to all tools with parameters",
      "Schema consistency: All MCP tools must have matching anyOf patterns between manifest schema and Pydantic validators",
      "Memory management: FastEmbed global singleton causes memory leaks - implement explicit ONNX Runtime cleanup",
      "SDK memory leak mitigation: Use MCPServerRunner with rotation every 1000 calls or set MCP_MAX_CALLS=1000 environment variable",
      "Parameter validation pattern: Use validate_int_parameter() and validate_bool_parameter() utilities for string-to-type conversion with MCP clients",
      "Service layer architecture: Implement service layer abstraction for dual FastMCP/SDK support with transport-agnostic business logic",
      "Parallel validation testing: Run both implementations with subprocess isolation and JSON-RPC communication for regression testing",
      "Implementation selection: Use --mcp-implementation fastmcp/sdk/both flag for testing during migration phases",
      "Memory monitoring: Monitor process memory with psutil.Process().memory_info().rss to detect SDK memory leaks early"
    ],
    "queryPreprocessing": [
      "Check for whitespace-only queries before stripping to provide specific error messages",
      "Use Unicode NFKC normalization for consistent search text while preserving technical characters",
      "Technical symbols (::, <>, #) are preserved during NFKC normalization",
      "NFKC handles ligatures (ﬀ → ff), fractions (½ → 1⁄2), and compatibility characters",
      "Include specific examples in Pydantic validator error messages for better user experience",
      "Test normalization with various Unicode inputs including mathematical symbols and ligatures",
      "Verify that programming syntax elements remain intact after normalization"
    ],
    "moduleMetadataSearch": [
      "Check for trailing/leading '::' in module paths before stripping whitespace to catch malformed patterns",
      "Use db_path.parent.name to extract crate name from cache/{crate}/{version}.db file structure",
      "Construct module search patterns as: f'{crate_name}::{module_path}::%' for SQL LIKE queries",
      "Always add new filter parameters to _make_key(), get(), and set() methods for cache consistency",
      "Maintain parameter ordering consistency across cache methods to ensure proper cache hits",
      "Test FastAPI validation errors by checking both 422 status code and response.json()['detail'] array",
      "Use nohup with PID capture for background server testing: 'nohup uv run uvicorn docsrs_mcp.app:app > server.log 2>&1 & echo $!'",
      "Server testing: Always use nohup when starting servers in background, use kill PID to stop servers cleanly, check logs with tail -f for debugging"
    ],
    "fuzzyPathResolution": [
      "SearchCache is designed for embedding-based searches, not simple string caching - use basic dictionary cache with TTL for simple path caching needs",
      "FastAPI HTTPException requires string detail, not dictionary - include suggestions in error message text to avoid 500 errors",
      "TestClient works synchronously - avoid mixing async fixtures, mock at appropriate level and use sync test functions",
      "RapidFuzz works best as fallback-only approach to preserve exact match performance while adding fuzzy capabilities",
      "Cache paths per crate to avoid repeated database queries during fuzzy search operations",
      "Use fallback pattern: attempt exact match first, then fuzzy search if no results found",
      "Implement simple TTL caching with dictionary for path lookups rather than complex caching frameworks",
      "RapidFuzz v3.0+ requires explicit processor=default_process - default preprocessing removed",
      "Use unicodedata.normalize('NFC') for Unicode consistency before fuzzy matching",
      "Composite scoring (ratio + token_sort_ratio + partial_ratio) improves accuracy ~25% over single algorithms",
      "Path component bonuses help prioritize exact final component matches in composite scoring",
      "resolve_path_alias is async function - tests must use @pytest.mark.asyncio and await calls",
      "5-minute TTL caching provides ~90% hit rate while maintaining reasonable data freshness"
    ],
    "pathAliasResolution": [
      "Implement PATH_ALIASES dictionary with O(1) lookup for common path shortcuts before database queries",
      "Include mappings for frequently used patterns: serde::Deserialize → serde::de::Deserialize, tokio::spawn → tokio::task::spawn",
      "Add std library aliases like Result → std::result::Result, Option → std::option::Option for better UX",
      "Place resolve_path_alias() function before database lookup to minimize performance impact (<1ms overhead)",
      "Test both unit tests for the alias function and integration tests for API endpoints",
      "Use --mode rest flag for easier HTTP/curl testing during development instead of STDIO mode",
      "Update PATH_ALIASES based on user feedback and common usage patterns to improve coverage",
      "Maintain sub-500ms response time requirement even with alias resolution overhead"
    ],
    "rustdocJsonParsing": [
      "Impl blocks have empty name fields - extract meaningful names from inner.trait and inner.for fields",
      "Use composite naming pattern: 'TraitName_for_TypeName' for trait implementations",
      "Check inner.trait field for null to identify inherent vs trait implementations",
      "Generate searchable identifiers from inner.for field when inner.trait is null (inherent impls)",
      "Existing streaming parser accommodates new item types without architecture changes",
      "No database schema modifications needed - use existing item_type field for impl blocks",
      "Complex type information may be nested in both trait and for fields - parse carefully",
      "Empty name fields are normal for impl blocks - don't treat as parsing errors"
    ],
    "backgroundScheduler": [
      "Use set() to maintain strong references: self.background_tasks = set() with add/discard callbacks",
      "Add jitter to prevent coordination: base_interval + random.uniform(-jitter_range, jitter_range)",
      "Check memory before intensive operations: psutil.virtual_memory().percent < 80",
      "Use environment variables for configuration: SCHEDULER_ENABLED, intervals, thresholds",
      "Test with asyncio.wait_for() and short timeouts - background tasks will timeout (expected)",
      "Test both enabled and disabled states for backward compatibility",
      "Background task cleanup: task.add_done_callback(lambda t: self.background_tasks.discard(t))",
      "Default jitter: ±10% variance provides good load distribution without affecting accuracy",
      "Memory threshold: 80% leaves headroom for processing spikes, skip operations when exceeded",
      "Configuration pattern: Default enabled for UX, clear disable mechanism for resource constraints"
    ]
  },
  "performanceMetrics": {
    "targets": {
      "warmSearchLatency": "< 500ms P95",
      "coldIngestTime": "< 3s for 10MB crates",
      "memoryUsage": "< 1GB RSS (NOTE: FastEmbed memory leak can cause 1.5GB+ growth without proper ONNX configuration)",
      "cacheSize": "< 2GB total"
    },
    "optimizationStrategies": {
      "embedding": "Batch size 32 (EMBEDDING_BATCH_SIZE) for optimal CPU utilization",
      "database": "Insert batches respecting SQLite's 999 parameter limit, pre-serialize data",
      "caching": "LRU eviction when > 2GB",
      "asyncio": "Use asyncio.gather for concurrent operations",
      "batchProcessing": "Maintains constant memory usage regardless of dataset size",
      "memoryManagement": "Use MemoryMonitor context manager, trigger GC after 100+ items, pre-serialize before batching",
      "streaming": "Async generators for data processing, wrapper functions for backwards compatibility",
      "errorRecovery": "Per-batch transactions, memory status logging, streaming-aware error handling",
      "databaseOptimization": "Create partial indexes for common filter patterns, use progressive filtering only for small result sets (<10K items)",
      "extensionManagement": "Always load sqlite-vec extension before vector operations, especially in testing environments",
      "codeExampleExtraction": "Language detection adds minimal overhead (~200ms warm queries), deduplication by hash prevents duplicates efficiently, backward compatibility essential for format changes",
      "fuzzyPathResolution": "Use fallback-only approach with RapidFuzz for minimal performance impact, cache paths per crate, implement simple TTL dictionary cache instead of complex caching frameworks. Composite scoring adds <5ms overhead while improving accuracy ~25%. 5-minute TTL provides ~90% cache hit rate",
      "pathAliasResolution": "Static PATH_ALIASES dictionary with O(1) lookup adds <1ms overhead, maintains sub-500ms response time requirement while significantly improving user experience",
      "implBlockParsing": "Impl block parsing uses existing streaming architecture without performance impact, composite naming creates searchable identifiers efficiently, no schema changes required for trait implementation search",
      "databaseBatchInsertion": "Use executemany() with IGNORE clause for duplicate handling achieves 70% reduction in insertion time compared to individual INSERT statements, especially beneficial for large re-export datasets",
      "batchInsertOptimization": "Pre-process re-export data into tuples before batching to avoid repeated serialization overhead during executemany() operations",
      "memoryLeakPrevention": "Configure FastEmbed ONNX Runtime with sess_options.enable_cpu_mem_arena = False to prevent memory accumulation, implement explicit model lifecycle management",
      "ingestionStatusTracking": "Use dedicated ingestion_status table with partial indexes for efficient incomplete detection queries, ~90% performance improvement over full table scans for status monitoring",
      "failFastRecovery": "DELETE and re-ingest pattern provides simpler implementation than complex state repair, uses more resources but eliminates cascading failure scenarios"
    }
  },
  "codeQuality": {
    "ruff": {
      "description": "Exclusive linting and formatting tool for this project",
      "replacesTools": ["black", "flake8", "isort", "pylint", "pycodestyle", "autopep8"],
      "commonCommands": {
        "lint": "uv run ruff check .",
        "lintFix": "uv run ruff check --fix .",
        "format": "uv run ruff format .",
        "formatCheck": "uv run ruff format --check .",
        "showDiff": "uv run ruff check --diff ."
      },
      "configurationTips": {
        "location": "pyproject.toml under [tool.ruff]",
        "basicSetup": {
          "lineLength": 88,
          "target-version": "py310",
          "selectRules": "Most rules enabled by default",
          "ignorePatterns": "Use 'exclude' for directories"
        },
        "commonRules": {
          "E": "pycodestyle errors",
          "W": "pycodestyle warnings", 
          "F": "Pyflakes",
          "I": "isort import sorting",
          "N": "pep8-naming",
          "UP": "pyupgrade"
        }
      },
      "integrationTips": [
        "Add ruff extension to VS Code for real-time feedback",
        "Configure pre-commit hook: 'uv run ruff check --fix && uv run ruff format'",
        "CI should run both 'ruff check' and 'ruff format --check'",
        "Use --fix flag in development, never in CI",
        "Ruff auto-fixes are safe and preserve code semantics",
        "Ruff formatting automatically fixes whitespace issues in docstrings"
      ],
      "ignorableWarnings": [
        "PLR0912 (too-many-branches): Can be ignored for documentation processing tasks",
        "PLR0915 (too-many-statements): Can be ignored for documentation processing tasks and complex algorithms like MMR diversification"
      ],
      "lintingBestPractices": {
        "formatCommand": "uv run ruff format",
        "lintCommand": "uv run ruff check --fix",
        "acceptableWarnings": "PLR0915 (too many statements) may be acceptable in complex algorithms like MMR diversification with multiple calculation steps",
        "workflow": "Run formatting before linting to avoid style-related lint errors"
      },
      "performanceNotes": [
        "10-100x faster than traditional Python tools",
        "Processes entire codebase in milliseconds",
        "No need for separate tools or complex configuration"
      ]
    },
    "refactoring": {
      "description": "Patterns and lessons learned for effective code refactoring",
      "fileBloat": {
        "problem": "Refactored files becoming larger than originals, violating refactoring goals",
        "commonCauses": [
          "Inline configuration data (JSON schemas, tool definitions) not recognized as bloat",
          "Hardcoded data structures mixed with business logic",
          "Configuration constants defined within functions instead of external files"
        ],
        "identificationTechnique": {
          "description": "Find largest functions in a file to identify bloat sources",
          "bashCommand": "grep -n \"^async def\\\\|^def\" file.py | while read line; do\n  num=$(echo $line | cut -d: -f1)\n  func=$(echo $line | cut -d: -f2-)\n  echo \"$func: line $num\"\ndone",
          "manualCalculation": "echo \"function_name: $((end_line-start_line)) lines\"",
          "example": "get_mcp_manifest: 273 lines (602-329) - mostly configuration data"
        },
        "solutionPattern": {
          "step1": "Analyze WHY file is large, not just THAT it's large",
          "step2": "Identify configuration data vs business logic",
          "step3": "Extract configuration to separate data files (e.g., mcp_tools_config.py)",
          "step4": "Verify refactoring actually improves maintainability",
          "example": "Reduced get_mcp_manifest from 273 to ~30 lines by extracting tool definitions"
        },
        "lessonsLearned": [
          "Configuration data (JSON schemas, tool definitions) should be extracted to separate files",
          "Line count includes both logic AND data - both affect maintainability", 
          "Always check if refactoring result actually improves the situation",
          "When refactoring, verify the end result meets the original goals"
        ],
        "debuggingTechniques": [
          "Use grep to find function boundaries and calculate sizes",
          "Identify hardcoded data structures within functions",
          "Compare before/after line counts to validate improvements",
          "Look for repeated patterns that can be extracted to configuration"
        ],
        "bestPractices": [
          "Separate configuration data from business logic",
          "Use external data files for schemas and tool definitions",
          "Balance file splitting to avoid over-modularization",
          "Always validate that refactoring achieves intended goals"
        ],
        "dateDocumented": "2025-08-23",
        "relatedFiles": ["endpoints.py", "mcp_tools_config.py", "endpoints_tools.py"],
        "realWorldExample": {
          "problem": "endpoints.py became 1070 lines after refactoring from 981-line app.py",
          "analysis": "get_mcp_manifest function contained 273 lines of hardcoded tool definitions",
          "solution": "Created mcp_tools_config.py for data, reduced function to ~30 lines",
          "outcome": "Achieved original refactoring goal of smaller, more maintainable files"
        }
      }
    }
  },
  "securityConsiderations": {
    "security_vulnerabilities": [
      "CVE-2025-49596: Critical RCE in MCP Inspector (CVSS 9.4) - upgrade to v0.14.1+",
      "Command injection possible through unsanitized file paths - use parameterized queries",
      "Path traversal attacks via ../ sequences - implement allow-lists for directories",
      "STDIO corruption from stdout writes - use stderr for all logging",
      "Prompt injection via tool descriptions - sanitize all tool metadata"
    ],
    "compatibility_issues": [
      "Windows path handling requires double backslashes in JSON config",
      "Python ModuleNotFoundError - ensure consistent virtual environments",
      "Claude Code MCP client rejects anyOf patterns - use simple string schemas instead",
      "Platform-specific Python path resolution - use absolute paths",
      "JSON Schema validation occurs before Pydantic - design schemas accordingly"
    ],
    "placeholders": {
      "securityEmail": {
        "issue": "Security contact placeholder (security@example.com) should be updated",
        "impact": "Users cannot report security issues properly",
        "action": "Replace security@example.com with actual security contact email",
        "relatedFiles": ["src/docsrs_mcp/app.py"]
      }
    }
  }
}